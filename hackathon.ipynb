{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from multiprocessing import Pool as mpPool\n",
    "from multiprocessing import cpu_count\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from functools import lru_cache, wraps\n",
    "\n",
    "EPSILON = 1e-6\n",
    "CACHE_SIZE = 2**13\n",
    "\n",
    "\n",
    "def random_prices(shape: tuple[int, int]) -> torch.Tensor:\n",
    "    prices_matrix = torch.cumsum(torch.randn(*shape), dim=0)\n",
    "    prices_matrix += torch.randn(1, shape[1])\n",
    "    return prices_matrix\n",
    "\n",
    "@lru_cache(maxsize=CACHE_SIZE)\n",
    "def change(prices, lag: int = 1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes absolute change in prices.\n",
    "\n",
    "    Args:\n",
    "        - `prices` (torch.Tensor): A tensor of shape `(batch_size, n_tradable)`.\n",
    "        - `lag` (int): The number of periods to lag the prices by.\n",
    "    Returns:\n",
    "        torch.Tensor: Absolute change in prices. Shape: `(batch_size, n_tradable)`.\n",
    "    \"\"\"\n",
    "    prices = torch.as_tensor(prices)\n",
    "\n",
    "    shifted_prices = torch.cat((prices[0].repeat(lag, 1), prices))\n",
    "\n",
    "    return shifted_prices[lag:] - shifted_prices[:-lag]\n",
    "\n",
    "def apply_columnwise(s: torch.Tensor, func: callable) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply a function column-wise to a tensor.\n",
    "\n",
    "    Result will be cached.\n",
    "\n",
    "    Args:\n",
    "        s (torch.Tensor): The input tensor.\n",
    "        func (callable): The function to apply column-wise.\n",
    "    \"\"\"\n",
    "    if s.dim() == 1:\n",
    "        return func(s)\n",
    "\n",
    "    res = torch.zeros_like(s)\n",
    "\n",
    "    for j in range(s.shape[1]):\n",
    "        res[:, j] = func(s[:, j])\n",
    "\n",
    "    return res\n",
    "\n",
    "def check_linearity(timestamps: np.ndarray, tolerance: float = 0.05) -> bool:\n",
    "    \"\"\"Check if timestamps have constant intervals within given tolerance.\"\"\"\n",
    "    if len(timestamps) < 2:\n",
    "        return True\n",
    "\n",
    "    deltas = np.diff(timestamps)\n",
    "    \n",
    "    max_step = np.max(deltas)\n",
    "    min_step = np.min(deltas)\n",
    "    is_linear = max_step - min_step <= 2*tolerance*np.median(deltas)\n",
    "    return bool(is_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Train_timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series1</th>\n",
       "      <th>Series2</th>\n",
       "      <th>Series3</th>\n",
       "      <th>Series4</th>\n",
       "      <th>Series5</th>\n",
       "      <th>Series6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938367</th>\n",
       "      <td>-0.763961</td>\n",
       "      <td>-1.670369</td>\n",
       "      <td>1.632822</td>\n",
       "      <td>0.327631</td>\n",
       "      <td>-1.465975</td>\n",
       "      <td>-2.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938368</th>\n",
       "      <td>-0.929016</td>\n",
       "      <td>-1.799173</td>\n",
       "      <td>1.903091</td>\n",
       "      <td>0.607440</td>\n",
       "      <td>-1.464328</td>\n",
       "      <td>-2.056986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938369</th>\n",
       "      <td>-1.058803</td>\n",
       "      <td>-1.798737</td>\n",
       "      <td>1.809294</td>\n",
       "      <td>0.673262</td>\n",
       "      <td>-1.462685</td>\n",
       "      <td>-1.881761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938370</th>\n",
       "      <td>-0.996506</td>\n",
       "      <td>-1.798323</td>\n",
       "      <td>1.675207</td>\n",
       "      <td>0.526339</td>\n",
       "      <td>-1.461045</td>\n",
       "      <td>-1.879009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938371</th>\n",
       "      <td>-0.921254</td>\n",
       "      <td>-1.797929</td>\n",
       "      <td>1.805300</td>\n",
       "      <td>0.599747</td>\n",
       "      <td>-1.459408</td>\n",
       "      <td>-1.933551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Series1   Series2   Series3   Series4   Series5   Series6\n",
       "938367 -0.763961 -1.670369  1.632822  0.327631 -1.465975 -2.002986\n",
       "938368 -0.929016 -1.799173  1.903091  0.607440 -1.464328 -2.056986\n",
       "938369 -1.058803 -1.798737  1.809294  0.673262 -1.462685 -1.881761\n",
       "938370 -0.996506 -1.798323  1.675207  0.526339 -1.461045 -1.879009\n",
       "938371 -0.921254 -1.797929  1.805300  0.599747 -1.459408 -1.933551"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_ = data['Date']\n",
    "# remove time from date\n",
    "del data['Date']\n",
    "data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def datetime_to_timestamp(date_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert datetime strings to Unix timestamps (seconds since epoch)\n",
    "    \n",
    "    Args:\n",
    "        date_series: pandas Series containing datetime strings\n",
    "        \n",
    "    Returns:\n",
    "        pandas Series with Unix timestamps as int64\n",
    "    \"\"\"\n",
    "    # Convert string to datetime if series contains strings\n",
    "    if date_series.dtype == object:\n",
    "        date_series = pd.to_datetime(date_series)\n",
    "    \n",
    "    # Convert to Unix timestamp (seconds since epoch)\n",
    "    return date_series.astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ = datetime_to_timestamp(time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_linearity(time_, tolerance=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_last(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Fill NaN values by propagating last valid observation forward using pandas\n",
    "    \n",
    "    Args:\n",
    "        data: Input array with NaN values. Shape: (T, N)\n",
    "        \n",
    "    Returns:\n",
    "        Array with NaN values filled by forward fill\n",
    "    \"\"\"\n",
    "    # Convert to pandas DataFrame for efficient ffill\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Apply forward fill\n",
    "    filled_df = df.ffill()\n",
    "    \n",
    "    return filled_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def fill_with_corr_diff(ts):\n",
    "    \"\"\"\n",
    "    Fill NaNs with correlation-based interpolation using regularized regression\n",
    "    \n",
    "    Args:\n",
    "        ts: numpy array of shape (T, N) where T is time steps and N is features\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape (T, N) with NaNs filled\n",
    "    \"\"\"\n",
    "    # Convert to pandas DataFrame for easier handling of NaNs\n",
    "    df = pd.DataFrame(ts)\n",
    "    T, N = df.shape\n",
    "    \n",
    "    # Create a copy to store the results\n",
    "    filled_df = df.copy()\n",
    "    \n",
    "    # Process each time step with NaN values\n",
    "    nan_timesteps = df.index[df.isna().any(axis=1)]\n",
    "    \n",
    "    for t in tqdm(nan_timesteps, desc=\"Filling missing values\"):\n",
    "        if t == 0:\n",
    "            # For the first time step, use the next available value\n",
    "            filled_df.loc[t] = df.loc[t].fillna(method='bfill')\n",
    "            continue\n",
    "            \n",
    "        # Get the mask of NaN values for the current time step\n",
    "        nan_mask = df.loc[t].isna()\n",
    "        nan_cols = df.columns[nan_mask]\n",
    "        \n",
    "        # Get last known values for the NaN columns\n",
    "        last_known_values = {}\n",
    "        for col in nan_cols:\n",
    "            last_valid_idx = df.loc[:t-1, col].last_valid_index()\n",
    "            if last_valid_idx is not None:\n",
    "                last_known_values[col] = df.loc[last_valid_idx, col]\n",
    "            else:\n",
    "                # If no previous valid value exists, use next available value\n",
    "                next_valid_idx = df.loc[t:, col].first_valid_index()\n",
    "                if next_valid_idx is not None:\n",
    "                    last_known_values[col] = df.loc[next_valid_idx, col]\n",
    "                else:\n",
    "                    # If no valid value exists at all, set to 0\n",
    "                    last_known_values[col] = 0\n",
    "        \n",
    "        for col in nan_cols:\n",
    "            # Count consecutive NaNs backwards from current position\n",
    "            consecutive_nans = 0\n",
    "            curr_t = t\n",
    "            while curr_t >= 0 and pd.isna(df.loc[curr_t, col]):\n",
    "                consecutive_nans += 1\n",
    "                curr_t -= 1\n",
    "            \n",
    "            if consecutive_nans == 1:\n",
    "                # Exactly one NaN - use regression based on other assets' changes\n",
    "                # Select non-NaN columns for this time step and the previous step\n",
    "                valid_cols = [c for c in df.columns if c != col and not pd.isna(df.loc[t, c]) and not pd.isna(df.loc[t-1, c])]\n",
    "                \n",
    "                if len(valid_cols) > 0:\n",
    "                    try:\n",
    "                        # Calculate changes for valid columns for prediction\n",
    "                        X_pred = np.array([[df.loc[t, c] - df.loc[t-1, c] for c in valid_cols]])\n",
    "                        \n",
    "                        # Get historical data for training (avoiding NaNs)\n",
    "                        train_data = []\n",
    "                        y_data = []\n",
    "                        \n",
    "                        # Look back up to 20 time steps, but avoid index errors\n",
    "                        for i in range(max(1, t-20), t):\n",
    "                            # Only use rows where both current and previous values are valid\n",
    "                            if not pd.isna(df.loc[i, col]) and not pd.isna(df.loc[i-1, col]):\n",
    "                                # Check if all needed predictors are non-NaN for this row\n",
    "                                predictors_valid = True\n",
    "                                row_predictors = []\n",
    "                                \n",
    "                                for c in valid_cols:\n",
    "                                    if pd.isna(df.loc[i, c]) or pd.isna(df.loc[i-1, c]):\n",
    "                                        predictors_valid = False\n",
    "                                        break\n",
    "                                    row_predictors.append(df.loc[i, c] - df.loc[i-1, c])\n",
    "                                \n",
    "                                if predictors_valid:\n",
    "                                    train_data.append(row_predictors)\n",
    "                                    y_data.append(df.loc[i, col] - df.loc[i-1, col])\n",
    "                        \n",
    "                        # Convert to numpy arrays\n",
    "                        X_train = np.array(train_data)\n",
    "                        y = np.array(y_data)\n",
    "                        \n",
    "                        if len(X_train) >= 3 and len(y) >= 3:  # Need at least a few samples for regression\n",
    "                            # Remove outliers using IQR method on target variable\n",
    "                            q1 = np.percentile(y, 25)\n",
    "                            q3 = np.percentile(y, 75)\n",
    "                            iqr = q3 - q1\n",
    "                            lower_bound = q1 - 50 * iqr\n",
    "                            upper_bound = q3 + 50 * iqr\n",
    "                            \n",
    "                            valid_indices = (y >= lower_bound) & (y <= upper_bound)\n",
    "                            X_train_filtered = X_train[valid_indices]\n",
    "                            y_filtered = y[valid_indices]\n",
    "                            \n",
    "                            if len(X_train_filtered) >= 3:  # Still need enough samples after filtering\n",
    "                                # Use Ridge regression with regularization instead of LinearRegression\n",
    "                                model = Ridge(alpha=1.0)  # Alpha controls regularization strength\n",
    "                                model.fit(X_train_filtered, y_filtered)\n",
    "                                \n",
    "                                # Predict the change but bound it to reasonable limits\n",
    "                                predicted_change = model.predict(X_pred)[0]\n",
    "                                \n",
    "                                # Limit change to be within historical range * safety factor\n",
    "                                max_abs_change = max(abs(y_filtered)) * 1.5\n",
    "                                predicted_change = max(min(predicted_change, max_abs_change), -max_abs_change)\n",
    "                                \n",
    "                                # Apply change to the last known value\n",
    "                                filled_value = last_known_values[col] + predicted_change\n",
    "                                \n",
    "                                # Additional sanity check: value shouldn't change too drastically\n",
    "                                if abs(filled_value / (last_known_values[col] + 1e-10) - 1) < 0.5:  # Max 50% change\n",
    "                                    filled_df.loc[t, col] = filled_value\n",
    "                                    continue\n",
    "                    except Exception as e:\n",
    "                        # If any error occurs during regression, fall back to last known value\n",
    "                        pass\n",
    "            \n",
    "            # If multiple NaNs or regression couldn't be applied, use last known value\n",
    "            filled_df.loc[t, col] = last_known_values[col]\n",
    "    \n",
    "    return filled_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling missing values: 100%|██████████| 243056/243056 [13:30<00:00, 299.81it/s]\n"
     ]
    }
   ],
   "source": [
    "ts_filled = fill_with_corr_diff(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_filled_forward = fill_with_last(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create plot with proper labels and title\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ts_filled - ts_filled_forward, alpha=0.7)\n",
    "plt.title('Difference Between Correlation-Based Filling and Forward Filling', fontsize=14)\n",
    "plt.xlabel('Time Steps', fontsize=12)\n",
    "plt.ylabel('Filling Difference', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_filled[-1000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of NaN counts per time step\n",
    "nan_mask = np.isnan(ts).astype(int)\n",
    "plt.hist(np.sum(nan_mask, axis=1), bins=50)\n",
    "plt.xlabel('Number of NaN values per time step')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of NaN values across time series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_filled = fill_with_arima(ts[-10_000:])\n",
    "# ts_filled = fill_with_last(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# plot_acf(np.diff(ts_filled[-60*4*1000:, 0]), lags=60*4)\n",
    "plot_pacf((ts_filled[-60*4*1000:, 0]), lags=10)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_filled[:, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ts_filled[:, 0], bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrlation matrix\n",
    "plt.imshow(np.corrcoef(ts_filled.T))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate first differences and handle NaNs\n",
    "ts_diff = np.diff(ts_filled, axis=0)\n",
    "ts_diff = np.nan_to_num(ts_diff)\n",
    "\n",
    "# Plot correlation matrix with labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(np.corrcoef(ts_diff.T), cmap='viridis', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='Correlation Coefficient')\n",
    "plt.title('Correlation Matrix of First Differences')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Feature Index')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sma(close_log: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes Simple Moving Average using cumulative sum approach.\n",
    "    Handles edge cases where window size exceeds available data.\n",
    "    \n",
    "    Args:\n",
    "        close_log: Input tensor of shape (T, N) where T is time dimension\n",
    "        period: SMA window size (must be positive)\n",
    "        \n",
    "    Returns:\n",
    "        Tensor: SMA with same shape as input, dtype float32\n",
    "    \"\"\"\n",
    "    if period <= 0:\n",
    "        raise ValueError(f\"Period must be positive, got {period}\")\n",
    "    if close_log.ndim != 2:\n",
    "        raise ValueError(f\"Input must be 2D tensor (T, N), got shape {close_log.shape}\")\n",
    "    \n",
    "    T, N = close_log.shape\n",
    "    if T == 0:\n",
    "        return close_log.clone()\n",
    "    \n",
    "    cumsum = torch.cumsum(close_log, dim=0)\n",
    "    \n",
    "    if period > T:\n",
    "        window = torch.arange(1, T+1, device=close_log.device, dtype=torch.float32).view(-1, 1)\n",
    "        return (cumsum / window).to(close_log.dtype)\n",
    "    \n",
    "    # Calculate moving sum using shifted cumulative sums\n",
    "    shifted = torch.zeros_like(cumsum)\n",
    "    shifted[period:] = cumsum[:-period]\n",
    "    moving_sum = cumsum - shifted\n",
    "    \n",
    "    # Calculate dynamic window sizes (clipped at period)\n",
    "    window = torch.arange(1, T+1, device=close_log.device, dtype=torch.float32).view(-1, 1)\n",
    "    window = torch.minimum(window, torch.tensor(period, dtype=torch.float32, device=close_log.device))\n",
    "    \n",
    "    return (moving_sum / window).to(close_log.dtype)\n",
    "\n",
    "\n",
    "def ema(close_log: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes Exponential Moving Average (EMA) of a time series using vectorized PyTorch ops.\n",
    "\n",
    "    Args:\n",
    "        close_log (torch.Tensor): Time series (T, N), where T — time, N — series.\n",
    "        period (int): Smoothing period.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: EMA of same shape as input.\n",
    "    \"\"\"\n",
    "    alpha = 2 / (period + 1)\n",
    "    close_log = close_log.float()\n",
    "    ema = torch.zeros_like(close_log)\n",
    "    ema[0] = close_log[0]  # init first value to be same\n",
    "\n",
    "    # recursive EMA computation, vectorized over columns\n",
    "    for t in range(1, close_log.shape[0]):\n",
    "        ema[t] = alpha * close_log[t] + (1 - alpha) * ema[t - 1]\n",
    "    \n",
    "    return ema\n",
    "\n",
    "def stdev(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates rolling standard deviation of a time series.\n",
    "\n",
    "    Args:\n",
    "        series (torch.Tensor): (T, N) tensor where T — time, N — different series (columns).\n",
    "        period (int): Rolling window size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: (T, N) rolling standard deviation. First few rows will be NaN or zero due to padding.\n",
    "    \"\"\"\n",
    "    T = series.shape[0]\n",
    "    if period > T:\n",
    "        raise ValueError(\"Period can't be greater than time dimension\")\n",
    "\n",
    "    # pad the front so that output shape stays (T, N)\n",
    "    pad = period - 1\n",
    "    padded = torch.nn.functional.pad(series.T.unsqueeze(1), (pad, 0), mode='replicate')  # (N, 1, T + pad)\n",
    "\n",
    "    # unfold to get rolling windows\n",
    "    unfolded = padded.unfold(dimension=2, size=period, step=1)  # (N, 1, T, period)\n",
    "    \n",
    "    # calc std over last dim (window)\n",
    "    std = unfolded.std(dim=-1)  # (N, 1, T)\n",
    "    \n",
    "    return std.squeeze(1).T  # -> (T, N)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def rolling_windows(x: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"Helper to create rolling windows: shape (T - period + 1, period, N)\"\"\"\n",
    "    if x.ndim == 1:\n",
    "        x = x.unsqueeze(-1)\n",
    "    x = x.T.unsqueeze(0)  # (1, N, T)\n",
    "    x = F.pad(x, (period - 1, 0), mode='replicate')\n",
    "    x = x.unfold(dimension=2, size=period, step=1)  # (1, N, T, period)\n",
    "    return x.squeeze(0).permute(2, 3, 0)  # (T, period, N)\n",
    "\n",
    "def kurtosis(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates rolling kurtosis using PyTorch operations.\n",
    "    Args:\n",
    "        series: (T, N)\n",
    "        period: Rolling window size\n",
    "    Returns:\n",
    "        Tensor of same shape as input with rolling kurtosis values\n",
    "    \"\"\"\n",
    "    kurtosis = torch.zeros_like(series)\n",
    "    \n",
    "    # Need at least 4 points to calculate kurtosis\n",
    "    if period < 4:\n",
    "        raise ValueError(\"Period must be at least 4 for kurtosis calculation\")\n",
    "    \n",
    "    # Calculate rolling kurtosis\n",
    "    for i in tqdm(range(period - 1, series.shape[0])):\n",
    "        window = series[i - period + 1:i + 1]\n",
    "        \n",
    "        # Calculate mean of the window\n",
    "        mean = torch.mean(window, dim=0)\n",
    "        \n",
    "        # Calculate the 2nd and 4th central moments\n",
    "        diff = window - mean\n",
    "        variance = torch.mean(diff ** 2, dim=0)\n",
    "        fourth_moment = torch.mean(diff ** 4, dim=0)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        safe_variance = torch.where(variance == 0, torch.ones_like(variance), variance)\n",
    "        \n",
    "        # Calculate kurtosis: (m⁴/σ⁴) - 3\n",
    "        # The -3 makes the kurtosis of a normal distribution equal to 0 (excess kurtosis)\n",
    "        k = fourth_moment / (safe_variance ** 2) - 3\n",
    "        \n",
    "        kurtosis[i] = k\n",
    "    \n",
    "    return kurtosis\n",
    "\n",
    "def skewness(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates rolling skewness using PyTorch operations.\n",
    "    Args:\n",
    "        series: (T, N)\n",
    "        period: Rolling window size\n",
    "    Returns:\n",
    "        Tensor of same shape as input with rolling skewness values\n",
    "    \"\"\"\n",
    "    skewness = torch.zeros_like(series)\n",
    "    \n",
    "    # Need at least 3 points to calculate skewness\n",
    "    if period < 3:\n",
    "        raise ValueError(\"Period must be at least 3 for skewness calculation\")\n",
    "    \n",
    "    # Calculate rolling skewness\n",
    "    for i in range(period - 1, series.shape[0]):\n",
    "        window = series[i - period + 1:i + 1]\n",
    "        \n",
    "        # Calculate mean of the window\n",
    "        mean = torch.mean(window, dim=0)\n",
    "        \n",
    "        # Calculate the 2nd and 3rd central moments\n",
    "        diff = window - mean\n",
    "        variance = torch.mean(diff ** 2, dim=0)\n",
    "        third_moment = torch.mean(diff ** 3, dim=0)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        std = torch.sqrt(variance)\n",
    "        safe_std = torch.where(std == 0, torch.ones_like(std), std)\n",
    "        \n",
    "        # Calculate skewness: m³/σ³\n",
    "        s = third_moment / (safe_std ** 3)\n",
    "        \n",
    "        skewness[i] = s\n",
    "    \n",
    "    return skewness\n",
    "\n",
    "def z_score(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    return (series - sma(series, period)) / stdev(series, period)\n",
    "\n",
    "def vwap(prices: torch.Tensor, volumes: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes Volume-Weighted Average Price with dynamic window handling.\n",
    "    Implements both cumulative and rolling window approaches.\n",
    "    \n",
    "    Args:\n",
    "        prices: Tensor of shape (T,) or (T, N) containing price values\n",
    "        volumes: Tensor of shape (T,) or (T, N) with corresponding volumes\n",
    "        period: Lookback window size for VWAP calculation\n",
    "        \n",
    "    Returns:\n",
    "        Tensor: VWAP values with same shape as input\n",
    "    \"\"\"\n",
    "    if prices.shape != volumes.shape:\n",
    "        raise ValueError(f\"Prices and volumes must have same shape. Got {prices.shape} vs {volumes.shape}\")\n",
    "    \n",
    "    if period <= 0:\n",
    "        raise ValueError(f\"Period must be positive, got {period}\")\n",
    "    \n",
    "    # Calculate price-volume product and cumulative sums\n",
    "    pv = prices * volumes\n",
    "    cum_pv = torch.cumsum(pv, dim=0)\n",
    "    cum_vol = torch.cumsum(volumes, dim=0)\n",
    "    \n",
    "    # Handle full-period windows using rolling difference\n",
    "    if len(prices) > period:\n",
    "        shifted_pv = torch.zeros_like(cum_pv)\n",
    "        shifted_pv[period:] = cum_pv[:-period]\n",
    "        \n",
    "        shifted_vol = torch.zeros_like(cum_vol)\n",
    "        shifted_vol[period:] = cum_vol[:-period]\n",
    "        \n",
    "        window_pv = cum_pv - shifted_pv\n",
    "        window_vol = cum_vol - shifted_vol\n",
    "    else:\n",
    "        window_pv = cum_pv\n",
    "        window_vol = cum_vol\n",
    "    \n",
    "    # Add epsilon to prevent division by zero\n",
    "    epsilon = torch.finfo(prices.dtype).eps\n",
    "    vwap_values = window_pv / (window_vol + epsilon)\n",
    "    \n",
    "    # Maintain original dtype\n",
    "    return vwap_values.to(prices.dtype)\n",
    "\n",
    "\n",
    "def rsi(close_log: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the Relative Strength Index (RSI) of a time series.\n",
    "\n",
    "    Args:\n",
    "        close_log: Tensor of shape (T, N) containing price values\n",
    "        period: Lookback window size for RSI calculation\n",
    "        \n",
    "    Returns:\n",
    "        Tensor: RSI values with same shape as input\n",
    "    \"\"\"\n",
    "    T, N = close_log.shape\n",
    "\n",
    "    delta = close_log[1:] - close_log[:-1]  # (T-1, N)\n",
    "\n",
    "    gain = torch.clamp(delta, min=0)\n",
    "    loss = -torch.clamp(delta, max=0)\n",
    "\n",
    "    avg_gain = torch.zeros((T - 1, N), device=close_log.device)\n",
    "    avg_loss = torch.zeros((T - 1, N), device=close_log.device)\n",
    "\n",
    "    avg_gain[period - 1] = gain[:period].mean(dim=0)\n",
    "    avg_loss[period - 1] = loss[:period].mean(dim=0)\n",
    "\n",
    "    for t in range(period, T - 1):\n",
    "        avg_gain[t] = (avg_gain[t - 1] * (period - 1) + gain[t]) / period\n",
    "        avg_loss[t] = (avg_loss[t - 1] * (period - 1) + loss[t]) / period\n",
    "\n",
    "    rs = avg_gain / (avg_loss + 1e-8)\n",
    "    rsi = 100 - 100 / (1 + rs)\n",
    "\n",
    "    # Padding to match the input length\n",
    "    rsi_full = torch.zeros((T, N), device=close_log.device)\n",
    "    rsi_full[period:] = rsi[period - 1:]  # first period values are default 0\n",
    "\n",
    "    return rsi_full\n",
    "\n",
    "# from pyriemann.utils.covariance import covariance_mest\n",
    "\n",
    "# def _corr_from_cov(cov: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Convert covariance matrix to correlation matrix.\n",
    "\n",
    "#     Args:\n",
    "#         cov (torch.Tensor): Covariance matrix of shape (N, N)\n",
    "    \n",
    "#     Returns:\n",
    "#         torch.Tensor: Correlation matrix of shape (N, N)\n",
    "#     \"\"\"\n",
    "#     # Compute standard deviations\n",
    "#     std = torch.sqrt(torch.diag(cov))  # (N,)\n",
    "\n",
    "#     # Outer product to build denominator matrix\n",
    "#     denom = std.unsqueeze(0) * std.unsqueeze(1)  # (N, N)\n",
    "\n",
    "#     # Avoid division by zero (small epsilon)\n",
    "#     eps = torch.finfo(cov.dtype).eps\n",
    "#     denom = denom.clamp(min=eps)\n",
    "\n",
    "#     # Normalize\n",
    "#     corr = cov / denom\n",
    "\n",
    "#     # Clamp final output between -1 and 1 (for safety)\n",
    "#     corr = corr.clamp(-1.0, 1.0)\n",
    "    \n",
    "#     return corr\n",
    "\n",
    "def _corr_from_cov(cov: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Преобразование ковариационной матрицы в корреляционную\"\"\"\n",
    "    std = torch.sqrt(torch.diag(cov))\n",
    "    return cov / (std[:, None] * std[None, :])\n",
    "\n",
    "\n",
    "# def rolling_tyler_correlation(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Calculates rolling Tyler correlation and flattens upper triangle of correlation matrix.\n",
    "#     Args:\n",
    "#         series: (T, N) tensor where T — time, N — different series (columns).\n",
    "#         period: Rolling window size.\n",
    "#     Returns:\n",
    "#         Tensor of shape (T, N*(N-1)//2) with flattened correlations only\n",
    "#     \"\"\"\n",
    "#     # Need at least 2 points to calculate correlation\n",
    "#     if period < 2:\n",
    "#         raise ValueError(\"Period must be at least 2 for correlation calculation\")\n",
    "    \n",
    "#     n_features = series.shape[1]\n",
    "#     triu_indices = torch.triu_indices(n_features, n_features, offset=1)\n",
    "#     n_corr_features = triu_indices.shape[1]\n",
    "    \n",
    "#     # Initialize output tensor with zeros\n",
    "#     correlations = torch.zeros((series.shape[0], n_corr_features), \n",
    "#                              device=series.device)\n",
    "    \n",
    "#     for i in tqdm(range(period - 1, series.shape[0])):\n",
    "#         window = series[i - period + 1:i + 1]\n",
    "#         cov = covariance_mest(window, m_estimator='tyl')\n",
    "#         corr = _corr_from_cov(cov)\n",
    "        \n",
    "#         # Flatten upper triangle of correlation matrix\n",
    "#         correlations[i] = corr[triu_indices[0], triu_indices[1]]\n",
    "    \n",
    "#     return correlations\n",
    "\n",
    "def rolling_correlation(series: torch.Tensor, period: int, func: callable) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates rolling Tyler correlation using pure PyTorch operations.\n",
    "    Args:\n",
    "        series: (T, N) tensor where T — time, N — different series (columns).\n",
    "        period: Rolling window size.\n",
    "    Returns:\n",
    "        Tensor of shape (T, N*(N-1)//2) with flattened correlations\n",
    "    \"\"\"\n",
    "    if period < 2:\n",
    "        raise ValueError(\"Period must be at least 2 for correlation calculation\")\n",
    "\n",
    "    device = series.device\n",
    "    n_features = series.size(1)\n",
    "    triu_indices = torch.triu_indices(n_features, n_features, offset=1)\n",
    "    \n",
    "    # Инициализируем выходной тензор\n",
    "    correlations = torch.zeros((series.size(0), triu_indices.size(1)), device=device)\n",
    "\n",
    "    for i in tqdm(range(period-1, series.size(0))):\n",
    "        window = series[i-period+1:i+1]\n",
    "        \n",
    "        window_centered = window - window.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        cov = func(window_centered)\n",
    "        corr = _corr_from_cov(cov)\n",
    "        \n",
    "        # upper triangle\n",
    "        correlations[i] = corr[triu_indices[0], triu_indices[1]]\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def _tyler_covariance_pytorch(X: torch.Tensor, max_iter=100, tol=1e-6) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Implementation of Tyler's M-estimator in PyTorch\n",
    "    \"\"\"\n",
    "    n, p = X.size()\n",
    "    cov = torch.eye(p, device=X.device)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        inv_cov = torch.linalg.pinv(cov)\n",
    "        dist = torch.einsum('ni,ij,nj->n', X, inv_cov, X)\n",
    "        weights = p / dist\n",
    "        new_cov = (X * weights[:, None]).T @ X / n\n",
    "        new_cov = new_cov / torch.trace(new_cov) * p\n",
    "        \n",
    "        if torch.norm(new_cov - cov) < tol:\n",
    "            break\n",
    "        cov = new_cov\n",
    "    \n",
    "    return cov\n",
    "\n",
    "def _simple_shrinkage(X: torch.Tensor, shrinkage: float = 0.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Implementation of simple shrinkage covariance estimator in PyTorch\n",
    "    Useless for boostings, yes\n",
    "\n",
    "    Formula:\n",
    "    $$\n",
    "    \\hat{\\Sigma} = (1 - \\lambda) \\hat{\\Sigma} + \\lambda \\text{diag}(\\hat{\\Sigma})\n",
    "    $$\n",
    "\n",
    "    Args:\n",
    "        X: (n, p) tensor where n — time samples, p — features.\n",
    "        shrinkage: Shrinkage parameter [0, 1].\n",
    "    Returns:\n",
    "        Covariance matrix with shrinkage (p, p)\n",
    "    \"\"\"\n",
    "    n, p = X.size()\n",
    "    \n",
    "    # Compute sample covariance matrix\n",
    "    X_centered = X - X.mean(dim=0, keepdim=True)\n",
    "    S = (X_centered.T @ X_centered) / (n - 1)  # Unbiased estimator\n",
    "    \n",
    "    # Compute target matrix (diagonal of variances)\n",
    "    variances = torch.diag(S)\n",
    "    T = torch.diag(variances)\n",
    "    \n",
    "    # Apply shrinkage\n",
    "    shrunk_cov = (1 - shrinkage) * S + shrinkage * T\n",
    "    \n",
    "    # Ensure numerical stability and symmetry\n",
    "    shrunk_cov = 0.5 * (shrunk_cov + shrunk_cov.T)\n",
    "    return shrunk_cov\n",
    "def rolling_min(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the rolling minimum of a time series.\n",
    "    \"\"\"\n",
    "    min_vals = torch.zeros_like(series)\n",
    "    for i in tqdm(range(period-1, series.size(0))):\n",
    "        window = series[i-period+1:i+1]\n",
    "        min_val = window.min(dim=0).values  # Extract values from named tuple\n",
    "        min_vals[i] = min_val\n",
    "    return min_vals\n",
    "\n",
    "def rolling_max(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the rolling maximum of a time series.\n",
    "    \"\"\"\n",
    "    max_vals = torch.zeros_like(series)\n",
    "    for i in tqdm(range(period-1, series.size(0))):\n",
    "        window = series[i-period+1:i+1]\n",
    "        max_val = window.max(dim=0).values  # Extract values from named tuple\n",
    "        max_vals[i] = max_val\n",
    "    return max_vals\n",
    "\n",
    "def stochastic_osciallator(series: torch.Tensor, period: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the stochastic oscillator of a time series.\n",
    "    \"\"\"\n",
    "    low = rolling_min(series, period)\n",
    "    high = rolling_max(series, period)\n",
    "    return (series - low) / (high - low)\n",
    "\n",
    "class Winsorizer:\n",
    "    def __init__(self, factor: float = 0.01):\n",
    "        self.factor = factor\n",
    "\n",
    "    def fit(self, x: torch.Tensor, step: int = 1000):\n",
    "        self.lower_bound = x[::step].quantile(self.factor, dim=0)\n",
    "        self.upper_bound = x[::step].quantile(1 - self.factor, dim=0)\n",
    "\n",
    "    def transform(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.clamp(x, min=self.lower_bound, max=self.upper_bound)\n",
    "\n",
    "\n",
    "class GlobalTimeFeatures:\n",
    "    def __init__(self, timestamp: torch.Tensor):\n",
    "        # Convert timestamp tensor to datetime objects\n",
    "        self.datetime = np.array([\n",
    "            datetime.fromtimestamp(ts.item())\n",
    "            for ts in timestamp / 10**9\n",
    "        ])\n",
    "    \n",
    "    def day_of_week(self) -> torch.Tensor:\n",
    "        # Returns tensor with values 0 (Monday) through 6 (Sunday)\n",
    "        return torch.tensor([\n",
    "            dt.weekday() \n",
    "            for dt in self.datetime\n",
    "        ], dtype=torch.long).unsqueeze(-1)\n",
    "    \n",
    "    def day_of_month(self) -> torch.Tensor:\n",
    "        # Returns tensor with values 1-31\n",
    "        return torch.tensor([\n",
    "            dt.day \n",
    "            for dt in self.datetime\n",
    "        ], dtype=torch.long).unsqueeze(-1)\n",
    "    \n",
    "    def month_of_year(self) -> torch.Tensor:\n",
    "        # Returns tensor with values 1-12\n",
    "        return torch.tensor([\n",
    "            dt.month \n",
    "            for dt in self.datetime\n",
    "        ], dtype=torch.long).unsqueeze(-1)\n",
    "    \n",
    "    def hour_of_day(self) -> torch.Tensor:\n",
    "        # Returns tensor with values 0-23\n",
    "        return torch.tensor([\n",
    "            dt.hour \n",
    "            for dt in self.datetime\n",
    "        ], dtype=torch.long).unsqueeze(-1)\n",
    "    \n",
    "    def minute_of_hour(self) -> torch.Tensor:\n",
    "        # Returns tensor with values 0-59\n",
    "        return torch.tensor([\n",
    "            dt.minute \n",
    "            for dt in self.datetime\n",
    "        ], dtype=torch.long).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA with bar plot visualization\n",
    "\n",
    "# n_components = 6\n",
    "# pca = PCA(n_components=n_components)\n",
    "# pca.fit(np.diff(ts_filled, axis=0))\n",
    "# # Create bar plot for explained variance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bars = plt.bar(\n",
    "#     range(1, n_components + 1), \n",
    "#     pca.explained_variance_ratio_,\n",
    "#     color='skyblue',\n",
    "#     edgecolor='black'\n",
    "# )\n",
    "\n",
    "# # Add value labels on top of each bar\n",
    "# for bar in bars:\n",
    "#     height = bar.get_height()\n",
    "#     plt.text(\n",
    "#         bar.get_x() + bar.get_width()/2., \n",
    "#         height,\n",
    "#         f'{height:.2f}',\n",
    "#         ha='center',\n",
    "#         va='bottom'\n",
    "#     )\n",
    "\n",
    "# # Add plot labels and title\n",
    "# plt.xlabel('Principal Component')\n",
    "# plt.ylabel('Explained Variance Ratio')\n",
    "# plt.title('Explained Variance Ratio by Principal Components')\n",
    "# plt.xticks(range(1, 7))\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_filled.cumsum(axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decompose time series into trend, seasonal, and residual components\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# # Decompose original time series\n",
    "# decomp_original = seasonal_decompose(ts_filled, period=60*24, model='additive')  # daily period\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(411)\n",
    "# plt.plot(ts_filled, label='Original')\n",
    "# plt.legend()\n",
    "# plt.subplot(412)\n",
    "# plt.plot(decomp_original.trend, label='Trend')\n",
    "# plt.legend()\n",
    "# plt.subplot(413)\n",
    "# plt.plot(decomp_original.seasonal, label='Seasonal')\n",
    "# plt.legend()\n",
    "# plt.subplot(414)\n",
    "# plt.plot(decomp_original.resid, label='Residual')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Decompose cumulative sum time series\n",
    "# decomp_cumsum = seasonal_decompose(ts_filled.cumsum(axis=0), period=60*24, model='additive')\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(411)\n",
    "# plt.plot(ts_filled.cumsum(axis=0), label='Cumulative Sum')\n",
    "# plt.legend()\n",
    "# plt.subplot(412)\n",
    "# plt.plot(decomp_cumsum.trend, label='Trend')\n",
    "# plt.legend()\n",
    "# plt.subplot(413)\n",
    "# plt.plot(decomp_cumsum.seasonal, label='Seasonal')\n",
    "# plt.legend()\n",
    "# plt.subplot(414)\n",
    "# plt.plot(decomp_cumsum.resid, label='Residual')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Decompose original time series\n",
    "# decomp_original = seasonal_decompose(ts_pca, period=60*24, model='additive')  # daily period\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(411)\n",
    "# plt.plot(ts_filled, label='Original')\n",
    "# plt.legend()\n",
    "# plt.subplot(412)\n",
    "# plt.plot(decomp_original.trend, label='Trend')\n",
    "# plt.legend()\n",
    "# plt.subplot(413)\n",
    "# plt.plot(decomp_original.seasonal, label='Seasonal')\n",
    "# plt.legend()\n",
    "# plt.subplot(414)\n",
    "# plt.plot(decomp_original.resid, label='Residual')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Decompose original time series\n",
    "# decomp_original = seasonal_decompose(ts_pca.cumsum(axis=0), period=60*24, model='additive')  # daily period\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# plt.subplot(411)\n",
    "# plt.plot(ts_filled, label='Original')\n",
    "# plt.legend()\n",
    "# plt.subplot(412)\n",
    "# plt.plot(decomp_original.trend, label='Trend')\n",
    "# plt.legend()\n",
    "# plt.subplot(413)\n",
    "# plt.plot(decomp_original.seasonal, label='Seasonal')\n",
    "# plt.legend()\n",
    "# plt.subplot(414)\n",
    "# plt.plot(decomp_original.resid, label='Residual')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No significant seasonals or cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_filled_tensor = torch.tensor(ts_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = torch.tensor(nan_mask).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time features\n",
    "\n",
    "_time_extractor = GlobalTimeFeatures(time_.to_numpy().reshape(-1, 1))\n",
    "day_of_week = _time_extractor.day_of_week() / 6\n",
    "day_of_month = _time_extractor.day_of_month() / 31\n",
    "month_of_year = _time_extractor.month_of_year() / 12\n",
    "hour_of_day = _time_extractor.hour_of_day() / 23\n",
    "minute_of_hour = _time_extractor.minute_of_hour() / 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_filled = torch.tensor(ts_filled)\n",
    "\n",
    "# Momentum features\n",
    "mom_1m = change(ts_filled, 1)\n",
    "mom_5m = change(ts_filled, 5)\n",
    "mom_1h = change(ts_filled, 60)\n",
    "mom_2h = change(ts_filled, 2*60)\n",
    "mom_3h = change(ts_filled, 3*60)\n",
    "mom_4h = change(ts_filled, 4*60)\n",
    "mom_1d = change(ts_filled, 60*24)\n",
    "mom_1w = change(ts_filled, 60*24*7)\n",
    "mom_1mo = change(ts_filled, 60*24*30)\n",
    "\n",
    "# Volatility features\n",
    "real_vol_1h = stdev(mom_1m, 60)\n",
    "real_vol_2h = stdev(mom_1m, 2*60)\n",
    "real_vol_3h = stdev(mom_1m, 3*60)\n",
    "real_vol_1d = stdev(mom_1m, 60*24)\n",
    "real_vol_1w = stdev(mom_1m, 60*24*7)\n",
    "\n",
    "# EMA features\n",
    "_ema_1h_values = ema(ts_filled, 60)\n",
    "_ema_2h_values = ema(ts_filled, 2*60)\n",
    "_ema_3h_values = ema(ts_filled, 3*60)\n",
    "_ema_4h_values = ema(ts_filled, 4*60)\n",
    "_ema_1d_values = ema(ts_filled, 60*24)\n",
    "_ema_7d_values = ema(ts_filled, 60*24*7)\n",
    "\n",
    "ema_1h_slope = torch.diff(_ema_1h_values)\n",
    "ema_2h_slope = torch.diff(_ema_2h_values)\n",
    "ema_3h_slope = torch.diff(_ema_3h_values)\n",
    "ema_4h_slope = torch.diff(_ema_4h_values)\n",
    "ema_1d_slope = torch.diff(_ema_1d_values)\n",
    "ema_7d_slope = torch.diff(_ema_7d_values)\n",
    "\n",
    "ema_1h_minus_sensor = _ema_1h_values - ts_filled\n",
    "ema_2h_minus_sensor = _ema_2h_values - ts_filled\n",
    "ema_3h_minus_sensor = _ema_3h_values - ts_filled\n",
    "ema_4h_minus_sensor = _ema_4h_values - ts_filled\n",
    "ema_1d_minus_sensor = _ema_1d_values - ts_filled\n",
    "ema_7d_minus_sensor = _ema_7d_values - ts_filled\n",
    "\n",
    "sma_ema_diff_1h = sma(ts_filled, 60) - _ema_1h_values\n",
    "sma_ema_diff_2h = sma(ts_filled, 2*60) - _ema_2h_values\n",
    "sma_ema_diff_3h = sma(ts_filled, 3*60) - _ema_3h_values\n",
    "sma_ema_diff_4h = sma(ts_filled, 4*60) - _ema_4h_values\n",
    "sma_ema_diff_1d = sma(ts_filled, 60*24) - _ema_1d_values\n",
    "sma_ema_diff_7d = sma(ts_filled, 60*24*7) - _ema_7d_values\n",
    "\n",
    "# MACD features\n",
    "macd_1h_2h = _ema_1h_values - _ema_2h_values\n",
    "macd_1h_3h = _ema_1h_values - _ema_3h_values\n",
    "macd_1h_4h = _ema_1h_values - _ema_4h_values\n",
    "macd_1h_1d = _ema_1h_values - _ema_1d_values\n",
    "macd_1h_7d = _ema_1h_values - _ema_7d_values\n",
    "macd_2h_3h = _ema_2h_values - _ema_3h_values\n",
    "macd_2h_4h = _ema_2h_values - _ema_4h_values\n",
    "macd_2h_1d = _ema_2h_values - _ema_1d_values\n",
    "macd_2h_7d = _ema_2h_values - _ema_7d_values\n",
    "macd_3h_4h = _ema_3h_values - _ema_4h_values\n",
    "macd_3h_1d = _ema_3h_values - _ema_1d_values\n",
    "macd_3h_7d = _ema_3h_values - _ema_7d_values\n",
    "macd_4h_1d = _ema_4h_values - _ema_1d_values\n",
    "macd_4h_7d = _ema_4h_values - _ema_7d_values\n",
    "macd_1d_7d = _ema_1d_values - _ema_7d_values\n",
    "\n",
    "# Correlation features\n",
    "rob_est_corr_12h = rolling_correlation(ts_filled.float(), 60*12, _simple_shrinkage)\n",
    "rob_est_corr_7d = rolling_correlation(ts_filled.float(), 60*24*7, _simple_shrinkage)\n",
    "\n",
    "# Statistical features\n",
    "skewness_1d = skewness(ts_filled, 60*24)\n",
    "skewness_1w = skewness(ts_filled, 60*24*7)\n",
    "kurtosis_1d = kurtosis(ts_filled, 60*24)\n",
    "kurtosis_1w = kurtosis(ts_filled, 60*24*7)\n",
    "\n",
    "# RSI features\n",
    "rsi_1h = rsi(ts_filled, 60)\n",
    "rsi_2h = rsi(ts_filled, 2*60)\n",
    "rsi_3h = rsi(ts_filled, 3*60)\n",
    "rsi_4h = rsi(ts_filled, 4*60)\n",
    "rsi_1d = rsi(ts_filled, 60*24)\n",
    "rsi_1w = rsi(ts_filled, 60*24*7)\n",
    "\n",
    "# Stochastic features\n",
    "stochastic_1h = stochastic_osciallator(ts_filled, 60)\n",
    "stochastic_2h = stochastic_osciallator(ts_filled, 2*60)\n",
    "stochastic_3h = stochastic_osciallator(ts_filled, 3*60)\n",
    "stochastic_4h = stochastic_osciallator(ts_filled, 4*60)\n",
    "stochastic_1d = stochastic_osciallator(ts_filled, 60*24)\n",
    "stochastic_1w = stochastic_osciallator(ts_filled, 60*24*7)\n",
    "stochastic_1mo = stochastic_osciallator(ts_filled, 60*24*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938312/938312 [00:10<00:00, 86019.25it/s]\n",
      "100%|██████████| 938312/938312 [00:11<00:00, 81567.71it/s]\n",
      "100%|██████████| 938252/938252 [00:10<00:00, 85387.03it/s]\n",
      "100%|██████████| 938252/938252 [00:10<00:00, 86131.86it/s]\n",
      "100%|██████████| 938192/938192 [00:11<00:00, 85147.01it/s]\n",
      "100%|██████████| 938192/938192 [00:10<00:00, 86610.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RSI features\n",
    "rsi_1h = rsi(ts_filled, 60)\n",
    "rsi_2h = rsi(ts_filled, 2*60)\n",
    "rsi_3h = rsi(ts_filled, 3*60)\n",
    "rsi_4h = rsi(ts_filled, 4*60)\n",
    "rsi_1d = rsi(ts_filled, 60*24)\n",
    "rsi_1w = rsi(ts_filled, 60*24*7)\n",
    "\n",
    "# Stochastic features\n",
    "stochastic_1h = stochastic_osciallator(ts_filled, 60)\n",
    "stochastic_2h = stochastic_osciallator(ts_filled, 2*60)\n",
    "stochastic_3h = stochastic_osciallator(ts_filled, 3*60)\n",
    "stochastic_4h = stochastic_osciallator(ts_filled, 4*60)\n",
    "stochastic_1d = stochastic_osciallator(ts_filled, 60*24)\n",
    "stochastic_1w = stochastic_osciallator(ts_filled, 60*24*7)\n",
    "stochastic_1mo = stochastic_osciallator(ts_filled, 60*24*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nans_in_hour = sma(nan_mask, 60) / 6 * 10\n",
    "# nans_in_day = sma(nan_mask, 60*24) / 6 * 10\n",
    "# nans_in_week = sma(nan_mask, 60*24*7) / 6 * 10\n",
    "# nans_in_month = sma(nan_mask, 60*24*30) / 6 * 10\n",
    "# total_nans_in_hour = torch.sum(nans_in_hour, dim=1, keepdim=True)\n",
    "# total_nans_in_day = torch.sum(nans_in_day, dim=1, keepdim=True)\n",
    "# total_nans_in_week = torch.sum(nans_in_week, dim=1, keepdim=True)\n",
    "# total_nans_in_month = torch.sum(nans_in_month, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kurtosis_1w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Features that require normalization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m features_need_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Momentum features\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     mom_1m, mom_5m, mom_1h, mom_4h, mom_1d, mom_1w, mom_1mo,\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# EMA features\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     ema_1h_slope, ema_1h_minus_sensor,\n\u001b[1;32m      8\u001b[0m     ema_1d_slope, ema_1d_minus_sensor,\n\u001b[1;32m      9\u001b[0m     ema_4h_slope, ema_4h_minus_sensor,\n\u001b[1;32m     10\u001b[0m     ema_7d_slope, ema_7d_minus_sensor,\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# SMA-EMA differences\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     sma_ema_diff_1h, sma_ema_diff_1d, sma_ema_diff_4h, sma_ema_diff_7d,\n\u001b[1;32m     14\u001b[0m     \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Volatility features\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     real_vol_1h, real_vol_1d, real_vol_1w,\n\u001b[1;32m     17\u001b[0m     \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Statistical features\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     skewness_1d, skewness_1w,\n\u001b[0;32m---> 20\u001b[0m     kurtosis_1d, \u001b[43mkurtosis_1w\u001b[49m, \n\u001b[1;32m     21\u001b[0m     \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Correlation features\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     rob_est_corr_12h, rob_est_corr_7d,\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m     macd_1h_2h, macd_1h_3h, macd_1h_4h, macd_1h_1d, macd_1h_7d,\n\u001b[1;32m     26\u001b[0m     macd_2h_3h, macd_2h_4h, macd_2h_1d, macd_2h_7d,\n\u001b[1;32m     27\u001b[0m     macd_3h_4h, macd_3h_1d, macd_3h_7d,\n\u001b[1;32m     28\u001b[0m     macd_4h_1d, macd_4h_7d,\n\u001b[1;32m     29\u001b[0m     macd_1d_7d,\n\u001b[1;32m     30\u001b[0m     \n\u001b[1;32m     31\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Features that don't require normalization\u001b[39;00m\n\u001b[1;32m     34\u001b[0m features_no_need_for_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# RSI features\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     rsi_1h, rsi_2h, rsi_3h, rsi_4h, rsi_1d, rsi_1w,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     stochastic_4h, stochastic_1d, stochastic_1w, stochastic_1mo\n\u001b[1;32m     44\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kurtosis_1w' is not defined"
     ]
    }
   ],
   "source": [
    "# Features that require normalization\n",
    "features_need_norm = torch.cat([\n",
    "    # Momentum features\n",
    "    mom_1m, mom_5m, mom_1h, mom_4h, mom_1d, mom_1w, mom_1mo,\n",
    "    \n",
    "    # EMA features\n",
    "    ema_1h_slope, ema_1h_minus_sensor,\n",
    "    ema_1d_slope, ema_1d_minus_sensor,\n",
    "    ema_4h_slope, ema_4h_minus_sensor,\n",
    "    ema_7d_slope, ema_7d_minus_sensor,\n",
    "    \n",
    "    # SMA-EMA differences\n",
    "    sma_ema_diff_1h, sma_ema_diff_1d, sma_ema_diff_4h, sma_ema_diff_7d,\n",
    "    \n",
    "    # Volatility features\n",
    "    real_vol_1h, real_vol_1d, real_vol_1w,\n",
    "    \n",
    "    # Statistical features\n",
    "    skewness_1d, skewness_1w,\n",
    "    kurtosis_1d, kurtosis_1w, \n",
    "    \n",
    "    # Correlation features\n",
    "    rob_est_corr_12h, rob_est_corr_7d,\n",
    "\n",
    "    macd_1h_2h, macd_1h_3h, macd_1h_4h, macd_1h_1d, macd_1h_7d,\n",
    "    macd_2h_3h, macd_2h_4h, macd_2h_1d, macd_2h_7d,\n",
    "    macd_3h_4h, macd_3h_1d, macd_3h_7d,\n",
    "    macd_4h_1d, macd_4h_7d,\n",
    "    macd_1d_7d,\n",
    "    \n",
    "], dim=1)\n",
    "\n",
    "# Features that don't require normalization\n",
    "features_no_need_for_norm = torch.cat([\n",
    "    # RSI features\n",
    "    rsi_1h, rsi_2h, rsi_3h, rsi_4h, rsi_1d, rsi_1w,\n",
    "    # Time features\n",
    "    minute_of_hour, hour_of_day,\n",
    "    day_of_month, month_of_year, day_of_week,\n",
    "    \n",
    "    # Stochastic features\n",
    "    stochastic_1h, stochastic_2h, stochastic_3h, \n",
    "    stochastic_4h, stochastic_1d, stochastic_1w, stochastic_1mo\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(total_nans_in_hour[-1000:])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorization and normalizing\n",
    "- Winsorizer need to be fited on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slice_1 = slice(0, int(0.5 * data.shape[0]))\n",
    "train_slice_2 = slice(train_slice_1.stop, train_slice_1.stop + int(0.25 * data.shape[0]))\n",
    "train_slice_3 = slice(train_slice_2.stop, train_slice_2.stop + int(0.25 * data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_period = 3 * 30*24\n",
    "no_norm_features_normed = z_score(features_need_norm, Q_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('final_features_normed.npy', no_norm_features_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_norm_features_normed_filled = torch.nan_to_num(no_norm_features_normed, nan=0, posinf=0, neginf=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsorizer = Winsorizer(factor=0.005)\n",
    "winsorizer.fit(no_norm_features_normed_filled[train_slice_1], step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_norm_features_normed_winsorized = winsorizer.transform(no_norm_features_normed_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.6574, -4.9546, -4.0360, -4.0037, -5.5237, -3.9103, -3.5901, -4.3387,\n",
       "         -4.0654, -4.0481, -5.0186, -3.9423, -3.4623, -3.8775, -3.9495, -4.0038,\n",
       "         -3.4708, -3.8625, -3.0516, -3.3981, -3.4350, -3.3380, -3.1554, -3.3215,\n",
       "         -3.0756, -3.3647, -3.4468, -3.3638, -2.9032, -3.2036, -3.3443, -3.4545,\n",
       "         -3.5036, -3.4704, -3.1753, -3.2202, -3.4637, -3.3471, -3.4353, -3.3849,\n",
       "         -3.1469, -3.2338, -3.3793, -3.4994, -3.4093, -3.6312, -3.1861, -3.8739,\n",
       "         -3.9801, -4.3073, -4.3568, -4.0104, -4.0764, -3.0988, -3.2611, -3.5091,\n",
       "         -3.4392, -3.1753, -3.5410, -3.5074, -3.7276, -3.7579, -3.3306, -3.5848,\n",
       "         -3.2915, -3.2857, -3.3350, -3.4777, -3.1330, -3.7678, -3.7408, -4.0079,\n",
       "         -4.1600, -3.6185, -3.8885, -3.5711, -4.0056, -4.1462, -4.2147, -3.6708,\n",
       "         -3.9831, -3.1570, -2.8896, -3.1275, -2.9627, -3.0515, -2.9014, -3.4365,\n",
       "         -3.5682, -3.5433, -3.6272, -3.2566, -3.5041, -1.7158, -1.7110, -1.5328,\n",
       "         -1.5335, -1.7646, -1.6043, -3.3084, -3.2601, -3.4468, -3.4948, -3.2521,\n",
       "         -3.4032, -4.2292, -4.3305, -4.4940, -4.5309, -4.0352, -4.4665, -3.2222,\n",
       "         -3.4658, -3.5031, -3.4487, -3.5484, -3.5046, -3.6177, -4.0169, -4.2920,\n",
       "         -4.1086, -3.7886, -3.6254, -2.2266, -2.2192, -2.1848, -2.2786, -2.5476,\n",
       "         -2.4519, -3.7713, -3.9507, -3.6278, -3.7478, -3.5334, -3.4813, -2.4706,\n",
       "         -3.6953, -4.0045, -3.3271, -3.5784, -1.8083, -1.9449, -2.7394, -3.7384,\n",
       "         -5.2273, -3.0657, -3.2994, -3.3484, -4.4750, -3.0637, -2.6544, -2.8682,\n",
       "         -2.7507, -2.7709, -2.4725, -2.7445, -2.7477, -3.0279, -2.8374, -2.8200,\n",
       "         -3.1153, -2.8172, -3.0750, -3.3309, -3.3911, -3.1914, -3.0488, -3.0861,\n",
       "         -3.1737, -3.4646, -3.5142, -3.3823, -3.0684, -3.2290, -3.5333, -3.6615,\n",
       "         -3.8725, -3.5325, -3.7655, -3.7880, -3.6426, -3.6807, -3.6443, -3.8663,\n",
       "         -3.8891, -3.9041, -3.7102, -4.1850, -3.5893, -3.4021, -3.2794, -3.6650,\n",
       "         -3.5113, -3.2927, -3.5042, -3.4783, -3.7138, -3.7035, -3.3290, -3.6809,\n",
       "         -3.3144, -3.2757, -3.3035, -3.1519, -3.3372, -3.0237],\n",
       "        dtype=torch.float64),\n",
       " tensor([3.8139, 4.8414, 4.0908, 3.9772, 5.4196, 3.9322, 3.7876, 4.3551, 4.1390,\n",
       "         4.0514, 5.0699, 3.9853, 3.7893, 3.8931, 4.1381, 4.2747, 3.5834, 4.0256,\n",
       "         3.4486, 3.3651, 3.5163, 3.6520, 3.1490, 3.5209, 3.2842, 3.3759, 3.4030,\n",
       "         3.3288, 3.2127, 3.3615, 3.2856, 3.4438, 3.4835, 3.5303, 3.1351, 3.3722,\n",
       "         3.2663, 3.3944, 3.4746, 3.4173, 3.1359, 3.4957, 3.2411, 3.5762, 3.6889,\n",
       "         3.0750, 3.2844, 3.4743, 4.0611, 3.9878, 4.0514, 3.8398, 3.8888, 3.4064,\n",
       "         3.1993, 3.5474, 3.2398, 3.2269, 3.0662, 3.4938, 3.5014, 3.3126, 3.0546,\n",
       "         3.1839, 3.1626, 3.4209, 3.4855, 3.0248, 3.1734, 3.2776, 3.7658, 3.7300,\n",
       "         3.7526, 3.3539, 3.5885, 3.7126, 4.0450, 4.2511, 4.4766, 3.6970, 4.0596,\n",
       "         3.1953, 3.0955, 2.9083, 2.8827, 2.9068, 3.1601, 3.2705, 3.5215, 3.5862,\n",
       "         3.4655, 3.2643, 3.6788, 5.4788, 4.9647, 5.5205, 5.4505, 4.2938, 5.6481,\n",
       "         3.8449, 3.9535, 4.2506, 4.3186, 3.5549, 4.0740, 4.0362, 4.1526, 4.2254,\n",
       "         4.4469, 3.6435, 4.0171, 3.6092, 3.5543, 3.5442, 3.6679, 3.5383, 3.5641,\n",
       "         3.8144, 3.9610, 3.9420, 4.4315, 3.7232, 3.8295, 5.1530, 5.1346, 4.8547,\n",
       "         5.2638, 5.0157, 5.3746, 3.9830, 3.9068, 3.9652, 4.1993, 4.3343, 3.9938,\n",
       "         3.5177, 2.3224, 2.2772, 2.6276, 2.3342, 5.3260, 4.6659, 3.1803, 3.1446,\n",
       "         1.6232, 2.7970, 3.5059, 2.7799, 2.8311, 2.7746, 2.8217, 2.8454, 2.8803,\n",
       "         2.8899, 2.8542, 2.8901, 3.0301, 2.9334, 3.1554, 3.0481, 3.3530, 3.0559,\n",
       "         3.3959, 3.4051, 3.5381, 3.5282, 3.4823, 3.5160, 3.4669, 3.5003, 3.7355,\n",
       "         3.6900, 3.3739, 3.6286, 3.6069, 3.6006, 3.8720, 3.6249, 3.7030, 4.2155,\n",
       "         3.8310, 3.8319, 3.8014, 3.6263, 3.5688, 3.6768, 3.6416, 3.8054, 3.7399,\n",
       "         3.2472, 3.3017, 3.4385, 3.2112, 3.1246, 3.1876, 3.5242, 3.5301, 3.3941,\n",
       "         3.0714, 3.2467, 3.2294, 3.1765, 3.2466, 3.3339, 3.2468, 3.1719],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winsorizer.lower_bound, winsorizer.upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.999)\n",
    "pca.fit(no_norm_features_normed_winsorized)\n",
    "\n",
    "print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_)}\")\n",
    "print(f'number of components: {pca.n_components_}. total features: {no_norm_features_normed_winsorized.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_norm_features_normed_winsorized_pca = torch.tensor(pca.transform(no_norm_features_normed_winsorized))\n",
    "n_components = pca.n_components_\n",
    "no_norm_features_normed_winsorized_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([938372, 241])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_norm = torch.cat([\n",
    "    no_norm_features_normed_winsorized, # TODO: PCA. but practically it's not needed\n",
    "    features_no_need_for_norm,\n",
    "], dim=1)\n",
    "features_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = torch.nan_to_num(features_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([938372, 6])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.roll(mom_4h, -4*60, dims=0)\n",
    "target[-4*60:] = torch.mean(mom_4h, dim=0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare data - features and target\n",
    "X = features_norm.float().to(device)\n",
    "y = target.float().to(device)\n",
    "\n",
    "X_train_1, y_train_1 = X[train_slice_1], y[train_slice_1]\n",
    "X_train_2, y_train_2 = X[train_slice_2], y[train_slice_2]\n",
    "X_train_3, y_train_3 = X[train_slice_3], y[train_slice_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: nan\n",
      "Epoch [20/100], Loss: nan\n",
      "Epoch [30/100], Loss: nan\n",
      "Epoch [40/100], Loss: nan\n",
      "Epoch [50/100], Loss: nan\n",
      "Epoch [60/100], Loss: nan\n",
      "Epoch [70/100], Loss: nan\n",
      "Epoch [80/100], Loss: nan\n",
      "Epoch [90/100], Loss: nan\n",
      "Epoch [100/100], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression model with 63 features, 6 targets, and bias term\n",
    "linreg = torch.nn.Linear(features_norm.shape[1], target.shape[1], bias=True).to(device)  # Move model to GPU\n",
    "\n",
    "# Define Huber loss function and optimizer with L2 regularization\n",
    "criterion = torch.nn.HuberLoss().to(device)  # Move loss function to GPU\n",
    "optimizer = torch.optim.Adam(linreg.parameters(), lr=3e-2, weight_decay=0.01)  # weight_decay for L2 reg\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = linreg(X_train_1)\n",
    "    loss = criterion(outputs, y_train_1)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: nan\n",
      "Model biases (constant terms): tensor([nan, nan, nan, nan, nan, nan])\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = linreg(X_train_2)\n",
    "    test_loss = criterion(test_outputs, y_train_2)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    \n",
    "    # Print model's bias terms\n",
    "    print(\"Model biases (constant terms):\", linreg.bias.cpu())  # Move biases to CPU for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_corr(predictions, true_values):\n",
    "    for i in range(predictions.shape[1]):\n",
    "        corr = np.corrcoef(predictions.T[i], true_values.T[i])[0, 1]\n",
    "        print(f\"Correlation between prediction {i} and true value: {corr:.4f}\")\n",
    "\n",
    "def r_list(predictions, true_values):\n",
    "    return [np.corrcoef(predictions.T[i], true_values.T[i])[0, 1] for i in range(predictions.shape[1])]\n",
    "\n",
    "def r2_from_list(r_list):\n",
    "    r2_list = np.array(r_list)**2\n",
    "    return np.mean(r2_list)\n",
    "\n",
    "def r2(predictions: torch.Tensor, true_values: torch.Tensor) -> float:\n",
    "    \"\"\"Calculate R-squared (coefficient of determination) score.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Model predictions tensor of shape (n_samples, n_targets)\n",
    "        true_values: Ground truth values tensor of shape (n_samples, n_targets)\n",
    "        \n",
    "    Returns:\n",
    "        R-squared score as float. Can be negative if model performs worse than mean baseline.\n",
    "    \"\"\"\n",
    "    # Calculate sum of squared residuals\n",
    "    ss_res = torch.sum((true_values - predictions) ** 2)\n",
    "    # Calculate total sum of squares\n",
    "    ss_tot = torch.sum((true_values - torch.mean(true_values)) ** 2)\n",
    "    # Calculate R-squared\n",
    "    return (1 - ss_res / ss_tot).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R^2: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing average R^2\n",
    "linreg_pred = linreg(X_train_3)\n",
    "r2_linreg = r2(linreg_pred, y_train_3)\n",
    "print(f\"Average R^2: {r2_linreg:.4f}\")\n",
    "r2_from_list(r_list(linreg_pred.detach().cpu(), y_train_3.detach().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linreg = X_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot histograms of each feature with feature number in label\n",
    "# for i in range(X.shape[1]):\n",
    "#     plt.hist(X[:, i].cpu(), bins=100)\n",
    "#     plt.title(f'Feature {i+1} Distribution')\n",
    "#     plt.xlabel('Value')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_model(model_and_data: tuple[CatBoostRegressor, np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Helper function for parallel prediction\"\"\"\n",
    "    model, X_np = model_and_data\n",
    "    return model.predict(X_np)\n",
    "\n",
    "\n",
    "class MultiTargetCatBoost:\n",
    "    def __init__(self, base_model: CatBoostRegressor):\n",
    "        \"\"\"Initialize multi-target CatBoost model\n",
    "        \n",
    "        Args:\n",
    "            base_model: Base CatBoostRegressor model to clone for each target\n",
    "        \"\"\"\n",
    "        self.base_model = base_model\n",
    "        self.models: list[CatBoostRegressor] = []\n",
    "        \n",
    "    def _convert_tensor(self, data: torch.Tensor | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert tensor to numpy array, handling CUDA tensors\"\"\"\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            return data.cpu().numpy()\n",
    "        return data\n",
    "\n",
    "    def fit(self, \n",
    "            train_X: torch.Tensor | np.ndarray, \n",
    "            train_y: torch.Tensor | np.ndarray,\n",
    "            val_X: torch.Tensor | np.ndarray,\n",
    "            val_y: torch.Tensor | np.ndarray) -> None:\n",
    "        \"\"\"Fit separate models for each target column\n",
    "        \n",
    "        Args:\n",
    "            train_X: Training features (n_samples, n_features)\n",
    "            train_y: Training targets (n_samples, n_targets)\n",
    "            val_X: Validation features\n",
    "            val_y: Validation targets\n",
    "        \"\"\"\n",
    "        # Convert all inputs to numpy arrays\n",
    "        train_X = self._convert_tensor(train_X)\n",
    "        train_y = self._convert_tensor(train_y)\n",
    "        val_X = self._convert_tensor(val_X)\n",
    "        val_y = self._convert_tensor(val_y)\n",
    "\n",
    "        self.models = []\n",
    "        for col in tqdm(range(train_y.shape[1]), desc=\"Training models\"):\n",
    "            model = self.base_model.copy()\n",
    "            train_pool = Pool(train_X, train_y[:, col])\n",
    "            val_pool = Pool(val_X, val_y[:, col])\n",
    "            model.fit(train_pool, eval_set=val_pool)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X: torch.Tensor | np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict all target columns using multiprocessing\n",
    "        \n",
    "        Args:\n",
    "            X: Input tensor/array of shape (n_samples, n_features)\n",
    "            \n",
    "        Returns:\n",
    "            Predictions array of shape (n_samples, n_targets)\n",
    "        \"\"\"\n",
    "        X_np = self._convert_tensor(X)\n",
    "        args = [(model, X_np) for model in self.models]\n",
    "        \n",
    "        with mpPool(processes=cpu_count()) as pool:\n",
    "            preds = pool.map(_predict_model, args)\n",
    "            \n",
    "        return np.stack(preds, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 6, 15),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 20),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 20, 100),\n",
    "        'has_time': trial.suggest_categorical('has_time', [True, False])\n",
    "    }\n",
    "    \n",
    "    # Create base model with trial parameters\n",
    "    base_model = CatBoostRegressor(\n",
    "        **params,\n",
    "        task_type=\"CPU\",\n",
    "        verbose=0,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    \n",
    "    # Initialize and train multi-target model\n",
    "    model = MultiTargetCatBoost(base_model)\n",
    "    model.fit(X_train_1, y_train_1, X_train_2, y_train_2)\n",
    "    \n",
    "    # Get predictions and calculate R2\n",
    "    preds = model.predict(X_train_2)\n",
    "    preds_tensor = torch.tensor(preds).cpu().detach()\n",
    "    y_true = y_train_2.cpu().detach()\n",
    "    \n",
    "    return r2_from_list(r_list(preds_tensor, y_true))\n",
    "\n",
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1879,\n",
       " 'learning_rate': 0.0010173196627404298,\n",
       " 'depth': 12,\n",
       " 'l2_leaf_reg': 4.216030631283651,\n",
       " 'early_stopping_rounds': 52,\n",
       " 'has_time': True}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params\n",
    "\n",
    "# {'iterations': 1879,\n",
    "#  'learning_rate': 0.0010173196627404298,\n",
    "#  'depth': 12,\n",
    "#  'l2_leaf_reg': 4.216030631283651,\n",
    "#  'early_stopping_rounds': 52,\n",
    "#  'has_time': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/6 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2702804\ttest: 1.2432477\tbest: 1.2432477 (0)\ttotal: 58.8ms\tremaining: 1m 45s\n",
      "100:\tlearn: 1.2474059\ttest: 1.2283950\tbest: 1.2283950 (100)\ttotal: 2.39s\tremaining: 40.2s\n",
      "200:\tlearn: 1.2269039\ttest: 1.2161427\tbest: 1.2161427 (200)\ttotal: 4.65s\tremaining: 37s\n",
      "300:\tlearn: 1.2083479\ttest: 1.2061124\tbest: 1.2061124 (300)\ttotal: 6.92s\tremaining: 34.4s\n",
      "400:\tlearn: 1.1912048\ttest: 1.1975819\tbest: 1.1975819 (400)\ttotal: 9.19s\tremaining: 32.1s\n",
      "500:\tlearn: 1.1752148\ttest: 1.1904058\tbest: 1.1904058 (500)\ttotal: 11.5s\tremaining: 29.7s\n",
      "600:\tlearn: 1.1604179\ttest: 1.1843868\tbest: 1.1843868 (600)\ttotal: 13.8s\tremaining: 27.5s\n",
      "700:\tlearn: 1.1465957\ttest: 1.1793628\tbest: 1.1793628 (700)\ttotal: 16.1s\tremaining: 25.2s\n",
      "800:\tlearn: 1.1337850\ttest: 1.1752250\tbest: 1.1752250 (800)\ttotal: 18.3s\tremaining: 22.9s\n",
      "900:\tlearn: 1.1216625\ttest: 1.1715960\tbest: 1.1715960 (900)\ttotal: 20.6s\tremaining: 20.6s\n",
      "1000:\tlearn: 1.1099424\ttest: 1.1686577\tbest: 1.1686577 (1000)\ttotal: 22.9s\tremaining: 18.3s\n",
      "1100:\tlearn: 1.0984778\ttest: 1.1661761\tbest: 1.1661761 (1100)\ttotal: 25.2s\tremaining: 16s\n",
      "1200:\tlearn: 1.0873762\ttest: 1.1641784\tbest: 1.1641784 (1200)\ttotal: 27.6s\tremaining: 13.8s\n",
      "1300:\tlearn: 1.0763864\ttest: 1.1624058\tbest: 1.1624058 (1300)\ttotal: 30s\tremaining: 11.5s\n",
      "1400:\tlearn: 1.0655899\ttest: 1.1611368\tbest: 1.1611368 (1400)\ttotal: 32.4s\tremaining: 9.22s\n",
      "1500:\tlearn: 1.0551376\ttest: 1.1598792\tbest: 1.1598792 (1500)\ttotal: 34.8s\tremaining: 6.93s\n",
      "1600:\tlearn: 1.0451398\ttest: 1.1589493\tbest: 1.1589493 (1600)\ttotal: 37.1s\tremaining: 4.62s\n",
      "1700:\tlearn: 1.0355260\ttest: 1.1581446\tbest: 1.1581437 (1698)\ttotal: 39.5s\tremaining: 2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  17%|█▋        | 1/6 [00:43<03:35, 43.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.0267927\ttest: 1.1575522\tbest: 1.1575522 (1799)\ttotal: 41.8s\tremaining: 0us\n",
      "bestTest = 1.157552168\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3759762\ttest: 1.3740258\tbest: 1.3740258 (0)\ttotal: 23ms\tremaining: 41.3s\n",
      "100:\tlearn: 1.3477549\ttest: 1.3545268\tbest: 1.3545268 (100)\ttotal: 2.31s\tremaining: 38.8s\n",
      "200:\tlearn: 1.3233197\ttest: 1.3375560\tbest: 1.3375560 (200)\ttotal: 4.57s\tremaining: 36.3s\n",
      "300:\tlearn: 1.3013932\ttest: 1.3228842\tbest: 1.3228842 (300)\ttotal: 6.85s\tremaining: 34.1s\n",
      "400:\tlearn: 1.2815876\ttest: 1.3100702\tbest: 1.3100702 (400)\ttotal: 9.16s\tremaining: 32s\n",
      "500:\tlearn: 1.2636163\ttest: 1.2988868\tbest: 1.2988868 (500)\ttotal: 11.5s\tremaining: 29.8s\n",
      "600:\tlearn: 1.2473101\ttest: 1.2892896\tbest: 1.2892896 (600)\ttotal: 13.8s\tremaining: 27.6s\n",
      "700:\tlearn: 1.2323494\ttest: 1.2812014\tbest: 1.2812014 (700)\ttotal: 16.2s\tremaining: 25.4s\n",
      "800:\tlearn: 1.2185555\ttest: 1.2744696\tbest: 1.2744696 (800)\ttotal: 18.6s\tremaining: 23.2s\n",
      "900:\tlearn: 1.2055990\ttest: 1.2687517\tbest: 1.2687517 (900)\ttotal: 21s\tremaining: 20.9s\n",
      "1000:\tlearn: 1.1932348\ttest: 1.2640154\tbest: 1.2640154 (1000)\ttotal: 23.4s\tremaining: 18.7s\n",
      "1100:\tlearn: 1.1812578\ttest: 1.2600296\tbest: 1.2600296 (1100)\ttotal: 25.8s\tremaining: 16.4s\n",
      "1200:\tlearn: 1.1699244\ttest: 1.2568515\tbest: 1.2568515 (1200)\ttotal: 28.3s\tremaining: 14.1s\n",
      "1300:\tlearn: 1.1588254\ttest: 1.2540319\tbest: 1.2540319 (1300)\ttotal: 30.8s\tremaining: 11.8s\n",
      "1400:\tlearn: 1.1486727\ttest: 1.2517406\tbest: 1.2517406 (1400)\ttotal: 33.2s\tremaining: 9.47s\n",
      "1500:\tlearn: 1.1383278\ttest: 1.2499095\tbest: 1.2499095 (1500)\ttotal: 35.8s\tremaining: 7.12s\n",
      "1600:\tlearn: 1.1287631\ttest: 1.2482828\tbest: 1.2482828 (1600)\ttotal: 38.2s\tremaining: 4.75s\n",
      "1700:\tlearn: 1.1195967\ttest: 1.2469713\tbest: 1.2469713 (1700)\ttotal: 40.7s\tremaining: 2.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  33%|███▎      | 2/6 [01:27<02:55, 43.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.1105823\ttest: 1.2457954\tbest: 1.2457954 (1799)\ttotal: 43.2s\tremaining: 0us\n",
      "bestTest = 1.245795446\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4101234\ttest: 1.3823119\tbest: 1.3823119 (0)\ttotal: 22ms\tremaining: 39.6s\n",
      "100:\tlearn: 1.3799504\ttest: 1.3602675\tbest: 1.3602675 (100)\ttotal: 2.38s\tremaining: 40s\n",
      "200:\tlearn: 1.3535399\ttest: 1.3419015\tbest: 1.3419015 (200)\ttotal: 4.77s\tremaining: 38s\n",
      "300:\tlearn: 1.3299163\ttest: 1.3267388\tbest: 1.3267388 (300)\ttotal: 7.18s\tremaining: 35.7s\n",
      "400:\tlearn: 1.3090342\ttest: 1.3140262\tbest: 1.3140262 (400)\ttotal: 9.56s\tremaining: 33.3s\n",
      "500:\tlearn: 1.2901665\ttest: 1.3031642\tbest: 1.3031642 (500)\ttotal: 12s\tremaining: 31s\n",
      "600:\tlearn: 1.2731352\ttest: 1.2939333\tbest: 1.2939333 (600)\ttotal: 14.3s\tremaining: 28.6s\n",
      "700:\tlearn: 1.2577520\ttest: 1.2859646\tbest: 1.2859646 (700)\ttotal: 16.7s\tremaining: 26.2s\n",
      "800:\tlearn: 1.2435745\ttest: 1.2793294\tbest: 1.2793294 (800)\ttotal: 19.1s\tremaining: 23.8s\n",
      "900:\tlearn: 1.2300946\ttest: 1.2737379\tbest: 1.2737379 (900)\ttotal: 21.5s\tremaining: 21.4s\n",
      "1000:\tlearn: 1.2171140\ttest: 1.2691201\tbest: 1.2691201 (1000)\ttotal: 23.9s\tremaining: 19.1s\n",
      "1100:\tlearn: 1.2044578\ttest: 1.2654078\tbest: 1.2654078 (1100)\ttotal: 26.4s\tremaining: 16.8s\n",
      "1200:\tlearn: 1.1926196\ttest: 1.2622246\tbest: 1.2622246 (1200)\ttotal: 28.9s\tremaining: 14.4s\n",
      "1300:\tlearn: 1.1810104\ttest: 1.2595039\tbest: 1.2595039 (1300)\ttotal: 31.4s\tremaining: 12s\n",
      "1400:\tlearn: 1.1702526\ttest: 1.2571372\tbest: 1.2571372 (1400)\ttotal: 33.9s\tremaining: 9.64s\n",
      "1500:\tlearn: 1.1594588\ttest: 1.2553123\tbest: 1.2553123 (1500)\ttotal: 36.4s\tremaining: 7.26s\n",
      "1600:\tlearn: 1.1492001\ttest: 1.2537669\tbest: 1.2537669 (1599)\ttotal: 39s\tremaining: 4.85s\n",
      "1700:\tlearn: 1.1391073\ttest: 1.2523902\tbest: 1.2523902 (1700)\ttotal: 41.6s\tremaining: 2.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  50%|█████     | 3/6 [02:13<02:14, 44.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.1294551\ttest: 1.2512939\tbest: 1.2512939 (1799)\ttotal: 44.1s\tremaining: 0us\n",
      "bestTest = 1.25129386\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4012963\ttest: 1.3341606\tbest: 1.3341606 (0)\ttotal: 24.9ms\tremaining: 44.7s\n",
      "100:\tlearn: 1.3696432\ttest: 1.3124108\tbest: 1.3124108 (100)\ttotal: 2.63s\tremaining: 44.2s\n",
      "200:\tlearn: 1.3414551\ttest: 1.2943243\tbest: 1.2943243 (200)\ttotal: 5.29s\tremaining: 42.1s\n",
      "300:\tlearn: 1.3159921\ttest: 1.2791276\tbest: 1.2791276 (300)\ttotal: 7.96s\tremaining: 39.6s\n",
      "400:\tlearn: 1.2931838\ttest: 1.2661960\tbest: 1.2661960 (400)\ttotal: 10.6s\tremaining: 36.8s\n",
      "500:\tlearn: 1.2723023\ttest: 1.2554135\tbest: 1.2554135 (500)\ttotal: 13.2s\tremaining: 34.1s\n",
      "600:\tlearn: 1.2535910\ttest: 1.2461737\tbest: 1.2461737 (600)\ttotal: 15.7s\tremaining: 31.3s\n",
      "700:\tlearn: 1.2365623\ttest: 1.2386397\tbest: 1.2386397 (700)\ttotal: 18.3s\tremaining: 28.6s\n",
      "800:\tlearn: 1.2207836\ttest: 1.2319853\tbest: 1.2319853 (800)\ttotal: 20.8s\tremaining: 25.9s\n",
      "900:\tlearn: 1.2059331\ttest: 1.2265325\tbest: 1.2265325 (900)\ttotal: 23.4s\tremaining: 23.3s\n",
      "1000:\tlearn: 1.1919055\ttest: 1.2220919\tbest: 1.2220919 (1000)\ttotal: 25.9s\tremaining: 20.7s\n",
      "1100:\tlearn: 1.1786429\ttest: 1.2181553\tbest: 1.2181553 (1100)\ttotal: 28.5s\tremaining: 18.1s\n",
      "1200:\tlearn: 1.1661859\ttest: 1.2149261\tbest: 1.2149261 (1200)\ttotal: 31.1s\tremaining: 15.5s\n",
      "1300:\tlearn: 1.1541764\ttest: 1.2123973\tbest: 1.2123973 (1300)\ttotal: 33.7s\tremaining: 12.9s\n",
      "1400:\tlearn: 1.1425770\ttest: 1.2100923\tbest: 1.2100923 (1400)\ttotal: 36.3s\tremaining: 10.3s\n",
      "1500:\tlearn: 1.1312771\ttest: 1.2082887\tbest: 1.2082887 (1500)\ttotal: 38.9s\tremaining: 7.75s\n",
      "1600:\tlearn: 1.1206560\ttest: 1.2069255\tbest: 1.2069255 (1600)\ttotal: 41.5s\tremaining: 5.16s\n",
      "1700:\tlearn: 1.1100152\ttest: 1.2058229\tbest: 1.2058229 (1700)\ttotal: 44.2s\tremaining: 2.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  67%|██████▋   | 4/6 [03:01<01:32, 46.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.0997609\ttest: 1.2047878\tbest: 1.2047878 (1799)\ttotal: 46.8s\tremaining: 0us\n",
      "bestTest = 1.204787795\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3295680\ttest: 1.3530542\tbest: 1.3530542 (0)\ttotal: 21.9ms\tremaining: 39.4s\n",
      "100:\tlearn: 1.3012438\ttest: 1.3301508\tbest: 1.3301508 (100)\ttotal: 2.4s\tremaining: 40.4s\n",
      "200:\tlearn: 1.2768744\ttest: 1.3121573\tbest: 1.3121573 (200)\ttotal: 4.83s\tremaining: 38.4s\n",
      "300:\tlearn: 1.2555926\ttest: 1.2976142\tbest: 1.2976142 (300)\ttotal: 7.3s\tremaining: 36.4s\n",
      "400:\tlearn: 1.2369107\ttest: 1.2856461\tbest: 1.2856461 (400)\ttotal: 9.76s\tremaining: 34s\n",
      "500:\tlearn: 1.2204135\ttest: 1.2757011\tbest: 1.2757011 (500)\ttotal: 12.2s\tremaining: 31.6s\n",
      "600:\tlearn: 1.2056864\ttest: 1.2675080\tbest: 1.2675080 (600)\ttotal: 14.8s\tremaining: 29.5s\n",
      "700:\tlearn: 1.1924859\ttest: 1.2608088\tbest: 1.2608088 (700)\ttotal: 17.3s\tremaining: 27.1s\n",
      "800:\tlearn: 1.1805850\ttest: 1.2550185\tbest: 1.2550185 (800)\ttotal: 19.8s\tremaining: 24.7s\n",
      "900:\tlearn: 1.1693579\ttest: 1.2502196\tbest: 1.2502196 (900)\ttotal: 22.4s\tremaining: 22.3s\n",
      "1000:\tlearn: 1.1589534\ttest: 1.2461416\tbest: 1.2461416 (1000)\ttotal: 25s\tremaining: 19.9s\n",
      "1100:\tlearn: 1.1491678\ttest: 1.2428553\tbest: 1.2428553 (1100)\ttotal: 27.6s\tremaining: 17.5s\n",
      "1200:\tlearn: 1.1398129\ttest: 1.2402246\tbest: 1.2402246 (1200)\ttotal: 30.3s\tremaining: 15.1s\n",
      "1300:\tlearn: 1.1309842\ttest: 1.2380676\tbest: 1.2380676 (1300)\ttotal: 33s\tremaining: 12.6s\n",
      "1400:\tlearn: 1.1223594\ttest: 1.2362148\tbest: 1.2362148 (1400)\ttotal: 35.7s\tremaining: 10.2s\n",
      "1500:\tlearn: 1.1138860\ttest: 1.2347006\tbest: 1.2347006 (1500)\ttotal: 38.4s\tremaining: 7.65s\n",
      "1600:\tlearn: 1.1054204\ttest: 1.2334033\tbest: 1.2334033 (1600)\ttotal: 41.2s\tremaining: 5.12s\n",
      "1700:\tlearn: 1.0973641\ttest: 1.2323668\tbest: 1.2323668 (1700)\ttotal: 44s\tremaining: 2.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  83%|████████▎ | 5/6 [03:50<00:47, 47.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.0891055\ttest: 1.2314110\tbest: 1.2314110 (1799)\ttotal: 46.9s\tremaining: 0us\n",
      "bestTest = 1.231410995\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3207390\ttest: 1.2397355\tbest: 1.2397355 (0)\ttotal: 23ms\tremaining: 41.4s\n",
      "100:\tlearn: 1.2941088\ttest: 1.2216197\tbest: 1.2216197 (100)\ttotal: 2.59s\tremaining: 43.5s\n",
      "200:\tlearn: 1.2703841\ttest: 1.2067576\tbest: 1.2067576 (200)\ttotal: 5.21s\tremaining: 41.5s\n",
      "300:\tlearn: 1.2490914\ttest: 1.1947661\tbest: 1.1947661 (300)\ttotal: 7.86s\tremaining: 39.2s\n",
      "400:\tlearn: 1.2297523\ttest: 1.1851375\tbest: 1.1851375 (400)\ttotal: 10.5s\tremaining: 36.8s\n",
      "500:\tlearn: 1.2122642\ttest: 1.1769101\tbest: 1.1769101 (500)\ttotal: 13.2s\tremaining: 34.2s\n",
      "600:\tlearn: 1.1958955\ttest: 1.1700760\tbest: 1.1700760 (600)\ttotal: 15.9s\tremaining: 31.7s\n",
      "700:\tlearn: 1.1804869\ttest: 1.1645681\tbest: 1.1645681 (700)\ttotal: 18.6s\tremaining: 29.2s\n",
      "800:\tlearn: 1.1659121\ttest: 1.1598818\tbest: 1.1598818 (800)\ttotal: 21.4s\tremaining: 26.7s\n",
      "900:\tlearn: 1.1520628\ttest: 1.1560036\tbest: 1.1560036 (900)\ttotal: 24.2s\tremaining: 24.2s\n",
      "1000:\tlearn: 1.1388540\ttest: 1.1526688\tbest: 1.1526688 (1000)\ttotal: 27s\tremaining: 21.6s\n",
      "1100:\tlearn: 1.1259021\ttest: 1.1497483\tbest: 1.1497483 (1100)\ttotal: 29.9s\tremaining: 19s\n",
      "1200:\tlearn: 1.1133677\ttest: 1.1474199\tbest: 1.1474199 (1200)\ttotal: 32.8s\tremaining: 16.4s\n",
      "1300:\tlearn: 1.1012719\ttest: 1.1454508\tbest: 1.1454508 (1300)\ttotal: 35.7s\tremaining: 13.7s\n",
      "1400:\tlearn: 1.0899457\ttest: 1.1438093\tbest: 1.1438093 (1400)\ttotal: 38.5s\tremaining: 11s\n",
      "1500:\tlearn: 1.0792093\ttest: 1.1423667\tbest: 1.1423667 (1500)\ttotal: 41.3s\tremaining: 8.23s\n",
      "1600:\tlearn: 1.0686534\ttest: 1.1412490\tbest: 1.1412490 (1600)\ttotal: 44.2s\tremaining: 5.49s\n",
      "1700:\tlearn: 1.0583016\ttest: 1.1404316\tbest: 1.1404316 (1700)\ttotal: 47s\tremaining: 2.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 6/6 [04:41<00:00, 46.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1799:\tlearn: 1.0485328\ttest: 1.1398161\tbest: 1.1398161 (1799)\ttotal: 49.8s\tremaining: 0us\n",
      "bestTest = 1.139816062\n",
      "bestIteration = 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # Get best parameters and create final model\n",
    "# best_params = study.best_params\n",
    "# base_model = CatBoostRegressor(\n",
    "#     iterations=2000,\n",
    "#     learning_rate=0.001,\n",
    "#     depth=10,\n",
    "#     l2_leaf_reg=4.5,\n",
    "#     early_stopping_rounds=52,\n",
    "#     has_time=True,\n",
    "#     task_type=\"GPU\",\n",
    "#     verbose=100,\n",
    "#     use_best_model=True\n",
    "# )\n",
    "# catboost_multi_target = MultiTargetCatBoost(base_model)\n",
    "# catboost_multi_target.fit(X_train_1, y_train_1, X_train_2, y_train_2)\n",
    "\n",
    "# 0.171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/6 [00:00<?, ?it/s]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2702475\ttest: 1.2432499\tbest: 1.2432499 (0)\ttotal: 41.3ms\tremaining: 1m 22s\n",
      "100:\tlearn: 1.2433290\ttest: 1.2283809\tbest: 1.2283809 (100)\ttotal: 3.5s\tremaining: 1m 5s\n",
      "200:\tlearn: 1.2192691\ttest: 1.2160881\tbest: 1.2160881 (200)\ttotal: 6.95s\tremaining: 1m 2s\n",
      "300:\tlearn: 1.1971377\ttest: 1.2058061\tbest: 1.2058061 (300)\ttotal: 10.4s\tremaining: 58.9s\n",
      "400:\tlearn: 1.1763866\ttest: 1.1973379\tbest: 1.1973379 (400)\ttotal: 13.9s\tremaining: 55.6s\n",
      "500:\tlearn: 1.1570407\ttest: 1.1901593\tbest: 1.1901593 (500)\ttotal: 17.4s\tremaining: 52.1s\n",
      "600:\tlearn: 1.1387794\ttest: 1.1841807\tbest: 1.1841807 (600)\ttotal: 20.9s\tremaining: 48.7s\n",
      "700:\tlearn: 1.1215766\ttest: 1.1790679\tbest: 1.1790679 (700)\ttotal: 24.4s\tremaining: 45.3s\n",
      "800:\tlearn: 1.1054794\ttest: 1.1747539\tbest: 1.1747539 (800)\ttotal: 27.9s\tremaining: 41.8s\n",
      "900:\tlearn: 1.0903402\ttest: 1.1710846\tbest: 1.1710846 (900)\ttotal: 31.4s\tremaining: 38.3s\n",
      "1000:\tlearn: 1.0761900\ttest: 1.1681171\tbest: 1.1681171 (1000)\ttotal: 35s\tremaining: 34.9s\n",
      "1100:\tlearn: 1.0619460\ttest: 1.1656597\tbest: 1.1656597 (1100)\ttotal: 38.6s\tremaining: 31.6s\n",
      "1200:\tlearn: 1.0482389\ttest: 1.1636385\tbest: 1.1636385 (1200)\ttotal: 42.4s\tremaining: 28.2s\n",
      "1300:\tlearn: 1.0344176\ttest: 1.1619745\tbest: 1.1619745 (1300)\ttotal: 46.1s\tremaining: 24.8s\n",
      "1400:\tlearn: 1.0211088\ttest: 1.1605263\tbest: 1.1605263 (1400)\ttotal: 49.9s\tremaining: 21.3s\n",
      "1500:\tlearn: 1.0082729\ttest: 1.1591821\tbest: 1.1591821 (1500)\ttotal: 53.8s\tremaining: 17.9s\n",
      "1600:\tlearn: 0.9962217\ttest: 1.1582511\tbest: 1.1582511 (1600)\ttotal: 57.7s\tremaining: 14.4s\n",
      "1700:\tlearn: 0.9844435\ttest: 1.1575103\tbest: 1.1575103 (1700)\ttotal: 1m 1s\tremaining: 10.8s\n",
      "1800:\tlearn: 0.9734914\ttest: 1.1567608\tbest: 1.1567608 (1800)\ttotal: 1m 5s\tremaining: 7.23s\n",
      "1900:\tlearn: 0.9623778\ttest: 1.1561620\tbest: 1.1561618 (1899)\ttotal: 1m 9s\tremaining: 3.61s\n",
      "1999:\tlearn: 0.9518456\ttest: 1.1557830\tbest: 1.1557830 (1999)\ttotal: 1m 13s\tremaining: 0us\n",
      "bestTest = 1.155783037\n",
      "bestIteration = 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  17%|█▋        | 1/6 [01:14<06:13, 74.66s/it]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3759439\ttest: 1.3740268\tbest: 1.3740268 (0)\ttotal: 35ms\tremaining: 1m 9s\n",
      "100:\tlearn: 1.3445104\ttest: 1.3545846\tbest: 1.3545846 (100)\ttotal: 3.77s\tremaining: 1m 10s\n",
      "200:\tlearn: 1.3170288\ttest: 1.3379127\tbest: 1.3379127 (200)\ttotal: 7.49s\tremaining: 1m 7s\n",
      "300:\tlearn: 1.2920741\ttest: 1.3234816\tbest: 1.3234816 (300)\ttotal: 11.2s\tremaining: 1m 3s\n",
      "400:\tlearn: 1.2693028\ttest: 1.3107085\tbest: 1.3107085 (400)\ttotal: 15s\tremaining: 59.8s\n",
      "500:\tlearn: 1.2484689\ttest: 1.2998137\tbest: 1.2998137 (500)\ttotal: 18.8s\tremaining: 56.2s\n",
      "600:\tlearn: 1.2292970\ttest: 1.2902643\tbest: 1.2902643 (600)\ttotal: 22.6s\tremaining: 52.6s\n",
      "700:\tlearn: 1.2117494\ttest: 1.2822059\tbest: 1.2822059 (700)\ttotal: 26.4s\tremaining: 49s\n",
      "800:\tlearn: 1.1948311\ttest: 1.2753528\tbest: 1.2753528 (800)\ttotal: 30.4s\tremaining: 45.5s\n",
      "900:\tlearn: 1.1792250\ttest: 1.2697464\tbest: 1.2697464 (900)\ttotal: 34.3s\tremaining: 41.9s\n",
      "1000:\tlearn: 1.1638115\ttest: 1.2651184\tbest: 1.2651184 (1000)\ttotal: 38.3s\tremaining: 38.2s\n",
      "1100:\tlearn: 1.1492724\ttest: 1.2613272\tbest: 1.2613272 (1100)\ttotal: 42.3s\tremaining: 34.5s\n",
      "1200:\tlearn: 1.1349895\ttest: 1.2580643\tbest: 1.2580643 (1200)\ttotal: 46.3s\tremaining: 30.8s\n",
      "1300:\tlearn: 1.1210480\ttest: 1.2554370\tbest: 1.2554370 (1300)\ttotal: 50.4s\tremaining: 27.1s\n",
      "1400:\tlearn: 1.1079550\ttest: 1.2531749\tbest: 1.2531749 (1400)\ttotal: 54.4s\tremaining: 23.3s\n",
      "1500:\tlearn: 1.0949661\ttest: 1.2513000\tbest: 1.2513000 (1500)\ttotal: 58.5s\tremaining: 19.4s\n",
      "1600:\tlearn: 1.0828941\ttest: 1.2496314\tbest: 1.2496314 (1600)\ttotal: 1m 2s\tremaining: 15.6s\n",
      "1700:\tlearn: 1.0709695\ttest: 1.2482836\tbest: 1.2482836 (1700)\ttotal: 1m 6s\tremaining: 11.7s\n",
      "1800:\tlearn: 1.0597741\ttest: 1.2470201\tbest: 1.2470168 (1799)\ttotal: 1m 10s\tremaining: 7.8s\n",
      "1900:\tlearn: 1.0487464\ttest: 1.2459287\tbest: 1.2459287 (1900)\ttotal: 1m 14s\tremaining: 3.88s\n",
      "1999:\tlearn: 1.0382359\ttest: 1.2450821\tbest: 1.2450821 (1999)\ttotal: 1m 18s\tremaining: 0us\n",
      "bestTest = 1.245082091\n",
      "bestIteration = 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  33%|███▎      | 2/6 [02:35<05:12, 78.10s/it]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4100910\ttest: 1.3822996\tbest: 1.3822996 (0)\ttotal: 33.4ms\tremaining: 1m 6s\n",
      "100:\tlearn: 1.3764900\ttest: 1.3603583\tbest: 1.3603583 (100)\ttotal: 3.96s\tremaining: 1m 14s\n",
      "200:\tlearn: 1.3466284\ttest: 1.3419750\tbest: 1.3419750 (200)\ttotal: 7.88s\tremaining: 1m 10s\n",
      "300:\tlearn: 1.3199147\ttest: 1.3269218\tbest: 1.3269218 (300)\ttotal: 11.8s\tremaining: 1m 6s\n",
      "400:\tlearn: 1.2957779\ttest: 1.3140659\tbest: 1.3140659 (400)\ttotal: 15.7s\tremaining: 1m 2s\n",
      "500:\tlearn: 1.2739934\ttest: 1.3034766\tbest: 1.3034766 (500)\ttotal: 19.6s\tremaining: 58.5s\n",
      "600:\tlearn: 1.2538004\ttest: 1.2943708\tbest: 1.2943708 (600)\ttotal: 23.4s\tremaining: 54.5s\n",
      "700:\tlearn: 1.2354657\ttest: 1.2863371\tbest: 1.2863371 (700)\ttotal: 27.3s\tremaining: 50.5s\n",
      "800:\tlearn: 1.2183565\ttest: 1.2796453\tbest: 1.2796453 (800)\ttotal: 31.1s\tremaining: 46.6s\n",
      "900:\tlearn: 1.2018293\ttest: 1.2739625\tbest: 1.2739625 (900)\ttotal: 35.1s\tremaining: 42.8s\n",
      "1000:\tlearn: 1.1863554\ttest: 1.2693611\tbest: 1.2693611 (1000)\ttotal: 39s\tremaining: 38.9s\n",
      "1100:\tlearn: 1.1710991\ttest: 1.2656299\tbest: 1.2656299 (1100)\ttotal: 43s\tremaining: 35.1s\n",
      "1200:\tlearn: 1.1561956\ttest: 1.2624280\tbest: 1.2624280 (1200)\ttotal: 47s\tremaining: 31.3s\n",
      "1300:\tlearn: 1.1417559\ttest: 1.2598157\tbest: 1.2598157 (1300)\ttotal: 51.1s\tremaining: 27.5s\n",
      "1400:\tlearn: 1.1283376\ttest: 1.2575442\tbest: 1.2575442 (1400)\ttotal: 55.1s\tremaining: 23.6s\n",
      "1500:\tlearn: 1.1150250\ttest: 1.2556312\tbest: 1.2556312 (1500)\ttotal: 59.1s\tremaining: 19.7s\n",
      "1600:\tlearn: 1.1022641\ttest: 1.2541024\tbest: 1.2541024 (1600)\ttotal: 1m 3s\tremaining: 15.7s\n",
      "1700:\tlearn: 1.0896017\ttest: 1.2527424\tbest: 1.2527404 (1699)\ttotal: 1m 7s\tremaining: 11.8s\n",
      "1800:\tlearn: 1.0770297\ttest: 1.2517693\tbest: 1.2517693 (1800)\ttotal: 1m 11s\tremaining: 7.89s\n",
      "1900:\tlearn: 1.0650627\ttest: 1.2510322\tbest: 1.2510311 (1899)\ttotal: 1m 15s\tremaining: 3.93s\n",
      "1999:\tlearn: 1.0532966\ttest: 1.2504727\tbest: 1.2504727 (1999)\ttotal: 1m 19s\tremaining: 0us\n",
      "bestTest = 1.250472698\n",
      "bestIteration = 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  50%|█████     | 3/6 [03:56<03:58, 79.61s/it]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.4012506\ttest: 1.3341710\tbest: 1.3341710 (0)\ttotal: 37.2ms\tremaining: 1m 14s\n",
      "100:\tlearn: 1.3650603\ttest: 1.3128976\tbest: 1.3128976 (100)\ttotal: 4.26s\tremaining: 1m 20s\n",
      "200:\tlearn: 1.3322288\ttest: 1.2953341\tbest: 1.2953341 (200)\ttotal: 8.56s\tremaining: 1m 16s\n",
      "300:\tlearn: 1.3021540\ttest: 1.2802145\tbest: 1.2802145 (300)\ttotal: 12.9s\tremaining: 1m 12s\n",
      "400:\tlearn: 1.2752217\ttest: 1.2672746\tbest: 1.2672746 (400)\ttotal: 17s\tremaining: 1m 7s\n",
      "500:\tlearn: 1.2507796\ttest: 1.2565787\tbest: 1.2565787 (500)\ttotal: 21.2s\tremaining: 1m 3s\n",
      "600:\tlearn: 1.2285632\ttest: 1.2471218\tbest: 1.2471218 (600)\ttotal: 25.2s\tremaining: 58.7s\n",
      "700:\tlearn: 1.2077396\ttest: 1.2394300\tbest: 1.2394300 (700)\ttotal: 29.3s\tremaining: 54.4s\n",
      "800:\tlearn: 1.1887160\ttest: 1.2329099\tbest: 1.2329099 (800)\ttotal: 33.4s\tremaining: 50s\n",
      "900:\tlearn: 1.1706819\ttest: 1.2273680\tbest: 1.2273680 (900)\ttotal: 37.4s\tremaining: 45.7s\n",
      "1000:\tlearn: 1.1536260\ttest: 1.2227422\tbest: 1.2227422 (1000)\ttotal: 41.5s\tremaining: 41.4s\n",
      "1100:\tlearn: 1.1375211\ttest: 1.2187417\tbest: 1.2187417 (1100)\ttotal: 45.6s\tremaining: 37.2s\n",
      "1200:\tlearn: 1.1217574\ttest: 1.2155634\tbest: 1.2155634 (1200)\ttotal: 49.7s\tremaining: 33.1s\n",
      "1300:\tlearn: 1.1071545\ttest: 1.2130556\tbest: 1.2130556 (1300)\ttotal: 53.8s\tremaining: 28.9s\n",
      "1400:\tlearn: 1.0931709\ttest: 1.2108223\tbest: 1.2108223 (1400)\ttotal: 57.8s\tremaining: 24.7s\n",
      "1500:\tlearn: 1.0791065\ttest: 1.2090449\tbest: 1.2090449 (1500)\ttotal: 1m 1s\tremaining: 20.6s\n",
      "1600:\tlearn: 1.0657621\ttest: 1.2074326\tbest: 1.2074326 (1600)\ttotal: 1m 5s\tremaining: 16.4s\n",
      "1700:\tlearn: 1.0526113\ttest: 1.2063273\tbest: 1.2063273 (1700)\ttotal: 1m 10s\tremaining: 12.3s\n",
      "1800:\tlearn: 1.0399386\ttest: 1.2053587\tbest: 1.2053587 (1800)\ttotal: 1m 14s\tremaining: 8.19s\n",
      "1900:\tlearn: 1.0276826\ttest: 1.2045244\tbest: 1.2045244 (1900)\ttotal: 1m 18s\tremaining: 4.07s\n",
      "1999:\tlearn: 1.0160202\ttest: 1.2037448\tbest: 1.2037448 (1999)\ttotal: 1m 22s\tremaining: 0us\n",
      "bestTest = 1.203744755\n",
      "bestIteration = 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  67%|██████▋   | 4/6 [05:20<02:42, 81.33s/it]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3295494\ttest: 1.3530582\tbest: 1.3530582 (0)\ttotal: 32.9ms\tremaining: 1m 5s\n",
      "100:\tlearn: 1.2993107\ttest: 1.3300837\tbest: 1.3300837 (100)\ttotal: 3.68s\tremaining: 1m 9s\n",
      "200:\tlearn: 1.2728851\ttest: 1.3117782\tbest: 1.3117782 (200)\ttotal: 7.39s\tremaining: 1m 6s\n",
      "300:\tlearn: 1.2495714\ttest: 1.2968942\tbest: 1.2968942 (300)\ttotal: 11.1s\tremaining: 1m 2s\n",
      "400:\tlearn: 1.2287049\ttest: 1.2849828\tbest: 1.2849828 (400)\ttotal: 14.9s\tremaining: 59.3s\n",
      "500:\tlearn: 1.2100594\ttest: 1.2751293\tbest: 1.2751293 (500)\ttotal: 18.6s\tremaining: 55.7s\n",
      "600:\tlearn: 1.1932444\ttest: 1.2669786\tbest: 1.2669786 (600)\ttotal: 22.4s\tremaining: 52.2s\n",
      "700:\tlearn: 1.1780772\ttest: 1.2601378\tbest: 1.2601378 (700)\ttotal: 26.2s\tremaining: 48.6s\n",
      "800:\tlearn: 1.1639866\ttest: 1.2543274\tbest: 1.2543274 (800)\ttotal: 30s\tremaining: 45s\n",
      "900:\tlearn: 1.1507787\ttest: 1.2494943\tbest: 1.2494943 (900)\ttotal: 34s\tremaining: 41.4s\n",
      "1000:\tlearn: 1.1381826\ttest: 1.2454262\tbest: 1.2454262 (1000)\ttotal: 38s\tremaining: 37.9s\n",
      "1100:\tlearn: 1.1262054\ttest: 1.2420962\tbest: 1.2420962 (1100)\ttotal: 42.1s\tremaining: 34.3s\n",
      "1200:\tlearn: 1.1146070\ttest: 1.2393573\tbest: 1.2393573 (1200)\ttotal: 46.2s\tremaining: 30.7s\n",
      "1300:\tlearn: 1.1035764\ttest: 1.2372076\tbest: 1.2372076 (1300)\ttotal: 50.3s\tremaining: 27s\n",
      "1400:\tlearn: 1.0926420\ttest: 1.2353322\tbest: 1.2353322 (1400)\ttotal: 54.5s\tremaining: 23.3s\n",
      "1500:\tlearn: 1.0817844\ttest: 1.2339303\tbest: 1.2339282 (1499)\ttotal: 58.7s\tremaining: 19.5s\n",
      "1600:\tlearn: 1.0711144\ttest: 1.2326138\tbest: 1.2326138 (1600)\ttotal: 1m 3s\tremaining: 15.7s\n",
      "1700:\tlearn: 1.0607871\ttest: 1.2315133\tbest: 1.2315133 (1700)\ttotal: 1m 7s\tremaining: 11.8s\n",
      "1800:\tlearn: 1.0506888\ttest: 1.2307178\tbest: 1.2307178 (1800)\ttotal: 1m 11s\tremaining: 7.92s\n",
      "1900:\tlearn: 1.0405615\ttest: 1.2300991\tbest: 1.2300991 (1900)\ttotal: 1m 15s\tremaining: 3.96s\n",
      "1999:\tlearn: 1.0308607\ttest: 1.2296240\tbest: 1.2296240 (1999)\ttotal: 1m 20s\tremaining: 0us\n",
      "bestTest = 1.229624033\n",
      "bestIteration = 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  83%|████████▎ | 5/6 [06:42<01:21, 81.57s/it]Warning: less than 75% GPU memory available for training. Free: 2139.375 Total: 5815.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3207003\ttest: 1.2397298\tbest: 1.2397298 (0)\ttotal: 34.4ms\tremaining: 1m 8s\n",
      "100:\tlearn: 1.2902824\ttest: 1.2214963\tbest: 1.2214963 (100)\ttotal: 3.9s\tremaining: 1m 13s\n",
      "200:\tlearn: 1.2628431\ttest: 1.2066471\tbest: 1.2066471 (200)\ttotal: 7.72s\tremaining: 1m 9s\n",
      "300:\tlearn: 1.2377419\ttest: 1.1945102\tbest: 1.1945102 (300)\ttotal: 11.7s\tremaining: 1m 6s\n",
      "400:\tlearn: 1.2144863\ttest: 1.1847076\tbest: 1.1847076 (400)\ttotal: 15.6s\tremaining: 1m 2s\n",
      "500:\tlearn: 1.1933316\ttest: 1.1766313\tbest: 1.1766313 (500)\ttotal: 19.6s\tremaining: 58.6s\n",
      "600:\tlearn: 1.1736729\ttest: 1.1698263\tbest: 1.1698263 (600)\ttotal: 23.6s\tremaining: 54.8s\n",
      "700:\tlearn: 1.1546811\ttest: 1.1639777\tbest: 1.1639777 (700)\ttotal: 27.6s\tremaining: 51.1s\n",
      "800:\tlearn: 1.1366061\ttest: 1.1591638\tbest: 1.1591638 (800)\ttotal: 31.7s\tremaining: 47.4s\n",
      "900:\tlearn: 1.1194442\ttest: 1.1552741\tbest: 1.1552741 (900)\ttotal: 35.8s\tremaining: 43.7s\n",
      "1000:\tlearn: 1.1029436\ttest: 1.1519530\tbest: 1.1519530 (1000)\ttotal: 39.9s\tremaining: 39.9s\n",
      "1100:\tlearn: 1.0869616\ttest: 1.1490565\tbest: 1.1490565 (1100)\ttotal: 44.2s\tremaining: 36.1s\n",
      "1200:\tlearn: 1.0713340\ttest: 1.1467612\tbest: 1.1467612 (1200)\ttotal: 48.4s\tremaining: 32.2s\n",
      "1300:\tlearn: 1.0562117\ttest: 1.1449193\tbest: 1.1449193 (1300)\ttotal: 52.7s\tremaining: 28.3s\n",
      "1400:\tlearn: 1.0418675\ttest: 1.1434704\tbest: 1.1434704 (1400)\ttotal: 56.9s\tremaining: 24.3s\n",
      "1500:\tlearn: 1.0283391\ttest: 1.1422208\tbest: 1.1422208 (1500)\ttotal: 1m 1s\tremaining: 20.3s\n",
      "1600:\tlearn: 1.0153267\ttest: 1.1411307\tbest: 1.1411307 (1600)\ttotal: 1m 5s\tremaining: 16.3s\n",
      "1700:\tlearn: 1.0022546\ttest: 1.1402926\tbest: 1.1402926 (1700)\ttotal: 1m 9s\tremaining: 12.2s\n",
      "1800:\tlearn: 0.9899438\ttest: 1.1397299\tbest: 1.1397203 (1798)\ttotal: 1m 13s\tremaining: 8.13s\n",
      "1900:\tlearn: 0.9781900\ttest: 1.1391743\tbest: 1.1391743 (1900)\ttotal: 1m 17s\tremaining: 4.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 6/6 [08:06<00:00, 82.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999:\tlearn: 0.9666369\ttest: 1.1388982\tbest: 1.1388692 (1991)\ttotal: 1m 21s\tremaining: 0us\n",
      "bestTest = 1.138869203\n",
      "bestIteration = 1991\n",
      "Shrink model to first 1992 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 6/6 [08:06<00:00, 81.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters and create final model\n",
    "base_model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.001,\n",
    "    depth=10,\n",
    "    l2_leaf_reg=4.5,\n",
    "    early_stopping_rounds=52,\n",
    "    has_time=True,\n",
    "    task_type=\"GPU\",\n",
    "    verbose=100,\n",
    "    use_best_model=True\n",
    ")\n",
    "catboost_multi_target = MultiTargetCatBoost(base_model)\n",
    "catboost_multi_target.fit(X_train_1, y_train_1, X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cbm = X_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing average R^2\n",
    "# Ensure tensors are on CPU before calculations\n",
    "catboost_pred_3 = catboost_multi_target.predict(X_train_3.cpu())\n",
    "y_train_3_cpu = y_train_3.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_pred_3 = torch.tensor(catboost_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between prediction 0 and true value: 0.3910\n",
      "Correlation between prediction 1 and true value: 0.4209\n",
      "Correlation between prediction 2 and true value: 0.4326\n",
      "Correlation between prediction 3 and true value: 0.4124\n",
      "Correlation between prediction 4 and true value: 0.4012\n",
      "Correlation between prediction 5 and true value: 0.4252\n",
      "0.1684957193630514\n",
      "0.17150105448093314\n"
     ]
    }
   ],
   "source": [
    "print_corr(catboost_pred_3, y_train_3_cpu)\n",
    "print(r2(catboost_pred_3, y_train_3_cpu))\n",
    "print(r2_from_list(r_list(catboost_pred_3, y_train_3_cpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target IS NOT answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_filled_test + catboost_pred_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Model\n",
    "class LSTMWithLayerNorm(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.3, use_skip=True):\n",
    "        super(LSTMWithLayerNorm, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.use_skip = use_skip\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "\n",
    "        # Build stacked LSTMs\n",
    "        for i in range(num_layers):\n",
    "            input_size = input_dim if i == 0 else hidden_dim\n",
    "            self.lstm_layers.append(\n",
    "                nn.LSTM(input_size, hidden_dim, num_layers=1, batch_first=True)\n",
    "            )\n",
    "            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n",
    "            self.dropouts.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = None\n",
    "\n",
    "        for lstm, layer_norm, dropout in zip(self.lstm_layers, self.layer_norms, self.dropouts):\n",
    "            x_residual, _ = lstm(x)\n",
    "            x_residual = layer_norm(x_residual)\n",
    "            x_residual = dropout(x_residual)\n",
    "            if self.use_skip:\n",
    "                if skip is not None and skip.shape == x_residual.shape:\n",
    "                    x_residual = x_residual + skip  # Add skip connection\n",
    "                skip = x_residual\n",
    "            x = x_residual\n",
    "\n",
    "        # Only use last time step output\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 42\n",
    "output_dim = y.shape[1]\n",
    "num_layers = 2\n",
    "dropout = 0.3\n",
    "weight_decay = 1e-4\n",
    "lr = 1e-3\n",
    "warmup_steps = 500\n",
    "total_steps = 5000\n",
    "\n",
    "# Instantiate Model\n",
    "model = LSTMWithLayerNorm(input_dim, hidden_dim, output_dim, num_layers, dropout).to(device)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Fix dimension if needed\n",
    "if X_train_1.dim() == 2:\n",
    "    X_train_1_nn = X_train_1.unsqueeze(1)  # [batch_size, 1, input_dim]\n",
    "if X_train_2.dim() == 2:\n",
    "    X_train_2_nn = X_train_2.unsqueeze(1)\n",
    "\n",
    "# Example: convert data to torch tensors with proper cloning\n",
    "X_train_1_nn = X_train_1_nn.clone().detach().to(device).float()\n",
    "y_train_1_nn = y_train_1.clone().detach().to(device).float()\n",
    "X_train_2_nn = X_train_2_nn.clone().detach().to(device).float()\n",
    "y_train_2_nn = y_train_2.clone().detach().to(device).float()\n",
    "\n",
    "# Debug print tensor shapes\n",
    "print(f\"X_train_1 shape: {X_train_1.shape}\")\n",
    "print(f\"y_train_1 shape: {y_train_1.shape}\")\n",
    "print(f\"X_train_2 shape: {X_train_2.shape}\")\n",
    "print(f\"y_train_2 shape: {y_train_2.shape}\")\n",
    "\n",
    "# Create Dataloaders\n",
    "train_dataset = TensorDataset(X_train_1_nn, y_train_1_nn)\n",
    "val_dataset = TensorDataset(X_train_2_nn, y_train_2_nn)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 5\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (X_batch, y_batch) in tqdm(enumerate(train_loader), desc=\"Batch\", total=len(train_loader)):\n",
    "        # Debug print batch shapes\n",
    "        # print(f\"Batch {batch_idx} - X_batch shape: {X_batch.shape}, y_batch shape: {y_batch.shape}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            output = model(X_batch)\n",
    "            loss = loss_fn(output, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "        except IndexError as e:\n",
    "            print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
    "            print(f\"X_batch shape: {X_batch.shape}\")\n",
    "            print(f\"Model input shape expected: (batch_size, seq_len, features)\")\n",
    "            raise\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            output = model(X_batch)\n",
    "            loss = loss_fn(output, y_batch)\n",
    "            val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"✅ Best model saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using best model\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction with memory-efficient batching\n",
    "batch_size = 512  # Adjust based on available GPU memory\n",
    "predictions = []\n",
    "\n",
    "if X_train_3.dim() == 2:\n",
    "    X_train_3_nn = X_train_3.unsqueeze(1)  # [batch_size, 1, input_dim]\n",
    "X_train_3_nn = X_train_3_nn.clone().detach().to(device).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # Process in batches to avoid OOM\n",
    "    for i in range(0, len(X_train_3_nn), batch_size):\n",
    "        batch = X_train_3_nn[i:i+batch_size]\n",
    "        pred = model(batch)\n",
    "        predictions.append(pred.cpu())\n",
    "        \n",
    "    test_predictions = torch.cat(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_from_list(r_list(test_predictions, y_train_3_cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralForcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_as_df = pd.DataFrame(target)\n",
    "features_cols = [f'f_{i}' for i in range(features_norm.shape[1])]\n",
    "features_df = pd.DataFrame(features_norm, columns=features_cols)\n",
    "data_as_df = pd.concat([data_as_df, features_df], axis=1)\n",
    "data_as_df['ds'] = _time_extractor.datetime\n",
    "\n",
    "for i in range(6):\n",
    "    if i in data_as_df.columns:\n",
    "        data_as_df = data_as_df.rename(columns={i: f'y_{i}'})\n",
    "\n",
    "data_as_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_data(data_as_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1. Melt correctly\n",
    "    id_cols = [col for col in data_as_df.columns if not col.startswith('y_')]\n",
    "\n",
    "    df_melted = data_as_df.melt(\n",
    "        id_vars=id_cols,\n",
    "        value_vars=[f'y_{i}' for i in range(6)],\n",
    "        var_name='unique_id',\n",
    "        value_name='y'\n",
    "    )\n",
    "\n",
    "    # 2. Clean up 'unique_id' to be just 0, 1, ..., 5\n",
    "    df_melted['unique_id'] = df_melted['unique_id'].str.replace('y_', '')\n",
    "    return df_melted\n",
    "\n",
    "df_melted = melt_data(data_as_df)\n",
    "df_melted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_melted[df_melted['ds'].isin(data_as_df['ds'][train_slice_1])]\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "\n",
    "models = [\n",
    "    NHITS(\n",
    "        input_size=60*24*7,   # how much past to use (week)\n",
    "        h=60 * 4,              # forecast 4 hours ahead\n",
    "        max_steps=2000,        # training steps\n",
    "        futr_exog_list=features_cols, # future known features\n",
    "        batch_size=8\n",
    "    )\n",
    "]\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='minutely')  # You can downsample if needed (e.g., 5min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = train_slice_2.stop - train_slice_2.start\n",
    "nf.fit(df=train_df, val_size=val_size, time_col='ds', target_col='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_predictions_train = torch.cat([\n",
    "    X_train_1,\n",
    "    linreg(X_train_1.to(device)),\n",
    "    torch.tensor(catboost_multi_target.predict(X_train_1.to(device)), device=device),\n",
    "], dim=1).float().detach()\n",
    "minor_predictions_val = torch.cat([\n",
    "    X_train_2,\n",
    "    linreg(X_train_2.to(device)),\n",
    "    torch.tensor(catboost_multi_target.predict(X_train_2.to(device)), device=device),\n",
    "], dim=1).float().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA on minor predictions\n",
    "# pca = PCA(n_components=0.999)\n",
    "# pca.fit(minor_predictions_train.cpu())\n",
    "# minor_predictions_train_pca = torch.tensor(pca.transform(minor_predictions_train.cpu()))\n",
    "# minor_predictions_val_pca = torch.tensor(pca.transform(minor_predictions_val.cpu()))\n",
    "# print(sum(pca.explained_variance_ratio_), pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stacking_model = MultiTargetCatBoost(CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.02,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3,\n",
    "    early_stopping_rounds=100,\n",
    "    task_type=\"CPU\",\n",
    "    has_time=True,\n",
    "    use_best_model=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2589926\ttest: 1.2388269\tbest: 1.2388269 (0)\ttotal: 53.8ms\tremaining: 1m 47s\n",
      "1:\tlearn: 1.2477627\ttest: 1.2346170\tbest: 1.2346170 (1)\ttotal: 111ms\tremaining: 1m 50s\n",
      "2:\tlearn: 1.2368077\ttest: 1.2302668\tbest: 1.2302668 (2)\ttotal: 162ms\tremaining: 1m 47s\n",
      "3:\tlearn: 1.2261323\ttest: 1.2259582\tbest: 1.2259582 (3)\ttotal: 216ms\tremaining: 1m 47s\n",
      "4:\tlearn: 1.2157333\ttest: 1.2221890\tbest: 1.2221890 (4)\ttotal: 272ms\tremaining: 1m 48s\n",
      "5:\tlearn: 1.2055244\ttest: 1.2184011\tbest: 1.2184011 (5)\ttotal: 325ms\tremaining: 1m 48s\n",
      "6:\tlearn: 1.1956597\ttest: 1.2153030\tbest: 1.2153030 (6)\ttotal: 386ms\tremaining: 1m 50s\n",
      "7:\tlearn: 1.1862866\ttest: 1.2121336\tbest: 1.2121336 (7)\ttotal: 454ms\tremaining: 1m 52s\n",
      "8:\tlearn: 1.1770175\ttest: 1.2091831\tbest: 1.2091831 (8)\ttotal: 543ms\tremaining: 2m\n",
      "9:\tlearn: 1.1679167\ttest: 1.2062933\tbest: 1.2062933 (9)\ttotal: 614ms\tremaining: 2m 2s\n",
      "10:\tlearn: 1.1590188\ttest: 1.2038442\tbest: 1.2038442 (10)\ttotal: 683ms\tremaining: 2m 3s\n",
      "11:\tlearn: 1.1504352\ttest: 1.2016037\tbest: 1.2016037 (11)\ttotal: 734ms\tremaining: 2m 1s\n",
      "12:\tlearn: 1.1422538\ttest: 1.1996129\tbest: 1.1996129 (12)\ttotal: 789ms\tremaining: 2m\n",
      "13:\tlearn: 1.1341869\ttest: 1.1977730\tbest: 1.1977730 (13)\ttotal: 848ms\tremaining: 2m\n",
      "14:\tlearn: 1.1262163\ttest: 1.1957485\tbest: 1.1957485 (14)\ttotal: 902ms\tremaining: 1m 59s\n",
      "15:\tlearn: 1.1184564\ttest: 1.1937589\tbest: 1.1937589 (15)\ttotal: 956ms\tremaining: 1m 58s\n",
      "16:\tlearn: 1.1109006\ttest: 1.1922397\tbest: 1.1922397 (16)\ttotal: 1.01s\tremaining: 1m 57s\n",
      "17:\tlearn: 1.1034952\ttest: 1.1905083\tbest: 1.1905083 (17)\ttotal: 1.06s\tremaining: 1m 56s\n",
      "18:\tlearn: 1.0964893\ttest: 1.1889699\tbest: 1.1889699 (18)\ttotal: 1.11s\tremaining: 1m 55s\n",
      "19:\tlearn: 1.0895543\ttest: 1.1875082\tbest: 1.1875082 (19)\ttotal: 1.16s\tremaining: 1m 54s\n",
      "20:\tlearn: 1.0827905\ttest: 1.1862246\tbest: 1.1862246 (20)\ttotal: 1.22s\tremaining: 1m 54s\n",
      "21:\tlearn: 1.0758301\ttest: 1.1850581\tbest: 1.1850581 (21)\ttotal: 1.27s\tremaining: 1m 54s\n",
      "22:\tlearn: 1.0694134\ttest: 1.1837921\tbest: 1.1837921 (22)\ttotal: 1.32s\tremaining: 1m 53s\n",
      "23:\tlearn: 1.0632042\ttest: 1.1831416\tbest: 1.1831416 (23)\ttotal: 1.37s\tremaining: 1m 53s\n",
      "24:\tlearn: 1.0571505\ttest: 1.1822592\tbest: 1.1822592 (24)\ttotal: 1.42s\tremaining: 1m 52s\n",
      "25:\tlearn: 1.0512738\ttest: 1.1818055\tbest: 1.1818055 (25)\ttotal: 1.48s\tremaining: 1m 52s\n",
      "26:\tlearn: 1.0455744\ttest: 1.1812786\tbest: 1.1812786 (26)\ttotal: 1.54s\tremaining: 1m 52s\n",
      "27:\tlearn: 1.0398811\ttest: 1.1805830\tbest: 1.1805830 (27)\ttotal: 1.59s\tremaining: 1m 51s\n",
      "28:\tlearn: 1.0344399\ttest: 1.1802301\tbest: 1.1802301 (28)\ttotal: 1.64s\tremaining: 1m 51s\n",
      "29:\tlearn: 1.0291479\ttest: 1.1797343\tbest: 1.1797343 (29)\ttotal: 1.69s\tremaining: 1m 50s\n",
      "30:\tlearn: 1.0238574\ttest: 1.1793762\tbest: 1.1793762 (30)\ttotal: 1.74s\tremaining: 1m 50s\n",
      "31:\tlearn: 1.0188422\ttest: 1.1790611\tbest: 1.1790611 (31)\ttotal: 1.79s\tremaining: 1m 49s\n",
      "32:\tlearn: 1.0136934\ttest: 1.1789016\tbest: 1.1789016 (32)\ttotal: 1.84s\tremaining: 1m 49s\n",
      "33:\tlearn: 1.0086611\ttest: 1.1786654\tbest: 1.1786654 (33)\ttotal: 1.9s\tremaining: 1m 49s\n",
      "34:\tlearn: 1.0036497\ttest: 1.1785046\tbest: 1.1785046 (34)\ttotal: 1.96s\tremaining: 1m 49s\n",
      "35:\tlearn: 0.9986862\ttest: 1.1782074\tbest: 1.1782074 (35)\ttotal: 2.01s\tremaining: 1m 49s\n",
      "36:\tlearn: 0.9942957\ttest: 1.1782695\tbest: 1.1782074 (35)\ttotal: 2.06s\tremaining: 1m 49s\n",
      "37:\tlearn: 0.9898279\ttest: 1.1781690\tbest: 1.1781690 (37)\ttotal: 2.11s\tremaining: 1m 48s\n",
      "38:\tlearn: 0.9854982\ttest: 1.1781769\tbest: 1.1781690 (37)\ttotal: 2.16s\tremaining: 1m 48s\n",
      "39:\tlearn: 0.9812976\ttest: 1.1780529\tbest: 1.1780529 (39)\ttotal: 2.21s\tremaining: 1m 48s\n",
      "40:\tlearn: 0.9771788\ttest: 1.1780602\tbest: 1.1780529 (39)\ttotal: 2.26s\tremaining: 1m 47s\n",
      "41:\tlearn: 0.9732714\ttest: 1.1781950\tbest: 1.1780529 (39)\ttotal: 2.31s\tremaining: 1m 47s\n",
      "42:\tlearn: 0.9693288\ttest: 1.1785169\tbest: 1.1780529 (39)\ttotal: 2.36s\tremaining: 1m 47s\n",
      "43:\tlearn: 0.9652719\ttest: 1.1786715\tbest: 1.1780529 (39)\ttotal: 2.41s\tremaining: 1m 47s\n",
      "44:\tlearn: 0.9615860\ttest: 1.1787138\tbest: 1.1780529 (39)\ttotal: 2.46s\tremaining: 1m 47s\n",
      "45:\tlearn: 0.9580273\ttest: 1.1788952\tbest: 1.1780529 (39)\ttotal: 2.51s\tremaining: 1m 46s\n",
      "46:\tlearn: 0.9545917\ttest: 1.1791558\tbest: 1.1780529 (39)\ttotal: 2.56s\tremaining: 1m 46s\n",
      "47:\tlearn: 0.9512227\ttest: 1.1794663\tbest: 1.1780529 (39)\ttotal: 2.61s\tremaining: 1m 46s\n",
      "48:\tlearn: 0.9476338\ttest: 1.1798298\tbest: 1.1780529 (39)\ttotal: 2.67s\tremaining: 1m 46s\n",
      "49:\tlearn: 0.9444144\ttest: 1.1800710\tbest: 1.1780529 (39)\ttotal: 2.71s\tremaining: 1m 45s\n",
      "50:\tlearn: 0.9411395\ttest: 1.1805132\tbest: 1.1780529 (39)\ttotal: 2.76s\tremaining: 1m 45s\n",
      "51:\tlearn: 0.9378196\ttest: 1.1807306\tbest: 1.1780529 (39)\ttotal: 2.81s\tremaining: 1m 45s\n",
      "52:\tlearn: 0.9346839\ttest: 1.1812380\tbest: 1.1780529 (39)\ttotal: 2.87s\tremaining: 1m 45s\n",
      "53:\tlearn: 0.9317153\ttest: 1.1817015\tbest: 1.1780529 (39)\ttotal: 2.92s\tremaining: 1m 45s\n",
      "54:\tlearn: 0.9287929\ttest: 1.1821974\tbest: 1.1780529 (39)\ttotal: 2.97s\tremaining: 1m 44s\n",
      "55:\tlearn: 0.9257524\ttest: 1.1827395\tbest: 1.1780529 (39)\ttotal: 3.01s\tremaining: 1m 44s\n",
      "56:\tlearn: 0.9228928\ttest: 1.1832416\tbest: 1.1780529 (39)\ttotal: 3.06s\tremaining: 1m 44s\n",
      "57:\tlearn: 0.9200948\ttest: 1.1837158\tbest: 1.1780529 (39)\ttotal: 3.11s\tremaining: 1m 44s\n",
      "58:\tlearn: 0.9173121\ttest: 1.1842583\tbest: 1.1780529 (39)\ttotal: 3.16s\tremaining: 1m 44s\n",
      "59:\tlearn: 0.9145594\ttest: 1.1847305\tbest: 1.1780529 (39)\ttotal: 3.22s\tremaining: 1m 44s\n",
      "60:\tlearn: 0.9119641\ttest: 1.1852131\tbest: 1.1780529 (39)\ttotal: 3.27s\tremaining: 1m 43s\n",
      "61:\tlearn: 0.9095479\ttest: 1.1857892\tbest: 1.1780529 (39)\ttotal: 3.32s\tremaining: 1m 43s\n",
      "62:\tlearn: 0.9072090\ttest: 1.1864443\tbest: 1.1780529 (39)\ttotal: 3.37s\tremaining: 1m 43s\n",
      "63:\tlearn: 0.9048020\ttest: 1.1869665\tbest: 1.1780529 (39)\ttotal: 3.41s\tremaining: 1m 43s\n",
      "64:\tlearn: 0.9024429\ttest: 1.1874019\tbest: 1.1780529 (39)\ttotal: 3.46s\tremaining: 1m 42s\n",
      "65:\tlearn: 0.9000731\ttest: 1.1878653\tbest: 1.1780529 (39)\ttotal: 3.51s\tremaining: 1m 42s\n",
      "66:\tlearn: 0.8979368\ttest: 1.1884776\tbest: 1.1780529 (39)\ttotal: 3.56s\tremaining: 1m 42s\n",
      "67:\tlearn: 0.8957503\ttest: 1.1889601\tbest: 1.1780529 (39)\ttotal: 3.61s\tremaining: 1m 42s\n",
      "68:\tlearn: 0.8936059\ttest: 1.1895059\tbest: 1.1780529 (39)\ttotal: 3.66s\tremaining: 1m 42s\n",
      "69:\tlearn: 0.8914078\ttest: 1.1901160\tbest: 1.1780529 (39)\ttotal: 3.71s\tremaining: 1m 42s\n",
      "70:\tlearn: 0.8893232\ttest: 1.1905930\tbest: 1.1780529 (39)\ttotal: 3.76s\tremaining: 1m 42s\n",
      "71:\tlearn: 0.8872914\ttest: 1.1911492\tbest: 1.1780529 (39)\ttotal: 3.8s\tremaining: 1m 41s\n",
      "72:\tlearn: 0.8852510\ttest: 1.1916459\tbest: 1.1780529 (39)\ttotal: 3.86s\tremaining: 1m 41s\n",
      "73:\tlearn: 0.8834261\ttest: 1.1920142\tbest: 1.1780529 (39)\ttotal: 3.91s\tremaining: 1m 41s\n",
      "74:\tlearn: 0.8814587\ttest: 1.1926146\tbest: 1.1780529 (39)\ttotal: 3.96s\tremaining: 1m 41s\n",
      "75:\tlearn: 0.8796865\ttest: 1.1930440\tbest: 1.1780529 (39)\ttotal: 4.02s\tremaining: 1m 41s\n",
      "76:\tlearn: 0.8777962\ttest: 1.1936373\tbest: 1.1780529 (39)\ttotal: 4.08s\tremaining: 1m 41s\n",
      "77:\tlearn: 0.8759723\ttest: 1.1942452\tbest: 1.1780529 (39)\ttotal: 4.14s\tremaining: 1m 42s\n",
      "78:\tlearn: 0.8742440\ttest: 1.1947911\tbest: 1.1780529 (39)\ttotal: 4.19s\tremaining: 1m 41s\n",
      "79:\tlearn: 0.8724986\ttest: 1.1951192\tbest: 1.1780529 (39)\ttotal: 4.24s\tremaining: 1m 41s\n",
      "80:\tlearn: 0.8707491\ttest: 1.1956493\tbest: 1.1780529 (39)\ttotal: 4.29s\tremaining: 1m 41s\n",
      "81:\tlearn: 0.8690802\ttest: 1.1960871\tbest: 1.1780529 (39)\ttotal: 4.34s\tremaining: 1m 41s\n",
      "82:\tlearn: 0.8674391\ttest: 1.1967113\tbest: 1.1780529 (39)\ttotal: 4.4s\tremaining: 1m 41s\n",
      "83:\tlearn: 0.8659491\ttest: 1.1972915\tbest: 1.1780529 (39)\ttotal: 4.45s\tremaining: 1m 41s\n",
      "84:\tlearn: 0.8644841\ttest: 1.1977031\tbest: 1.1780529 (39)\ttotal: 4.49s\tremaining: 1m 41s\n",
      "85:\tlearn: 0.8629788\ttest: 1.1982446\tbest: 1.1780529 (39)\ttotal: 4.54s\tremaining: 1m 41s\n",
      "86:\tlearn: 0.8615814\ttest: 1.1986868\tbest: 1.1780529 (39)\ttotal: 4.59s\tremaining: 1m 40s\n",
      "87:\tlearn: 0.8601495\ttest: 1.1991470\tbest: 1.1780529 (39)\ttotal: 4.64s\tremaining: 1m 40s\n",
      "88:\tlearn: 0.8587893\ttest: 1.1995871\tbest: 1.1780529 (39)\ttotal: 4.69s\tremaining: 1m 40s\n",
      "89:\tlearn: 0.8573175\ttest: 1.2002111\tbest: 1.1780529 (39)\ttotal: 4.75s\tremaining: 1m 40s\n",
      "90:\tlearn: 0.8558754\ttest: 1.2007173\tbest: 1.1780529 (39)\ttotal: 4.8s\tremaining: 1m 40s\n",
      "91:\tlearn: 0.8546176\ttest: 1.2012599\tbest: 1.1780529 (39)\ttotal: 4.86s\tremaining: 1m 40s\n",
      "92:\tlearn: 0.8532404\ttest: 1.2019133\tbest: 1.1780529 (39)\ttotal: 4.92s\tremaining: 1m 40s\n",
      "93:\tlearn: 0.8519739\ttest: 1.2023561\tbest: 1.1780529 (39)\ttotal: 4.97s\tremaining: 1m 40s\n",
      "94:\tlearn: 0.8507564\ttest: 1.2028736\tbest: 1.1780529 (39)\ttotal: 5.01s\tremaining: 1m 40s\n",
      "95:\tlearn: 0.8494891\ttest: 1.2033297\tbest: 1.1780529 (39)\ttotal: 5.06s\tremaining: 1m 40s\n",
      "96:\tlearn: 0.8482190\ttest: 1.2039058\tbest: 1.1780529 (39)\ttotal: 5.12s\tremaining: 1m 40s\n",
      "97:\tlearn: 0.8470236\ttest: 1.2041154\tbest: 1.1780529 (39)\ttotal: 5.16s\tremaining: 1m 40s\n",
      "98:\tlearn: 0.8458568\ttest: 1.2044390\tbest: 1.1780529 (39)\ttotal: 5.21s\tremaining: 1m 39s\n",
      "99:\tlearn: 0.8446002\ttest: 1.2048641\tbest: 1.1780529 (39)\ttotal: 5.25s\tremaining: 1m 39s\n",
      "100:\tlearn: 0.8434751\ttest: 1.2054255\tbest: 1.1780529 (39)\ttotal: 5.31s\tremaining: 1m 39s\n",
      "101:\tlearn: 0.8423599\ttest: 1.2057277\tbest: 1.1780529 (39)\ttotal: 5.37s\tremaining: 1m 39s\n",
      "102:\tlearn: 0.8412781\ttest: 1.2061333\tbest: 1.1780529 (39)\ttotal: 5.42s\tremaining: 1m 39s\n",
      "103:\tlearn: 0.8401602\ttest: 1.2064217\tbest: 1.1780529 (39)\ttotal: 5.47s\tremaining: 1m 39s\n",
      "104:\tlearn: 0.8391043\ttest: 1.2068436\tbest: 1.1780529 (39)\ttotal: 5.52s\tremaining: 1m 39s\n",
      "105:\tlearn: 0.8380474\ttest: 1.2072896\tbest: 1.1780529 (39)\ttotal: 5.57s\tremaining: 1m 39s\n",
      "106:\tlearn: 0.8370019\ttest: 1.2076664\tbest: 1.1780529 (39)\ttotal: 5.62s\tremaining: 1m 39s\n",
      "107:\tlearn: 0.8360375\ttest: 1.2079079\tbest: 1.1780529 (39)\ttotal: 5.67s\tremaining: 1m 39s\n",
      "108:\tlearn: 0.8350236\ttest: 1.2083074\tbest: 1.1780529 (39)\ttotal: 5.72s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.8340975\ttest: 1.2085610\tbest: 1.1780529 (39)\ttotal: 5.77s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.8331888\ttest: 1.2087412\tbest: 1.1780529 (39)\ttotal: 5.82s\tremaining: 1m 39s\n",
      "111:\tlearn: 0.8322632\ttest: 1.2092303\tbest: 1.1780529 (39)\ttotal: 5.87s\tremaining: 1m 38s\n",
      "112:\tlearn: 0.8312529\ttest: 1.2096579\tbest: 1.1780529 (39)\ttotal: 5.92s\tremaining: 1m 38s\n",
      "113:\tlearn: 0.8303380\ttest: 1.2098237\tbest: 1.1780529 (39)\ttotal: 5.97s\tremaining: 1m 38s\n",
      "114:\tlearn: 0.8292782\ttest: 1.2101051\tbest: 1.1780529 (39)\ttotal: 6.02s\tremaining: 1m 38s\n",
      "115:\tlearn: 0.8283000\ttest: 1.2105487\tbest: 1.1780529 (39)\ttotal: 6.07s\tremaining: 1m 38s\n",
      "116:\tlearn: 0.8274438\ttest: 1.2108073\tbest: 1.1780529 (39)\ttotal: 6.12s\tremaining: 1m 38s\n",
      "117:\tlearn: 0.8265853\ttest: 1.2112117\tbest: 1.1780529 (39)\ttotal: 6.17s\tremaining: 1m 38s\n",
      "118:\tlearn: 0.8257050\ttest: 1.2115008\tbest: 1.1780529 (39)\ttotal: 6.22s\tremaining: 1m 38s\n",
      "119:\tlearn: 0.8248356\ttest: 1.2118523\tbest: 1.1780529 (39)\ttotal: 6.26s\tremaining: 1m 38s\n",
      "120:\tlearn: 0.8239974\ttest: 1.2122418\tbest: 1.1780529 (39)\ttotal: 6.32s\tremaining: 1m 38s\n",
      "121:\tlearn: 0.8230333\ttest: 1.2125737\tbest: 1.1780529 (39)\ttotal: 6.38s\tremaining: 1m 38s\n",
      "122:\tlearn: 0.8221860\ttest: 1.2128408\tbest: 1.1780529 (39)\ttotal: 6.43s\tremaining: 1m 38s\n",
      "123:\tlearn: 0.8213203\ttest: 1.2131108\tbest: 1.1780529 (39)\ttotal: 6.48s\tremaining: 1m 38s\n",
      "124:\tlearn: 0.8204675\ttest: 1.2133308\tbest: 1.1780529 (39)\ttotal: 6.52s\tremaining: 1m 37s\n",
      "125:\tlearn: 0.8196598\ttest: 1.2137061\tbest: 1.1780529 (39)\ttotal: 6.57s\tremaining: 1m 37s\n",
      "126:\tlearn: 0.8189175\ttest: 1.2139641\tbest: 1.1780529 (39)\ttotal: 6.62s\tremaining: 1m 37s\n",
      "127:\tlearn: 0.8180852\ttest: 1.2143071\tbest: 1.1780529 (39)\ttotal: 6.67s\tremaining: 1m 37s\n",
      "128:\tlearn: 0.8171731\ttest: 1.2145955\tbest: 1.1780529 (39)\ttotal: 6.74s\tremaining: 1m 37s\n",
      "129:\tlearn: 0.8163911\ttest: 1.2149085\tbest: 1.1780529 (39)\ttotal: 6.79s\tremaining: 1m 37s\n",
      "130:\tlearn: 0.8155303\ttest: 1.2151816\tbest: 1.1780529 (39)\ttotal: 6.84s\tremaining: 1m 37s\n",
      "131:\tlearn: 0.8147785\ttest: 1.2153414\tbest: 1.1780529 (39)\ttotal: 6.88s\tremaining: 1m 37s\n",
      "132:\tlearn: 0.8140812\ttest: 1.2155171\tbest: 1.1780529 (39)\ttotal: 6.93s\tremaining: 1m 37s\n",
      "133:\tlearn: 0.8133949\ttest: 1.2156995\tbest: 1.1780529 (39)\ttotal: 6.97s\tremaining: 1m 37s\n",
      "134:\tlearn: 0.8127271\ttest: 1.2159394\tbest: 1.1780529 (39)\ttotal: 7.02s\tremaining: 1m 36s\n",
      "135:\tlearn: 0.8119311\ttest: 1.2162606\tbest: 1.1780529 (39)\ttotal: 7.07s\tremaining: 1m 36s\n",
      "136:\tlearn: 0.8110666\ttest: 1.2164239\tbest: 1.1780529 (39)\ttotal: 7.13s\tremaining: 1m 36s\n",
      "137:\tlearn: 0.8103686\ttest: 1.2164795\tbest: 1.1780529 (39)\ttotal: 7.18s\tremaining: 1m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  17%|█▋        | 1/6 [00:08<00:41,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138:\tlearn: 0.8095517\ttest: 1.2168811\tbest: 1.1780529 (39)\ttotal: 7.23s\tremaining: 1m 36s\n",
      "139:\tlearn: 0.8087007\ttest: 1.2170675\tbest: 1.1780529 (39)\ttotal: 7.29s\tremaining: 1m 36s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.178052876\n",
      "bestIteration = 39\n",
      "\n",
      "Shrink model to first 40 iterations.\n",
      "0:\tlearn: 1.3623699\ttest: 1.3674035\tbest: 1.3674035 (0)\ttotal: 50.5ms\tremaining: 1m 41s\n",
      "1:\tlearn: 1.3489970\ttest: 1.3612936\tbest: 1.3612936 (1)\ttotal: 101ms\tremaining: 1m 40s\n",
      "2:\tlearn: 1.3359033\ttest: 1.3553857\tbest: 1.3553857 (2)\ttotal: 157ms\tremaining: 1m 44s\n",
      "3:\tlearn: 1.3231387\ttest: 1.3495401\tbest: 1.3495401 (3)\ttotal: 215ms\tremaining: 1m 47s\n",
      "4:\tlearn: 1.3108332\ttest: 1.3438347\tbest: 1.3438347 (4)\ttotal: 265ms\tremaining: 1m 45s\n",
      "5:\tlearn: 1.2988476\ttest: 1.3387874\tbest: 1.3387874 (5)\ttotal: 323ms\tremaining: 1m 47s\n",
      "6:\tlearn: 1.2872145\ttest: 1.3336427\tbest: 1.3336427 (6)\ttotal: 375ms\tremaining: 1m 46s\n",
      "7:\tlearn: 1.2757380\ttest: 1.3286971\tbest: 1.3286971 (7)\ttotal: 428ms\tremaining: 1m 46s\n",
      "8:\tlearn: 1.2645953\ttest: 1.3239679\tbest: 1.3239679 (8)\ttotal: 480ms\tremaining: 1m 46s\n",
      "9:\tlearn: 1.2537600\ttest: 1.3194194\tbest: 1.3194194 (9)\ttotal: 529ms\tremaining: 1m 45s\n",
      "10:\tlearn: 1.2431682\ttest: 1.3151157\tbest: 1.3151157 (10)\ttotal: 586ms\tremaining: 1m 46s\n",
      "11:\tlearn: 1.2328928\ttest: 1.3110379\tbest: 1.3110379 (11)\ttotal: 643ms\tremaining: 1m 46s\n",
      "12:\tlearn: 1.2227086\ttest: 1.3069676\tbest: 1.3069676 (12)\ttotal: 697ms\tremaining: 1m 46s\n",
      "13:\tlearn: 1.2126836\ttest: 1.3036307\tbest: 1.3036307 (13)\ttotal: 754ms\tremaining: 1m 46s\n",
      "14:\tlearn: 1.2032297\ttest: 1.3001159\tbest: 1.3001159 (14)\ttotal: 809ms\tremaining: 1m 47s\n",
      "15:\tlearn: 1.1938280\ttest: 1.2967581\tbest: 1.2967581 (15)\ttotal: 859ms\tremaining: 1m 46s\n",
      "16:\tlearn: 1.1847255\ttest: 1.2938030\tbest: 1.2938030 (16)\ttotal: 911ms\tremaining: 1m 46s\n",
      "17:\tlearn: 1.1759032\ttest: 1.2910227\tbest: 1.2910227 (17)\ttotal: 964ms\tremaining: 1m 46s\n",
      "18:\tlearn: 1.1672222\ttest: 1.2884268\tbest: 1.2884268 (18)\ttotal: 1.02s\tremaining: 1m 46s\n",
      "19:\tlearn: 1.1587662\ttest: 1.2856189\tbest: 1.2856189 (19)\ttotal: 1.07s\tremaining: 1m 46s\n",
      "20:\tlearn: 1.1506189\ttest: 1.2827836\tbest: 1.2827836 (20)\ttotal: 1.12s\tremaining: 1m 45s\n",
      "21:\tlearn: 1.1427121\ttest: 1.2805127\tbest: 1.2805127 (21)\ttotal: 1.17s\tremaining: 1m 45s\n",
      "22:\tlearn: 1.1349775\ttest: 1.2782908\tbest: 1.2782908 (22)\ttotal: 1.22s\tremaining: 1m 45s\n",
      "23:\tlearn: 1.1275220\ttest: 1.2762487\tbest: 1.2762487 (23)\ttotal: 1.28s\tremaining: 1m 45s\n",
      "24:\tlearn: 1.1202500\ttest: 1.2743261\tbest: 1.2743261 (24)\ttotal: 1.33s\tremaining: 1m 44s\n",
      "25:\tlearn: 1.1128794\ttest: 1.2727069\tbest: 1.2727069 (25)\ttotal: 1.39s\tremaining: 1m 45s\n",
      "26:\tlearn: 1.1060358\ttest: 1.2707807\tbest: 1.2707807 (26)\ttotal: 1.44s\tremaining: 1m 45s\n",
      "27:\tlearn: 1.0990865\ttest: 1.2691866\tbest: 1.2691866 (27)\ttotal: 1.49s\tremaining: 1m 45s\n",
      "28:\tlearn: 1.0924110\ttest: 1.2675763\tbest: 1.2675763 (28)\ttotal: 1.54s\tremaining: 1m 44s\n",
      "29:\tlearn: 1.0859519\ttest: 1.2663982\tbest: 1.2663982 (29)\ttotal: 1.6s\tremaining: 1m 44s\n",
      "30:\tlearn: 1.0797508\ttest: 1.2650047\tbest: 1.2650047 (30)\ttotal: 1.65s\tremaining: 1m 44s\n",
      "31:\tlearn: 1.0736195\ttest: 1.2635772\tbest: 1.2635772 (31)\ttotal: 1.7s\tremaining: 1m 44s\n",
      "32:\tlearn: 1.0677376\ttest: 1.2623178\tbest: 1.2623178 (32)\ttotal: 1.74s\tremaining: 1m 43s\n",
      "33:\tlearn: 1.0617498\ttest: 1.2614366\tbest: 1.2614366 (33)\ttotal: 1.82s\tremaining: 1m 45s\n",
      "34:\tlearn: 1.0558908\ttest: 1.2605666\tbest: 1.2605666 (34)\ttotal: 1.88s\tremaining: 1m 45s\n",
      "35:\tlearn: 1.0503992\ttest: 1.2594170\tbest: 1.2594170 (35)\ttotal: 1.92s\tremaining: 1m 44s\n",
      "36:\tlearn: 1.0450733\ttest: 1.2584613\tbest: 1.2584613 (36)\ttotal: 1.97s\tremaining: 1m 44s\n",
      "37:\tlearn: 1.0397871\ttest: 1.2578932\tbest: 1.2578932 (37)\ttotal: 2.02s\tremaining: 1m 44s\n",
      "38:\tlearn: 1.0346996\ttest: 1.2570092\tbest: 1.2570092 (38)\ttotal: 2.07s\tremaining: 1m 44s\n",
      "39:\tlearn: 1.0294691\ttest: 1.2563919\tbest: 1.2563919 (39)\ttotal: 2.12s\tremaining: 1m 44s\n",
      "40:\tlearn: 1.0244799\ttest: 1.2558956\tbest: 1.2558956 (40)\ttotal: 2.18s\tremaining: 1m 43s\n",
      "41:\tlearn: 1.0197453\ttest: 1.2552481\tbest: 1.2552481 (41)\ttotal: 2.22s\tremaining: 1m 43s\n",
      "42:\tlearn: 1.0150241\ttest: 1.2548314\tbest: 1.2548314 (42)\ttotal: 2.28s\tremaining: 1m 43s\n",
      "43:\tlearn: 1.0105282\ttest: 1.2542627\tbest: 1.2542627 (43)\ttotal: 2.33s\tremaining: 1m 43s\n",
      "44:\tlearn: 1.0059817\ttest: 1.2538274\tbest: 1.2538274 (44)\ttotal: 2.39s\tremaining: 1m 43s\n",
      "45:\tlearn: 1.0016370\ttest: 1.2535402\tbest: 1.2535402 (45)\ttotal: 2.44s\tremaining: 1m 43s\n",
      "46:\tlearn: 0.9973480\ttest: 1.2532622\tbest: 1.2532622 (46)\ttotal: 2.5s\tremaining: 1m 43s\n",
      "47:\tlearn: 0.9933786\ttest: 1.2529417\tbest: 1.2529417 (47)\ttotal: 2.54s\tremaining: 1m 43s\n",
      "48:\tlearn: 0.9892786\ttest: 1.2527900\tbest: 1.2527900 (48)\ttotal: 2.6s\tremaining: 1m 43s\n",
      "49:\tlearn: 0.9852227\ttest: 1.2527843\tbest: 1.2527843 (49)\ttotal: 2.66s\tremaining: 1m 43s\n",
      "50:\tlearn: 0.9813343\ttest: 1.2527290\tbest: 1.2527290 (50)\ttotal: 2.72s\tremaining: 1m 43s\n",
      "51:\tlearn: 0.9776560\ttest: 1.2524836\tbest: 1.2524836 (51)\ttotal: 2.76s\tremaining: 1m 43s\n",
      "52:\tlearn: 0.9739332\ttest: 1.2523147\tbest: 1.2523147 (52)\ttotal: 2.82s\tremaining: 1m 43s\n",
      "53:\tlearn: 0.9703303\ttest: 1.2521212\tbest: 1.2521212 (53)\ttotal: 2.87s\tremaining: 1m 43s\n",
      "54:\tlearn: 0.9669309\ttest: 1.2520150\tbest: 1.2520150 (54)\ttotal: 2.92s\tremaining: 1m 43s\n",
      "55:\tlearn: 0.9634565\ttest: 1.2518852\tbest: 1.2518852 (55)\ttotal: 2.97s\tremaining: 1m 43s\n",
      "56:\tlearn: 0.9599628\ttest: 1.2518904\tbest: 1.2518852 (55)\ttotal: 3.03s\tremaining: 1m 43s\n",
      "57:\tlearn: 0.9566269\ttest: 1.2519096\tbest: 1.2518852 (55)\ttotal: 3.08s\tremaining: 1m 43s\n",
      "58:\tlearn: 0.9533817\ttest: 1.2521352\tbest: 1.2518852 (55)\ttotal: 3.15s\tremaining: 1m 43s\n",
      "59:\tlearn: 0.9502657\ttest: 1.2520347\tbest: 1.2518852 (55)\ttotal: 3.2s\tremaining: 1m 43s\n",
      "60:\tlearn: 0.9471418\ttest: 1.2520044\tbest: 1.2518852 (55)\ttotal: 3.26s\tremaining: 1m 43s\n",
      "61:\tlearn: 0.9440533\ttest: 1.2520381\tbest: 1.2518852 (55)\ttotal: 3.31s\tremaining: 1m 43s\n",
      "62:\tlearn: 0.9412293\ttest: 1.2520181\tbest: 1.2518852 (55)\ttotal: 3.37s\tremaining: 1m 43s\n",
      "63:\tlearn: 0.9383220\ttest: 1.2523326\tbest: 1.2518852 (55)\ttotal: 3.42s\tremaining: 1m 43s\n",
      "64:\tlearn: 0.9354753\ttest: 1.2523662\tbest: 1.2518852 (55)\ttotal: 3.48s\tremaining: 1m 43s\n",
      "65:\tlearn: 0.9327352\ttest: 1.2525843\tbest: 1.2518852 (55)\ttotal: 3.53s\tremaining: 1m 43s\n",
      "66:\tlearn: 0.9299759\ttest: 1.2527936\tbest: 1.2518852 (55)\ttotal: 3.59s\tremaining: 1m 43s\n",
      "67:\tlearn: 0.9272592\ttest: 1.2529396\tbest: 1.2518852 (55)\ttotal: 3.64s\tremaining: 1m 43s\n",
      "68:\tlearn: 0.9248244\ttest: 1.2530008\tbest: 1.2518852 (55)\ttotal: 3.69s\tremaining: 1m 43s\n",
      "69:\tlearn: 0.9222815\ttest: 1.2532620\tbest: 1.2518852 (55)\ttotal: 3.75s\tremaining: 1m 43s\n",
      "70:\tlearn: 0.9198412\ttest: 1.2535839\tbest: 1.2518852 (55)\ttotal: 3.81s\tremaining: 1m 43s\n",
      "71:\tlearn: 0.9174403\ttest: 1.2537987\tbest: 1.2518852 (55)\ttotal: 3.86s\tremaining: 1m 43s\n",
      "72:\tlearn: 0.9149520\ttest: 1.2540791\tbest: 1.2518852 (55)\ttotal: 3.91s\tremaining: 1m 43s\n",
      "73:\tlearn: 0.9126664\ttest: 1.2544312\tbest: 1.2518852 (55)\ttotal: 3.96s\tremaining: 1m 43s\n",
      "74:\tlearn: 0.9104194\ttest: 1.2545172\tbest: 1.2518852 (55)\ttotal: 4.01s\tremaining: 1m 42s\n",
      "75:\tlearn: 0.9082673\ttest: 1.2546576\tbest: 1.2518852 (55)\ttotal: 4.06s\tremaining: 1m 42s\n",
      "76:\tlearn: 0.9062345\ttest: 1.2547792\tbest: 1.2518852 (55)\ttotal: 4.11s\tremaining: 1m 42s\n",
      "77:\tlearn: 0.9040783\ttest: 1.2550466\tbest: 1.2518852 (55)\ttotal: 4.16s\tremaining: 1m 42s\n",
      "78:\tlearn: 0.9020018\ttest: 1.2551580\tbest: 1.2518852 (55)\ttotal: 4.21s\tremaining: 1m 42s\n",
      "79:\tlearn: 0.8998431\ttest: 1.2553856\tbest: 1.2518852 (55)\ttotal: 4.26s\tremaining: 1m 42s\n",
      "80:\tlearn: 0.8978051\ttest: 1.2556295\tbest: 1.2518852 (55)\ttotal: 4.31s\tremaining: 1m 42s\n",
      "81:\tlearn: 0.8958120\ttest: 1.2556768\tbest: 1.2518852 (55)\ttotal: 4.37s\tremaining: 1m 42s\n",
      "82:\tlearn: 0.8939032\ttest: 1.2558441\tbest: 1.2518852 (55)\ttotal: 4.42s\tremaining: 1m 42s\n",
      "83:\tlearn: 0.8920267\ttest: 1.2561009\tbest: 1.2518852 (55)\ttotal: 4.47s\tremaining: 1m 42s\n",
      "84:\tlearn: 0.8900753\ttest: 1.2565236\tbest: 1.2518852 (55)\ttotal: 4.53s\tremaining: 1m 42s\n",
      "85:\tlearn: 0.8881021\ttest: 1.2569141\tbest: 1.2518852 (55)\ttotal: 4.59s\tremaining: 1m 42s\n",
      "86:\tlearn: 0.8862384\ttest: 1.2571300\tbest: 1.2518852 (55)\ttotal: 4.63s\tremaining: 1m 41s\n",
      "87:\tlearn: 0.8845102\ttest: 1.2574144\tbest: 1.2518852 (55)\ttotal: 4.69s\tremaining: 1m 41s\n",
      "88:\tlearn: 0.8826743\ttest: 1.2578329\tbest: 1.2518852 (55)\ttotal: 4.74s\tremaining: 1m 41s\n",
      "89:\tlearn: 0.8809524\ttest: 1.2580690\tbest: 1.2518852 (55)\ttotal: 4.79s\tremaining: 1m 41s\n",
      "90:\tlearn: 0.8791641\ttest: 1.2583320\tbest: 1.2518852 (55)\ttotal: 4.84s\tremaining: 1m 41s\n",
      "91:\tlearn: 0.8775367\ttest: 1.2585586\tbest: 1.2518852 (55)\ttotal: 4.88s\tremaining: 1m 41s\n",
      "92:\tlearn: 0.8759231\ttest: 1.2587061\tbest: 1.2518852 (55)\ttotal: 4.93s\tremaining: 1m 41s\n",
      "93:\tlearn: 0.8743793\ttest: 1.2589277\tbest: 1.2518852 (55)\ttotal: 4.97s\tremaining: 1m 40s\n",
      "94:\tlearn: 0.8726609\ttest: 1.2591382\tbest: 1.2518852 (55)\ttotal: 5.03s\tremaining: 1m 40s\n",
      "95:\tlearn: 0.8711766\ttest: 1.2592492\tbest: 1.2518852 (55)\ttotal: 5.08s\tremaining: 1m 40s\n",
      "96:\tlearn: 0.8696299\ttest: 1.2595810\tbest: 1.2518852 (55)\ttotal: 5.13s\tremaining: 1m 40s\n",
      "97:\tlearn: 0.8681531\ttest: 1.2597608\tbest: 1.2518852 (55)\ttotal: 5.18s\tremaining: 1m 40s\n",
      "98:\tlearn: 0.8666026\ttest: 1.2601172\tbest: 1.2518852 (55)\ttotal: 5.24s\tremaining: 1m 40s\n",
      "99:\tlearn: 0.8651364\ttest: 1.2603961\tbest: 1.2518852 (55)\ttotal: 5.29s\tremaining: 1m 40s\n",
      "100:\tlearn: 0.8636891\ttest: 1.2605713\tbest: 1.2518852 (55)\ttotal: 5.33s\tremaining: 1m 40s\n",
      "101:\tlearn: 0.8622709\ttest: 1.2608087\tbest: 1.2518852 (55)\ttotal: 5.38s\tremaining: 1m 40s\n",
      "102:\tlearn: 0.8609298\ttest: 1.2611058\tbest: 1.2518852 (55)\ttotal: 5.43s\tremaining: 1m 40s\n",
      "103:\tlearn: 0.8595103\ttest: 1.2613179\tbest: 1.2518852 (55)\ttotal: 5.49s\tremaining: 1m 40s\n",
      "104:\tlearn: 0.8581364\ttest: 1.2616706\tbest: 1.2518852 (55)\ttotal: 5.54s\tremaining: 1m 40s\n",
      "105:\tlearn: 0.8567468\ttest: 1.2619106\tbest: 1.2518852 (55)\ttotal: 5.6s\tremaining: 1m 40s\n",
      "106:\tlearn: 0.8553703\ttest: 1.2624119\tbest: 1.2518852 (55)\ttotal: 5.66s\tremaining: 1m 40s\n",
      "107:\tlearn: 0.8540183\ttest: 1.2626527\tbest: 1.2518852 (55)\ttotal: 5.71s\tremaining: 1m 40s\n",
      "108:\tlearn: 0.8526956\ttest: 1.2628732\tbest: 1.2518852 (55)\ttotal: 5.76s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.8514617\ttest: 1.2630844\tbest: 1.2518852 (55)\ttotal: 5.81s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.8502930\ttest: 1.2631736\tbest: 1.2518852 (55)\ttotal: 5.85s\tremaining: 1m 39s\n",
      "111:\tlearn: 0.8491502\ttest: 1.2634666\tbest: 1.2518852 (55)\ttotal: 5.9s\tremaining: 1m 39s\n",
      "112:\tlearn: 0.8479851\ttest: 1.2636604\tbest: 1.2518852 (55)\ttotal: 5.95s\tremaining: 1m 39s\n",
      "113:\tlearn: 0.8468753\ttest: 1.2639188\tbest: 1.2518852 (55)\ttotal: 5.99s\tremaining: 1m 39s\n",
      "114:\tlearn: 0.8456608\ttest: 1.2643689\tbest: 1.2518852 (55)\ttotal: 6.05s\tremaining: 1m 39s\n",
      "115:\tlearn: 0.8445340\ttest: 1.2646992\tbest: 1.2518852 (55)\ttotal: 6.11s\tremaining: 1m 39s\n",
      "116:\tlearn: 0.8433743\ttest: 1.2648721\tbest: 1.2518852 (55)\ttotal: 6.16s\tremaining: 1m 39s\n",
      "117:\tlearn: 0.8422267\ttest: 1.2651854\tbest: 1.2518852 (55)\ttotal: 6.22s\tremaining: 1m 39s\n",
      "118:\tlearn: 0.8410980\ttest: 1.2654603\tbest: 1.2518852 (55)\ttotal: 6.27s\tremaining: 1m 39s\n",
      "119:\tlearn: 0.8400436\ttest: 1.2654718\tbest: 1.2518852 (55)\ttotal: 6.31s\tremaining: 1m 38s\n",
      "120:\tlearn: 0.8389100\ttest: 1.2658610\tbest: 1.2518852 (55)\ttotal: 6.37s\tremaining: 1m 38s\n",
      "121:\tlearn: 0.8378625\ttest: 1.2660047\tbest: 1.2518852 (55)\ttotal: 6.43s\tremaining: 1m 38s\n",
      "122:\tlearn: 0.8368112\ttest: 1.2662809\tbest: 1.2518852 (55)\ttotal: 6.48s\tremaining: 1m 38s\n",
      "123:\tlearn: 0.8358275\ttest: 1.2663266\tbest: 1.2518852 (55)\ttotal: 6.53s\tremaining: 1m 38s\n",
      "124:\tlearn: 0.8347106\ttest: 1.2666534\tbest: 1.2518852 (55)\ttotal: 6.58s\tremaining: 1m 38s\n",
      "125:\tlearn: 0.8335355\ttest: 1.2668006\tbest: 1.2518852 (55)\ttotal: 6.64s\tremaining: 1m 38s\n",
      "126:\tlearn: 0.8324923\ttest: 1.2671745\tbest: 1.2518852 (55)\ttotal: 6.7s\tremaining: 1m 38s\n",
      "127:\tlearn: 0.8313978\ttest: 1.2673817\tbest: 1.2518852 (55)\ttotal: 6.75s\tremaining: 1m 38s\n",
      "128:\tlearn: 0.8304300\ttest: 1.2676403\tbest: 1.2518852 (55)\ttotal: 6.79s\tremaining: 1m 38s\n",
      "129:\tlearn: 0.8295589\ttest: 1.2677591\tbest: 1.2518852 (55)\ttotal: 6.84s\tremaining: 1m 38s\n",
      "130:\tlearn: 0.8286601\ttest: 1.2678885\tbest: 1.2518852 (55)\ttotal: 6.88s\tremaining: 1m 38s\n",
      "131:\tlearn: 0.8277555\ttest: 1.2679580\tbest: 1.2518852 (55)\ttotal: 6.92s\tremaining: 1m 38s\n",
      "132:\tlearn: 0.8268410\ttest: 1.2680349\tbest: 1.2518852 (55)\ttotal: 6.97s\tremaining: 1m 37s\n",
      "133:\tlearn: 0.8259327\ttest: 1.2682354\tbest: 1.2518852 (55)\ttotal: 7.02s\tremaining: 1m 37s\n",
      "134:\tlearn: 0.8250110\ttest: 1.2684513\tbest: 1.2518852 (55)\ttotal: 7.08s\tremaining: 1m 37s\n",
      "135:\tlearn: 0.8241165\ttest: 1.2688330\tbest: 1.2518852 (55)\ttotal: 7.13s\tremaining: 1m 37s\n",
      "136:\tlearn: 0.8232018\ttest: 1.2691009\tbest: 1.2518852 (55)\ttotal: 7.19s\tremaining: 1m 37s\n",
      "137:\tlearn: 0.8223301\ttest: 1.2692259\tbest: 1.2518852 (55)\ttotal: 7.23s\tremaining: 1m 37s\n",
      "138:\tlearn: 0.8214578\ttest: 1.2694404\tbest: 1.2518852 (55)\ttotal: 7.28s\tremaining: 1m 37s\n",
      "139:\tlearn: 0.8205753\ttest: 1.2697088\tbest: 1.2518852 (55)\ttotal: 7.33s\tremaining: 1m 37s\n",
      "140:\tlearn: 0.8197548\ttest: 1.2700321\tbest: 1.2518852 (55)\ttotal: 7.39s\tremaining: 1m 37s\n",
      "141:\tlearn: 0.8189353\ttest: 1.2701191\tbest: 1.2518852 (55)\ttotal: 7.45s\tremaining: 1m 37s\n",
      "142:\tlearn: 0.8180942\ttest: 1.2702958\tbest: 1.2518852 (55)\ttotal: 7.5s\tremaining: 1m 37s\n",
      "143:\tlearn: 0.8172510\ttest: 1.2704345\tbest: 1.2518852 (55)\ttotal: 7.54s\tremaining: 1m 37s\n",
      "144:\tlearn: 0.8164443\ttest: 1.2705306\tbest: 1.2518852 (55)\ttotal: 7.59s\tremaining: 1m 37s\n",
      "145:\tlearn: 0.8156901\ttest: 1.2705785\tbest: 1.2518852 (55)\ttotal: 7.63s\tremaining: 1m 36s\n",
      "146:\tlearn: 0.8149477\ttest: 1.2706914\tbest: 1.2518852 (55)\ttotal: 7.67s\tremaining: 1m 36s\n",
      "147:\tlearn: 0.8142096\ttest: 1.2707667\tbest: 1.2518852 (55)\ttotal: 7.71s\tremaining: 1m 36s\n",
      "148:\tlearn: 0.8134668\ttest: 1.2709399\tbest: 1.2518852 (55)\ttotal: 7.76s\tremaining: 1m 36s\n",
      "149:\tlearn: 0.8127206\ttest: 1.2710413\tbest: 1.2518852 (55)\ttotal: 7.8s\tremaining: 1m 36s\n",
      "150:\tlearn: 0.8119758\ttest: 1.2710029\tbest: 1.2518852 (55)\ttotal: 7.84s\tremaining: 1m 36s\n",
      "151:\tlearn: 0.8112015\ttest: 1.2711705\tbest: 1.2518852 (55)\ttotal: 7.89s\tremaining: 1m 35s\n",
      "152:\tlearn: 0.8104577\ttest: 1.2712139\tbest: 1.2518852 (55)\ttotal: 7.93s\tremaining: 1m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  33%|███▎      | 2/6 [00:17<00:35,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153:\tlearn: 0.8096158\ttest: 1.2712979\tbest: 1.2518852 (55)\ttotal: 7.99s\tremaining: 1m 35s\n",
      "154:\tlearn: 0.8088898\ttest: 1.2713914\tbest: 1.2518852 (55)\ttotal: 8.04s\tremaining: 1m 35s\n",
      "155:\tlearn: 0.8081847\ttest: 1.2714977\tbest: 1.2518852 (55)\ttotal: 8.09s\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.251885196\n",
      "bestIteration = 55\n",
      "\n",
      "Shrink model to first 56 iterations.\n",
      "0:\tlearn: 1.3956076\ttest: 1.3759401\tbest: 1.3759401 (0)\ttotal: 43.8ms\tremaining: 1m 27s\n",
      "1:\tlearn: 1.3811671\ttest: 1.3693417\tbest: 1.3693417 (1)\ttotal: 97.6ms\tremaining: 1m 37s\n",
      "2:\tlearn: 1.3671626\ttest: 1.3630299\tbest: 1.3630299 (2)\ttotal: 147ms\tremaining: 1m 38s\n",
      "3:\tlearn: 1.3533622\ttest: 1.3571517\tbest: 1.3571517 (3)\ttotal: 199ms\tremaining: 1m 39s\n",
      "4:\tlearn: 1.3400390\ttest: 1.3516559\tbest: 1.3516559 (4)\ttotal: 255ms\tremaining: 1m 41s\n",
      "5:\tlearn: 1.3270063\ttest: 1.3463508\tbest: 1.3463508 (5)\ttotal: 310ms\tremaining: 1m 42s\n",
      "6:\tlearn: 1.3144274\ttest: 1.3416581\tbest: 1.3416581 (6)\ttotal: 364ms\tremaining: 1m 43s\n",
      "7:\tlearn: 1.3021164\ttest: 1.3370823\tbest: 1.3370823 (7)\ttotal: 419ms\tremaining: 1m 44s\n",
      "8:\tlearn: 1.2900761\ttest: 1.3324435\tbest: 1.3324435 (8)\ttotal: 466ms\tremaining: 1m 43s\n",
      "9:\tlearn: 1.2785133\ttest: 1.3279879\tbest: 1.3279879 (9)\ttotal: 517ms\tremaining: 1m 42s\n",
      "10:\tlearn: 1.2670362\ttest: 1.3237922\tbest: 1.3237922 (10)\ttotal: 570ms\tremaining: 1m 42s\n",
      "11:\tlearn: 1.2559225\ttest: 1.3197097\tbest: 1.3197097 (11)\ttotal: 620ms\tremaining: 1m 42s\n",
      "12:\tlearn: 1.2451245\ttest: 1.3158309\tbest: 1.3158309 (12)\ttotal: 668ms\tremaining: 1m 42s\n",
      "13:\tlearn: 1.2345407\ttest: 1.3122596\tbest: 1.3122596 (13)\ttotal: 723ms\tremaining: 1m 42s\n",
      "14:\tlearn: 1.2242978\ttest: 1.3089798\tbest: 1.3089798 (14)\ttotal: 780ms\tremaining: 1m 43s\n",
      "15:\tlearn: 1.2142732\ttest: 1.3059073\tbest: 1.3059073 (15)\ttotal: 835ms\tremaining: 1m 43s\n",
      "16:\tlearn: 1.2044264\ttest: 1.3032022\tbest: 1.3032022 (16)\ttotal: 887ms\tremaining: 1m 43s\n",
      "17:\tlearn: 1.1949487\ttest: 1.3001462\tbest: 1.3001462 (17)\ttotal: 938ms\tremaining: 1m 43s\n",
      "18:\tlearn: 1.1857209\ttest: 1.2973779\tbest: 1.2973779 (18)\ttotal: 988ms\tremaining: 1m 43s\n",
      "19:\tlearn: 1.1766450\ttest: 1.2949079\tbest: 1.2949079 (19)\ttotal: 1.04s\tremaining: 1m 42s\n",
      "20:\tlearn: 1.1679428\ttest: 1.2925803\tbest: 1.2925803 (20)\ttotal: 1.08s\tremaining: 1m 42s\n",
      "21:\tlearn: 1.1590919\ttest: 1.2905004\tbest: 1.2905004 (21)\ttotal: 1.15s\tremaining: 1m 43s\n",
      "22:\tlearn: 1.1506285\ttest: 1.2884761\tbest: 1.2884761 (22)\ttotal: 1.21s\tremaining: 1m 43s\n",
      "23:\tlearn: 1.1422695\ttest: 1.2867490\tbest: 1.2867490 (23)\ttotal: 1.26s\tremaining: 1m 43s\n",
      "24:\tlearn: 1.1343947\ttest: 1.2848529\tbest: 1.2848529 (24)\ttotal: 1.31s\tremaining: 1m 43s\n",
      "25:\tlearn: 1.1266496\ttest: 1.2831628\tbest: 1.2831628 (25)\ttotal: 1.36s\tremaining: 1m 43s\n",
      "26:\tlearn: 1.1191102\ttest: 1.2815050\tbest: 1.2815050 (26)\ttotal: 1.41s\tremaining: 1m 42s\n",
      "27:\tlearn: 1.1119148\ttest: 1.2802337\tbest: 1.2802337 (27)\ttotal: 1.46s\tremaining: 1m 42s\n",
      "28:\tlearn: 1.1045922\ttest: 1.2790086\tbest: 1.2790086 (28)\ttotal: 1.51s\tremaining: 1m 42s\n",
      "29:\tlearn: 1.0976565\ttest: 1.2777219\tbest: 1.2777219 (29)\ttotal: 1.57s\tremaining: 1m 42s\n",
      "30:\tlearn: 1.0909295\ttest: 1.2765151\tbest: 1.2765151 (30)\ttotal: 1.62s\tremaining: 1m 42s\n",
      "31:\tlearn: 1.0842471\ttest: 1.2754091\tbest: 1.2754091 (31)\ttotal: 1.66s\tremaining: 1m 42s\n",
      "32:\tlearn: 1.0779994\ttest: 1.2744189\tbest: 1.2744189 (32)\ttotal: 1.71s\tremaining: 1m 42s\n",
      "33:\tlearn: 1.0717391\ttest: 1.2734592\tbest: 1.2734592 (33)\ttotal: 1.75s\tremaining: 1m 41s\n",
      "34:\tlearn: 1.0652893\ttest: 1.2726631\tbest: 1.2726631 (34)\ttotal: 1.81s\tremaining: 1m 41s\n",
      "35:\tlearn: 1.0590388\ttest: 1.2719130\tbest: 1.2719130 (35)\ttotal: 1.87s\tremaining: 1m 41s\n",
      "36:\tlearn: 1.0531003\ttest: 1.2712649\tbest: 1.2712649 (36)\ttotal: 1.93s\tremaining: 1m 42s\n",
      "37:\tlearn: 1.0472661\ttest: 1.2707343\tbest: 1.2707343 (37)\ttotal: 2.01s\tremaining: 1m 43s\n",
      "38:\tlearn: 1.0417691\ttest: 1.2701799\tbest: 1.2701799 (38)\ttotal: 2.08s\tremaining: 1m 44s\n",
      "39:\tlearn: 1.0362402\ttest: 1.2698424\tbest: 1.2698424 (39)\ttotal: 2.15s\tremaining: 1m 45s\n",
      "40:\tlearn: 1.0308296\ttest: 1.2693849\tbest: 1.2693849 (40)\ttotal: 2.21s\tremaining: 1m 45s\n",
      "41:\tlearn: 1.0257147\ttest: 1.2691127\tbest: 1.2691127 (41)\ttotal: 2.28s\tremaining: 1m 46s\n",
      "42:\tlearn: 1.0205698\ttest: 1.2686935\tbest: 1.2686935 (42)\ttotal: 2.33s\tremaining: 1m 46s\n",
      "43:\tlearn: 1.0155126\ttest: 1.2683418\tbest: 1.2683418 (43)\ttotal: 2.38s\tremaining: 1m 45s\n",
      "44:\tlearn: 1.0107062\ttest: 1.2681165\tbest: 1.2681165 (44)\ttotal: 2.44s\tremaining: 1m 46s\n",
      "45:\tlearn: 1.0060250\ttest: 1.2679198\tbest: 1.2679198 (45)\ttotal: 2.5s\tremaining: 1m 46s\n",
      "46:\tlearn: 1.0015248\ttest: 1.2676833\tbest: 1.2676833 (46)\ttotal: 2.55s\tremaining: 1m 45s\n",
      "47:\tlearn: 0.9969000\ttest: 1.2675376\tbest: 1.2675376 (47)\ttotal: 2.6s\tremaining: 1m 45s\n",
      "48:\tlearn: 0.9924444\ttest: 1.2674612\tbest: 1.2674612 (48)\ttotal: 2.65s\tremaining: 1m 45s\n",
      "49:\tlearn: 0.9882015\ttest: 1.2675177\tbest: 1.2674612 (48)\ttotal: 2.71s\tremaining: 1m 45s\n",
      "50:\tlearn: 0.9839278\ttest: 1.2675323\tbest: 1.2674612 (48)\ttotal: 2.76s\tremaining: 1m 45s\n",
      "51:\tlearn: 0.9798743\ttest: 1.2675286\tbest: 1.2674612 (48)\ttotal: 2.81s\tremaining: 1m 45s\n",
      "52:\tlearn: 0.9758180\ttest: 1.2674617\tbest: 1.2674612 (48)\ttotal: 2.86s\tremaining: 1m 45s\n",
      "53:\tlearn: 0.9718538\ttest: 1.2675856\tbest: 1.2674612 (48)\ttotal: 2.92s\tremaining: 1m 45s\n",
      "54:\tlearn: 0.9680847\ttest: 1.2675725\tbest: 1.2674612 (48)\ttotal: 2.97s\tremaining: 1m 44s\n",
      "55:\tlearn: 0.9643481\ttest: 1.2676550\tbest: 1.2674612 (48)\ttotal: 3.02s\tremaining: 1m 44s\n",
      "56:\tlearn: 0.9607153\ttest: 1.2677008\tbest: 1.2674612 (48)\ttotal: 3.07s\tremaining: 1m 44s\n",
      "57:\tlearn: 0.9572174\ttest: 1.2679956\tbest: 1.2674612 (48)\ttotal: 3.11s\tremaining: 1m 44s\n",
      "58:\tlearn: 0.9538232\ttest: 1.2681251\tbest: 1.2674612 (48)\ttotal: 3.16s\tremaining: 1m 44s\n",
      "59:\tlearn: 0.9506358\ttest: 1.2683223\tbest: 1.2674612 (48)\ttotal: 3.21s\tremaining: 1m 43s\n",
      "60:\tlearn: 0.9472113\ttest: 1.2684181\tbest: 1.2674612 (48)\ttotal: 3.26s\tremaining: 1m 43s\n",
      "61:\tlearn: 0.9440008\ttest: 1.2685679\tbest: 1.2674612 (48)\ttotal: 3.31s\tremaining: 1m 43s\n",
      "62:\tlearn: 0.9407961\ttest: 1.2688075\tbest: 1.2674612 (48)\ttotal: 3.36s\tremaining: 1m 43s\n",
      "63:\tlearn: 0.9376799\ttest: 1.2691056\tbest: 1.2674612 (48)\ttotal: 3.42s\tremaining: 1m 43s\n",
      "64:\tlearn: 0.9347483\ttest: 1.2693045\tbest: 1.2674612 (48)\ttotal: 3.47s\tremaining: 1m 43s\n",
      "65:\tlearn: 0.9316366\ttest: 1.2695484\tbest: 1.2674612 (48)\ttotal: 3.53s\tremaining: 1m 43s\n",
      "66:\tlearn: 0.9287628\ttest: 1.2698225\tbest: 1.2674612 (48)\ttotal: 3.58s\tremaining: 1m 43s\n",
      "67:\tlearn: 0.9258693\ttest: 1.2700783\tbest: 1.2674612 (48)\ttotal: 3.64s\tremaining: 1m 43s\n",
      "68:\tlearn: 0.9230595\ttest: 1.2703110\tbest: 1.2674612 (48)\ttotal: 3.68s\tremaining: 1m 43s\n",
      "69:\tlearn: 0.9203127\ttest: 1.2706484\tbest: 1.2674612 (48)\ttotal: 3.73s\tremaining: 1m 42s\n",
      "70:\tlearn: 0.9177061\ttest: 1.2709716\tbest: 1.2674612 (48)\ttotal: 3.78s\tremaining: 1m 42s\n",
      "71:\tlearn: 0.9150763\ttest: 1.2713491\tbest: 1.2674612 (48)\ttotal: 3.84s\tremaining: 1m 42s\n",
      "72:\tlearn: 0.9126305\ttest: 1.2717388\tbest: 1.2674612 (48)\ttotal: 3.88s\tremaining: 1m 42s\n",
      "73:\tlearn: 0.9100284\ttest: 1.2720999\tbest: 1.2674612 (48)\ttotal: 3.94s\tremaining: 1m 42s\n",
      "74:\tlearn: 0.9077158\ttest: 1.2723912\tbest: 1.2674612 (48)\ttotal: 3.98s\tremaining: 1m 42s\n",
      "75:\tlearn: 0.9053776\ttest: 1.2727915\tbest: 1.2674612 (48)\ttotal: 4.04s\tremaining: 1m 42s\n",
      "76:\tlearn: 0.9030941\ttest: 1.2731224\tbest: 1.2674612 (48)\ttotal: 4.09s\tremaining: 1m 42s\n",
      "77:\tlearn: 0.9008845\ttest: 1.2734680\tbest: 1.2674612 (48)\ttotal: 4.13s\tremaining: 1m 41s\n",
      "78:\tlearn: 0.8985981\ttest: 1.2737279\tbest: 1.2674612 (48)\ttotal: 4.18s\tremaining: 1m 41s\n",
      "79:\tlearn: 0.8964805\ttest: 1.2741350\tbest: 1.2674612 (48)\ttotal: 4.23s\tremaining: 1m 41s\n",
      "80:\tlearn: 0.8943821\ttest: 1.2744598\tbest: 1.2674612 (48)\ttotal: 4.28s\tremaining: 1m 41s\n",
      "81:\tlearn: 0.8922945\ttest: 1.2748606\tbest: 1.2674612 (48)\ttotal: 4.34s\tremaining: 1m 41s\n",
      "82:\tlearn: 0.8901439\ttest: 1.2753098\tbest: 1.2674612 (48)\ttotal: 4.4s\tremaining: 1m 41s\n",
      "83:\tlearn: 0.8881320\ttest: 1.2756523\tbest: 1.2674612 (48)\ttotal: 4.45s\tremaining: 1m 41s\n",
      "84:\tlearn: 0.8860978\ttest: 1.2759960\tbest: 1.2674612 (48)\ttotal: 4.5s\tremaining: 1m 41s\n",
      "85:\tlearn: 0.8842030\ttest: 1.2762903\tbest: 1.2674612 (48)\ttotal: 4.56s\tremaining: 1m 41s\n",
      "86:\tlearn: 0.8823449\ttest: 1.2765378\tbest: 1.2674612 (48)\ttotal: 4.61s\tremaining: 1m 41s\n",
      "87:\tlearn: 0.8804980\ttest: 1.2769681\tbest: 1.2674612 (48)\ttotal: 4.66s\tremaining: 1m 41s\n",
      "88:\tlearn: 0.8786052\ttest: 1.2773152\tbest: 1.2674612 (48)\ttotal: 4.71s\tremaining: 1m 41s\n",
      "89:\tlearn: 0.8768282\ttest: 1.2776675\tbest: 1.2674612 (48)\ttotal: 4.78s\tremaining: 1m 41s\n",
      "90:\tlearn: 0.8750985\ttest: 1.2779714\tbest: 1.2674612 (48)\ttotal: 4.83s\tremaining: 1m 41s\n",
      "91:\tlearn: 0.8734682\ttest: 1.2783787\tbest: 1.2674612 (48)\ttotal: 4.88s\tremaining: 1m 41s\n",
      "92:\tlearn: 0.8718125\ttest: 1.2786309\tbest: 1.2674612 (48)\ttotal: 4.93s\tremaining: 1m 41s\n",
      "93:\tlearn: 0.8702441\ttest: 1.2788359\tbest: 1.2674612 (48)\ttotal: 4.99s\tremaining: 1m 41s\n",
      "94:\tlearn: 0.8686142\ttest: 1.2792145\tbest: 1.2674612 (48)\ttotal: 5.04s\tremaining: 1m 41s\n",
      "95:\tlearn: 0.8670302\ttest: 1.2794536\tbest: 1.2674612 (48)\ttotal: 5.09s\tremaining: 1m 40s\n",
      "96:\tlearn: 0.8654405\ttest: 1.2799408\tbest: 1.2674612 (48)\ttotal: 5.14s\tremaining: 1m 40s\n",
      "97:\tlearn: 0.8639445\ttest: 1.2802196\tbest: 1.2674612 (48)\ttotal: 5.18s\tremaining: 1m 40s\n",
      "98:\tlearn: 0.8624149\ttest: 1.2806128\tbest: 1.2674612 (48)\ttotal: 5.24s\tremaining: 1m 40s\n",
      "99:\tlearn: 0.8609804\ttest: 1.2808040\tbest: 1.2674612 (48)\ttotal: 5.29s\tremaining: 1m 40s\n",
      "100:\tlearn: 0.8595476\ttest: 1.2811644\tbest: 1.2674612 (48)\ttotal: 5.35s\tremaining: 1m 40s\n",
      "101:\tlearn: 0.8580797\ttest: 1.2815297\tbest: 1.2674612 (48)\ttotal: 5.41s\tremaining: 1m 40s\n",
      "102:\tlearn: 0.8566169\ttest: 1.2819577\tbest: 1.2674612 (48)\ttotal: 5.47s\tremaining: 1m 40s\n",
      "103:\tlearn: 0.8552480\ttest: 1.2823599\tbest: 1.2674612 (48)\ttotal: 5.52s\tremaining: 1m 40s\n",
      "104:\tlearn: 0.8538979\ttest: 1.2827074\tbest: 1.2674612 (48)\ttotal: 5.57s\tremaining: 1m 40s\n",
      "105:\tlearn: 0.8525166\ttest: 1.2830545\tbest: 1.2674612 (48)\ttotal: 5.62s\tremaining: 1m 40s\n",
      "106:\tlearn: 0.8512236\ttest: 1.2832931\tbest: 1.2674612 (48)\ttotal: 5.66s\tremaining: 1m 40s\n",
      "107:\tlearn: 0.8499827\ttest: 1.2835978\tbest: 1.2674612 (48)\ttotal: 5.71s\tremaining: 1m 40s\n",
      "108:\tlearn: 0.8486741\ttest: 1.2838852\tbest: 1.2674612 (48)\ttotal: 5.76s\tremaining: 1m 39s\n",
      "109:\tlearn: 0.8474419\ttest: 1.2841466\tbest: 1.2674612 (48)\ttotal: 5.8s\tremaining: 1m 39s\n",
      "110:\tlearn: 0.8462623\ttest: 1.2844406\tbest: 1.2674612 (48)\ttotal: 5.84s\tremaining: 1m 39s\n",
      "111:\tlearn: 0.8450135\ttest: 1.2847932\tbest: 1.2674612 (48)\ttotal: 5.9s\tremaining: 1m 39s\n",
      "112:\tlearn: 0.8437241\ttest: 1.2852159\tbest: 1.2674612 (48)\ttotal: 5.95s\tremaining: 1m 39s\n",
      "113:\tlearn: 0.8425487\ttest: 1.2853384\tbest: 1.2674612 (48)\ttotal: 6.01s\tremaining: 1m 39s\n",
      "114:\tlearn: 0.8413259\ttest: 1.2857155\tbest: 1.2674612 (48)\ttotal: 6.06s\tremaining: 1m 39s\n",
      "115:\tlearn: 0.8402337\ttest: 1.2860563\tbest: 1.2674612 (48)\ttotal: 6.12s\tremaining: 1m 39s\n",
      "116:\tlearn: 0.8391053\ttest: 1.2862713\tbest: 1.2674612 (48)\ttotal: 6.17s\tremaining: 1m 39s\n",
      "117:\tlearn: 0.8380249\ttest: 1.2863716\tbest: 1.2674612 (48)\ttotal: 6.22s\tremaining: 1m 39s\n",
      "118:\tlearn: 0.8368373\ttest: 1.2866926\tbest: 1.2674612 (48)\ttotal: 6.27s\tremaining: 1m 39s\n",
      "119:\tlearn: 0.8357940\ttest: 1.2869618\tbest: 1.2674612 (48)\ttotal: 6.32s\tremaining: 1m 38s\n",
      "120:\tlearn: 0.8348085\ttest: 1.2871862\tbest: 1.2674612 (48)\ttotal: 6.36s\tremaining: 1m 38s\n",
      "121:\tlearn: 0.8336916\ttest: 1.2875222\tbest: 1.2674612 (48)\ttotal: 6.41s\tremaining: 1m 38s\n",
      "122:\tlearn: 0.8326507\ttest: 1.2875803\tbest: 1.2674612 (48)\ttotal: 6.45s\tremaining: 1m 38s\n",
      "123:\tlearn: 0.8316272\ttest: 1.2878178\tbest: 1.2674612 (48)\ttotal: 6.51s\tremaining: 1m 38s\n",
      "124:\tlearn: 0.8306121\ttest: 1.2880544\tbest: 1.2674612 (48)\ttotal: 6.55s\tremaining: 1m 38s\n",
      "125:\tlearn: 0.8294892\ttest: 1.2884100\tbest: 1.2674612 (48)\ttotal: 6.61s\tremaining: 1m 38s\n",
      "126:\tlearn: 0.8285717\ttest: 1.2886985\tbest: 1.2674612 (48)\ttotal: 6.65s\tremaining: 1m 38s\n",
      "127:\tlearn: 0.8276090\ttest: 1.2890273\tbest: 1.2674612 (48)\ttotal: 6.7s\tremaining: 1m 37s\n",
      "128:\tlearn: 0.8265761\ttest: 1.2893011\tbest: 1.2674612 (48)\ttotal: 6.75s\tremaining: 1m 37s\n",
      "129:\tlearn: 0.8256915\ttest: 1.2894878\tbest: 1.2674612 (48)\ttotal: 6.79s\tremaining: 1m 37s\n",
      "130:\tlearn: 0.8247675\ttest: 1.2897303\tbest: 1.2674612 (48)\ttotal: 6.83s\tremaining: 1m 37s\n",
      "131:\tlearn: 0.8238105\ttest: 1.2900431\tbest: 1.2674612 (48)\ttotal: 6.88s\tremaining: 1m 37s\n",
      "132:\tlearn: 0.8229094\ttest: 1.2902836\tbest: 1.2674612 (48)\ttotal: 6.95s\tremaining: 1m 37s\n",
      "133:\tlearn: 0.8219816\ttest: 1.2904966\tbest: 1.2674612 (48)\ttotal: 6.99s\tremaining: 1m 37s\n",
      "134:\tlearn: 0.8211349\ttest: 1.2906707\tbest: 1.2674612 (48)\ttotal: 7.04s\tremaining: 1m 37s\n",
      "135:\tlearn: 0.8202191\ttest: 1.2908760\tbest: 1.2674612 (48)\ttotal: 7.09s\tremaining: 1m 37s\n",
      "136:\tlearn: 0.8192685\ttest: 1.2910309\tbest: 1.2674612 (48)\ttotal: 7.14s\tremaining: 1m 37s\n",
      "137:\tlearn: 0.8184028\ttest: 1.2912553\tbest: 1.2674612 (48)\ttotal: 7.18s\tremaining: 1m 36s\n",
      "138:\tlearn: 0.8174937\ttest: 1.2913603\tbest: 1.2674612 (48)\ttotal: 7.24s\tremaining: 1m 37s\n",
      "139:\tlearn: 0.8166809\ttest: 1.2913854\tbest: 1.2674612 (48)\ttotal: 7.28s\tremaining: 1m 36s\n",
      "140:\tlearn: 0.8155617\ttest: 1.2916679\tbest: 1.2674612 (48)\ttotal: 7.34s\tremaining: 1m 36s\n",
      "141:\tlearn: 0.8147108\ttest: 1.2918392\tbest: 1.2674612 (48)\ttotal: 7.39s\tremaining: 1m 36s\n",
      "142:\tlearn: 0.8138678\ttest: 1.2919488\tbest: 1.2674612 (48)\ttotal: 7.44s\tremaining: 1m 36s\n",
      "143:\tlearn: 0.8130356\ttest: 1.2920687\tbest: 1.2674612 (48)\ttotal: 7.48s\tremaining: 1m 36s\n",
      "144:\tlearn: 0.8122045\ttest: 1.2921810\tbest: 1.2674612 (48)\ttotal: 7.53s\tremaining: 1m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  50%|█████     | 3/6 [00:26<00:26,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145:\tlearn: 0.8112351\ttest: 1.2924341\tbest: 1.2674612 (48)\ttotal: 7.58s\tremaining: 1m 36s\n",
      "146:\tlearn: 0.8103572\ttest: 1.2927331\tbest: 1.2674612 (48)\ttotal: 7.63s\tremaining: 1m 36s\n",
      "147:\tlearn: 0.8095198\ttest: 1.2928226\tbest: 1.2674612 (48)\ttotal: 7.68s\tremaining: 1m 36s\n",
      "148:\tlearn: 0.8087106\ttest: 1.2929774\tbest: 1.2674612 (48)\ttotal: 7.73s\tremaining: 1m 36s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.267461158\n",
      "bestIteration = 48\n",
      "\n",
      "Shrink model to first 49 iterations.\n",
      "0:\tlearn: 1.3885569\ttest: 1.3274829\tbest: 1.3274829 (0)\ttotal: 39.3ms\tremaining: 1m 18s\n",
      "1:\tlearn: 1.3757000\ttest: 1.3210912\tbest: 1.3210912 (1)\ttotal: 81.3ms\tremaining: 1m 21s\n",
      "2:\tlearn: 1.3634475\ttest: 1.3150453\tbest: 1.3150453 (2)\ttotal: 140ms\tremaining: 1m 33s\n",
      "3:\tlearn: 1.3512079\ttest: 1.3091715\tbest: 1.3091715 (3)\ttotal: 187ms\tremaining: 1m 33s\n",
      "4:\tlearn: 1.3394194\ttest: 1.3037233\tbest: 1.3037233 (4)\ttotal: 239ms\tremaining: 1m 35s\n",
      "5:\tlearn: 1.3278635\ttest: 1.2984392\tbest: 1.2984392 (5)\ttotal: 284ms\tremaining: 1m 34s\n",
      "6:\tlearn: 1.3166790\ttest: 1.2932446\tbest: 1.2932446 (6)\ttotal: 333ms\tremaining: 1m 34s\n",
      "7:\tlearn: 1.3056096\ttest: 1.2881789\tbest: 1.2881789 (7)\ttotal: 383ms\tremaining: 1m 35s\n",
      "8:\tlearn: 1.2951667\ttest: 1.2836114\tbest: 1.2836114 (8)\ttotal: 429ms\tremaining: 1m 34s\n",
      "9:\tlearn: 1.2848758\ttest: 1.2789561\tbest: 1.2789561 (9)\ttotal: 472ms\tremaining: 1m 34s\n",
      "10:\tlearn: 1.2747719\ttest: 1.2746599\tbest: 1.2746599 (10)\ttotal: 522ms\tremaining: 1m 34s\n",
      "11:\tlearn: 1.2650186\ttest: 1.2707726\tbest: 1.2707726 (11)\ttotal: 571ms\tremaining: 1m 34s\n",
      "12:\tlearn: 1.2554245\ttest: 1.2668207\tbest: 1.2668207 (12)\ttotal: 620ms\tremaining: 1m 34s\n",
      "13:\tlearn: 1.2460517\ttest: 1.2631542\tbest: 1.2631542 (13)\ttotal: 669ms\tremaining: 1m 34s\n",
      "14:\tlearn: 1.2369218\ttest: 1.2600504\tbest: 1.2600504 (14)\ttotal: 727ms\tremaining: 1m 36s\n",
      "15:\tlearn: 1.2280348\ttest: 1.2567415\tbest: 1.2567415 (15)\ttotal: 780ms\tremaining: 1m 36s\n",
      "16:\tlearn: 1.2194668\ttest: 1.2535894\tbest: 1.2535894 (16)\ttotal: 829ms\tremaining: 1m 36s\n",
      "17:\tlearn: 1.2109817\ttest: 1.2510707\tbest: 1.2510707 (17)\ttotal: 885ms\tremaining: 1m 37s\n",
      "18:\tlearn: 1.2029289\ttest: 1.2484121\tbest: 1.2484121 (18)\ttotal: 941ms\tremaining: 1m 38s\n",
      "19:\tlearn: 1.1950457\ttest: 1.2457814\tbest: 1.2457814 (19)\ttotal: 994ms\tremaining: 1m 38s\n",
      "20:\tlearn: 1.1873569\ttest: 1.2432061\tbest: 1.2432061 (20)\ttotal: 1.05s\tremaining: 1m 38s\n",
      "21:\tlearn: 1.1798644\ttest: 1.2407347\tbest: 1.2407347 (21)\ttotal: 1.1s\tremaining: 1m 38s\n",
      "22:\tlearn: 1.1723705\ttest: 1.2388354\tbest: 1.2388354 (22)\ttotal: 1.15s\tremaining: 1m 39s\n",
      "23:\tlearn: 1.1650777\ttest: 1.2371512\tbest: 1.2371512 (23)\ttotal: 1.21s\tremaining: 1m 39s\n",
      "24:\tlearn: 1.1581583\ttest: 1.2352664\tbest: 1.2352664 (24)\ttotal: 1.26s\tremaining: 1m 39s\n",
      "25:\tlearn: 1.1513955\ttest: 1.2333986\tbest: 1.2333986 (25)\ttotal: 1.3s\tremaining: 1m 39s\n",
      "26:\tlearn: 1.1446453\ttest: 1.2320274\tbest: 1.2320274 (26)\ttotal: 1.36s\tremaining: 1m 39s\n",
      "27:\tlearn: 1.1381916\ttest: 1.2304890\tbest: 1.2304890 (27)\ttotal: 1.41s\tremaining: 1m 39s\n",
      "28:\tlearn: 1.1319448\ttest: 1.2292039\tbest: 1.2292039 (28)\ttotal: 1.45s\tremaining: 1m 38s\n",
      "29:\tlearn: 1.1257972\ttest: 1.2277684\tbest: 1.2277684 (29)\ttotal: 1.5s\tremaining: 1m 38s\n",
      "30:\tlearn: 1.1197771\ttest: 1.2265970\tbest: 1.2265970 (30)\ttotal: 1.54s\tremaining: 1m 38s\n",
      "31:\tlearn: 1.1139166\ttest: 1.2251981\tbest: 1.2251981 (31)\ttotal: 1.59s\tremaining: 1m 37s\n",
      "32:\tlearn: 1.1081533\ttest: 1.2243944\tbest: 1.2243944 (32)\ttotal: 1.65s\tremaining: 1m 38s\n",
      "33:\tlearn: 1.1025683\ttest: 1.2234124\tbest: 1.2234124 (33)\ttotal: 1.7s\tremaining: 1m 38s\n",
      "34:\tlearn: 1.0971817\ttest: 1.2227278\tbest: 1.2227278 (34)\ttotal: 1.75s\tremaining: 1m 38s\n",
      "35:\tlearn: 1.0919825\ttest: 1.2218274\tbest: 1.2218274 (35)\ttotal: 1.81s\tremaining: 1m 38s\n",
      "36:\tlearn: 1.0868873\ttest: 1.2210308\tbest: 1.2210308 (36)\ttotal: 1.85s\tremaining: 1m 38s\n",
      "37:\tlearn: 1.0817685\ttest: 1.2204274\tbest: 1.2204274 (37)\ttotal: 1.9s\tremaining: 1m 38s\n",
      "38:\tlearn: 1.0768273\ttest: 1.2197173\tbest: 1.2197173 (38)\ttotal: 1.95s\tremaining: 1m 38s\n",
      "39:\tlearn: 1.0721375\ttest: 1.2188869\tbest: 1.2188869 (39)\ttotal: 2.01s\tremaining: 1m 38s\n",
      "40:\tlearn: 1.0674737\ttest: 1.2183852\tbest: 1.2183852 (40)\ttotal: 2.06s\tremaining: 1m 38s\n",
      "41:\tlearn: 1.0628789\ttest: 1.2177392\tbest: 1.2177392 (41)\ttotal: 2.12s\tremaining: 1m 38s\n",
      "42:\tlearn: 1.0583700\ttest: 1.2172179\tbest: 1.2172179 (42)\ttotal: 2.17s\tremaining: 1m 38s\n",
      "43:\tlearn: 1.0538400\ttest: 1.2170291\tbest: 1.2170291 (43)\ttotal: 2.22s\tremaining: 1m 38s\n",
      "44:\tlearn: 1.0495537\ttest: 1.2167305\tbest: 1.2167305 (44)\ttotal: 2.27s\tremaining: 1m 38s\n",
      "45:\tlearn: 1.0455070\ttest: 1.2163720\tbest: 1.2163720 (45)\ttotal: 2.32s\tremaining: 1m 38s\n",
      "46:\tlearn: 1.0415634\ttest: 1.2161795\tbest: 1.2161795 (46)\ttotal: 2.37s\tremaining: 1m 38s\n",
      "47:\tlearn: 1.0377415\ttest: 1.2159602\tbest: 1.2159602 (47)\ttotal: 2.42s\tremaining: 1m 38s\n",
      "48:\tlearn: 1.0339388\ttest: 1.2157343\tbest: 1.2157343 (48)\ttotal: 2.47s\tremaining: 1m 38s\n",
      "49:\tlearn: 1.0302448\ttest: 1.2159172\tbest: 1.2157343 (48)\ttotal: 2.52s\tremaining: 1m 38s\n",
      "50:\tlearn: 1.0266219\ttest: 1.2159556\tbest: 1.2157343 (48)\ttotal: 2.58s\tremaining: 1m 38s\n",
      "51:\tlearn: 1.0229453\ttest: 1.2158467\tbest: 1.2157343 (48)\ttotal: 2.63s\tremaining: 1m 38s\n",
      "52:\tlearn: 1.0195264\ttest: 1.2157858\tbest: 1.2157343 (48)\ttotal: 2.68s\tremaining: 1m 38s\n",
      "53:\tlearn: 1.0161770\ttest: 1.2159416\tbest: 1.2157343 (48)\ttotal: 2.73s\tremaining: 1m 38s\n",
      "54:\tlearn: 1.0126836\ttest: 1.2160375\tbest: 1.2157343 (48)\ttotal: 2.79s\tremaining: 1m 38s\n",
      "55:\tlearn: 1.0094628\ttest: 1.2160506\tbest: 1.2157343 (48)\ttotal: 2.85s\tremaining: 1m 38s\n",
      "56:\tlearn: 1.0063380\ttest: 1.2162094\tbest: 1.2157343 (48)\ttotal: 2.9s\tremaining: 1m 38s\n",
      "57:\tlearn: 1.0033246\ttest: 1.2163652\tbest: 1.2157343 (48)\ttotal: 2.94s\tremaining: 1m 38s\n",
      "58:\tlearn: 1.0003079\ttest: 1.2165032\tbest: 1.2157343 (48)\ttotal: 2.99s\tremaining: 1m 38s\n",
      "59:\tlearn: 0.9973334\ttest: 1.2164857\tbest: 1.2157343 (48)\ttotal: 3.04s\tremaining: 1m 38s\n",
      "60:\tlearn: 0.9944899\ttest: 1.2166869\tbest: 1.2157343 (48)\ttotal: 3.09s\tremaining: 1m 38s\n",
      "61:\tlearn: 0.9915585\ttest: 1.2168336\tbest: 1.2157343 (48)\ttotal: 3.15s\tremaining: 1m 38s\n",
      "62:\tlearn: 0.9886597\ttest: 1.2170083\tbest: 1.2157343 (48)\ttotal: 3.2s\tremaining: 1m 38s\n",
      "63:\tlearn: 0.9860490\ttest: 1.2172684\tbest: 1.2157343 (48)\ttotal: 3.26s\tremaining: 1m 38s\n",
      "64:\tlearn: 0.9833433\ttest: 1.2174459\tbest: 1.2157343 (48)\ttotal: 3.31s\tremaining: 1m 38s\n",
      "65:\tlearn: 0.9806824\ttest: 1.2179726\tbest: 1.2157343 (48)\ttotal: 3.38s\tremaining: 1m 38s\n",
      "66:\tlearn: 0.9780360\ttest: 1.2182872\tbest: 1.2157343 (48)\ttotal: 3.42s\tremaining: 1m 38s\n",
      "67:\tlearn: 0.9755788\ttest: 1.2184495\tbest: 1.2157343 (48)\ttotal: 3.47s\tremaining: 1m 38s\n",
      "68:\tlearn: 0.9731150\ttest: 1.2187347\tbest: 1.2157343 (48)\ttotal: 3.52s\tremaining: 1m 38s\n",
      "69:\tlearn: 0.9706931\ttest: 1.2189356\tbest: 1.2157343 (48)\ttotal: 3.58s\tremaining: 1m 38s\n",
      "70:\tlearn: 0.9684980\ttest: 1.2191429\tbest: 1.2157343 (48)\ttotal: 3.63s\tremaining: 1m 38s\n",
      "71:\tlearn: 0.9662754\ttest: 1.2193550\tbest: 1.2157343 (48)\ttotal: 3.68s\tremaining: 1m 38s\n",
      "72:\tlearn: 0.9640962\ttest: 1.2195028\tbest: 1.2157343 (48)\ttotal: 3.73s\tremaining: 1m 38s\n",
      "73:\tlearn: 0.9618241\ttest: 1.2199209\tbest: 1.2157343 (48)\ttotal: 3.79s\tremaining: 1m 38s\n",
      "74:\tlearn: 0.9597449\ttest: 1.2200180\tbest: 1.2157343 (48)\ttotal: 3.84s\tremaining: 1m 38s\n",
      "75:\tlearn: 0.9576963\ttest: 1.2203351\tbest: 1.2157343 (48)\ttotal: 3.9s\tremaining: 1m 38s\n",
      "76:\tlearn: 0.9555257\ttest: 1.2206407\tbest: 1.2157343 (48)\ttotal: 3.95s\tremaining: 1m 38s\n",
      "77:\tlearn: 0.9535333\ttest: 1.2209495\tbest: 1.2157343 (48)\ttotal: 4s\tremaining: 1m 38s\n",
      "78:\tlearn: 0.9513944\ttest: 1.2213799\tbest: 1.2157343 (48)\ttotal: 4.06s\tremaining: 1m 38s\n",
      "79:\tlearn: 0.9493096\ttest: 1.2217486\tbest: 1.2157343 (48)\ttotal: 4.11s\tremaining: 1m 38s\n",
      "80:\tlearn: 0.9473435\ttest: 1.2222884\tbest: 1.2157343 (48)\ttotal: 4.17s\tremaining: 1m 38s\n",
      "81:\tlearn: 0.9454648\ttest: 1.2227588\tbest: 1.2157343 (48)\ttotal: 4.22s\tremaining: 1m 38s\n",
      "82:\tlearn: 0.9437153\ttest: 1.2231244\tbest: 1.2157343 (48)\ttotal: 4.28s\tremaining: 1m 38s\n",
      "83:\tlearn: 0.9417930\ttest: 1.2233529\tbest: 1.2157343 (48)\ttotal: 4.33s\tremaining: 1m 38s\n",
      "84:\tlearn: 0.9399345\ttest: 1.2235994\tbest: 1.2157343 (48)\ttotal: 4.38s\tremaining: 1m 38s\n",
      "85:\tlearn: 0.9381452\ttest: 1.2238787\tbest: 1.2157343 (48)\ttotal: 4.43s\tremaining: 1m 38s\n",
      "86:\tlearn: 0.9365192\ttest: 1.2239855\tbest: 1.2157343 (48)\ttotal: 4.49s\tremaining: 1m 38s\n",
      "87:\tlearn: 0.9348346\ttest: 1.2243565\tbest: 1.2157343 (48)\ttotal: 4.54s\tremaining: 1m 38s\n",
      "88:\tlearn: 0.9332014\ttest: 1.2247438\tbest: 1.2157343 (48)\ttotal: 4.59s\tremaining: 1m 38s\n",
      "89:\tlearn: 0.9315059\ttest: 1.2251900\tbest: 1.2157343 (48)\ttotal: 4.64s\tremaining: 1m 38s\n",
      "90:\tlearn: 0.9299279\ttest: 1.2255127\tbest: 1.2157343 (48)\ttotal: 4.71s\tremaining: 1m 38s\n",
      "91:\tlearn: 0.9283547\ttest: 1.2258051\tbest: 1.2157343 (48)\ttotal: 4.76s\tremaining: 1m 38s\n",
      "92:\tlearn: 0.9268126\ttest: 1.2261704\tbest: 1.2157343 (48)\ttotal: 4.81s\tremaining: 1m 38s\n",
      "93:\tlearn: 0.9253116\ttest: 1.2264931\tbest: 1.2157343 (48)\ttotal: 4.85s\tremaining: 1m 38s\n",
      "94:\tlearn: 0.9237860\ttest: 1.2267309\tbest: 1.2157343 (48)\ttotal: 4.9s\tremaining: 1m 38s\n",
      "95:\tlearn: 0.9223662\ttest: 1.2270175\tbest: 1.2157343 (48)\ttotal: 4.95s\tremaining: 1m 38s\n",
      "96:\tlearn: 0.9208978\ttest: 1.2272871\tbest: 1.2157343 (48)\ttotal: 5s\tremaining: 1m 38s\n",
      "97:\tlearn: 0.9195003\ttest: 1.2275088\tbest: 1.2157343 (48)\ttotal: 5.05s\tremaining: 1m 37s\n",
      "98:\tlearn: 0.9179607\ttest: 1.2278660\tbest: 1.2157343 (48)\ttotal: 5.11s\tremaining: 1m 38s\n",
      "99:\tlearn: 0.9166764\ttest: 1.2279876\tbest: 1.2157343 (48)\ttotal: 5.16s\tremaining: 1m 37s\n",
      "100:\tlearn: 0.9152510\ttest: 1.2282348\tbest: 1.2157343 (48)\ttotal: 5.22s\tremaining: 1m 38s\n",
      "101:\tlearn: 0.9138912\ttest: 1.2285802\tbest: 1.2157343 (48)\ttotal: 5.27s\tremaining: 1m 38s\n",
      "102:\tlearn: 0.9124726\ttest: 1.2289580\tbest: 1.2157343 (48)\ttotal: 5.33s\tremaining: 1m 38s\n",
      "103:\tlearn: 0.9111426\ttest: 1.2293442\tbest: 1.2157343 (48)\ttotal: 5.38s\tremaining: 1m 38s\n",
      "104:\tlearn: 0.9098145\ttest: 1.2295739\tbest: 1.2157343 (48)\ttotal: 5.43s\tremaining: 1m 38s\n",
      "105:\tlearn: 0.9084563\ttest: 1.2300409\tbest: 1.2157343 (48)\ttotal: 5.49s\tremaining: 1m 38s\n",
      "106:\tlearn: 0.9071400\ttest: 1.2302475\tbest: 1.2157343 (48)\ttotal: 5.54s\tremaining: 1m 38s\n",
      "107:\tlearn: 0.9059466\ttest: 1.2304912\tbest: 1.2157343 (48)\ttotal: 5.6s\tremaining: 1m 38s\n",
      "108:\tlearn: 0.9047288\ttest: 1.2309172\tbest: 1.2157343 (48)\ttotal: 5.65s\tremaining: 1m 38s\n",
      "109:\tlearn: 0.9035902\ttest: 1.2313588\tbest: 1.2157343 (48)\ttotal: 5.7s\tremaining: 1m 37s\n",
      "110:\tlearn: 0.9023434\ttest: 1.2319272\tbest: 1.2157343 (48)\ttotal: 5.76s\tremaining: 1m 37s\n",
      "111:\tlearn: 0.9012717\ttest: 1.2320297\tbest: 1.2157343 (48)\ttotal: 5.81s\tremaining: 1m 37s\n",
      "112:\tlearn: 0.9000708\ttest: 1.2323569\tbest: 1.2157343 (48)\ttotal: 5.87s\tremaining: 1m 37s\n",
      "113:\tlearn: 0.8988625\ttest: 1.2325760\tbest: 1.2157343 (48)\ttotal: 5.92s\tremaining: 1m 37s\n",
      "114:\tlearn: 0.8977294\ttest: 1.2329132\tbest: 1.2157343 (48)\ttotal: 5.97s\tremaining: 1m 37s\n",
      "115:\tlearn: 0.8966239\ttest: 1.2331999\tbest: 1.2157343 (48)\ttotal: 6.03s\tremaining: 1m 37s\n",
      "116:\tlearn: 0.8955202\ttest: 1.2334800\tbest: 1.2157343 (48)\ttotal: 6.08s\tremaining: 1m 37s\n",
      "117:\tlearn: 0.8944299\ttest: 1.2335275\tbest: 1.2157343 (48)\ttotal: 6.13s\tremaining: 1m 37s\n",
      "118:\tlearn: 0.8934772\ttest: 1.2338009\tbest: 1.2157343 (48)\ttotal: 6.17s\tremaining: 1m 37s\n",
      "119:\tlearn: 0.8923236\ttest: 1.2341327\tbest: 1.2157343 (48)\ttotal: 6.23s\tremaining: 1m 37s\n",
      "120:\tlearn: 0.8912895\ttest: 1.2344229\tbest: 1.2157343 (48)\ttotal: 6.28s\tremaining: 1m 37s\n",
      "121:\tlearn: 0.8903075\ttest: 1.2346602\tbest: 1.2157343 (48)\ttotal: 6.33s\tremaining: 1m 37s\n",
      "122:\tlearn: 0.8892043\ttest: 1.2347760\tbest: 1.2157343 (48)\ttotal: 6.38s\tremaining: 1m 37s\n",
      "123:\tlearn: 0.8881801\ttest: 1.2352663\tbest: 1.2157343 (48)\ttotal: 6.43s\tremaining: 1m 37s\n",
      "124:\tlearn: 0.8871346\ttest: 1.2353744\tbest: 1.2157343 (48)\ttotal: 6.51s\tremaining: 1m 37s\n",
      "125:\tlearn: 0.8861460\ttest: 1.2356559\tbest: 1.2157343 (48)\ttotal: 6.6s\tremaining: 1m 38s\n",
      "126:\tlearn: 0.8851543\ttest: 1.2357930\tbest: 1.2157343 (48)\ttotal: 6.67s\tremaining: 1m 38s\n",
      "127:\tlearn: 0.8841047\ttest: 1.2359866\tbest: 1.2157343 (48)\ttotal: 6.73s\tremaining: 1m 38s\n",
      "128:\tlearn: 0.8830432\ttest: 1.2362952\tbest: 1.2157343 (48)\ttotal: 6.78s\tremaining: 1m 38s\n",
      "129:\tlearn: 0.8821394\ttest: 1.2365398\tbest: 1.2157343 (48)\ttotal: 6.83s\tremaining: 1m 38s\n",
      "130:\tlearn: 0.8811817\ttest: 1.2368514\tbest: 1.2157343 (48)\ttotal: 6.89s\tremaining: 1m 38s\n",
      "131:\tlearn: 0.8802455\ttest: 1.2370367\tbest: 1.2157343 (48)\ttotal: 6.95s\tremaining: 1m 38s\n",
      "132:\tlearn: 0.8793728\ttest: 1.2374320\tbest: 1.2157343 (48)\ttotal: 7.01s\tremaining: 1m 38s\n",
      "133:\tlearn: 0.8784187\ttest: 1.2377380\tbest: 1.2157343 (48)\ttotal: 7.07s\tremaining: 1m 38s\n",
      "134:\tlearn: 0.8775347\ttest: 1.2378794\tbest: 1.2157343 (48)\ttotal: 7.13s\tremaining: 1m 38s\n",
      "135:\tlearn: 0.8765740\ttest: 1.2382479\tbest: 1.2157343 (48)\ttotal: 7.18s\tremaining: 1m 38s\n",
      "136:\tlearn: 0.8756819\ttest: 1.2385639\tbest: 1.2157343 (48)\ttotal: 7.22s\tremaining: 1m 38s\n",
      "137:\tlearn: 0.8748658\ttest: 1.2387578\tbest: 1.2157343 (48)\ttotal: 7.27s\tremaining: 1m 38s\n",
      "138:\tlearn: 0.8739828\ttest: 1.2390442\tbest: 1.2157343 (48)\ttotal: 7.32s\tremaining: 1m 38s\n",
      "139:\tlearn: 0.8731953\ttest: 1.2391422\tbest: 1.2157343 (48)\ttotal: 7.37s\tremaining: 1m 37s\n",
      "140:\tlearn: 0.8723791\ttest: 1.2393729\tbest: 1.2157343 (48)\ttotal: 7.43s\tremaining: 1m 37s\n",
      "141:\tlearn: 0.8715667\ttest: 1.2396902\tbest: 1.2157343 (48)\ttotal: 7.48s\tremaining: 1m 37s\n",
      "142:\tlearn: 0.8707058\ttest: 1.2398136\tbest: 1.2157343 (48)\ttotal: 7.52s\tremaining: 1m 37s\n",
      "143:\tlearn: 0.8697383\ttest: 1.2398984\tbest: 1.2157343 (48)\ttotal: 7.57s\tremaining: 1m 37s\n",
      "144:\tlearn: 0.8688871\ttest: 1.2400153\tbest: 1.2157343 (48)\ttotal: 7.62s\tremaining: 1m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  67%|██████▋   | 4/6 [00:34<00:17,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145:\tlearn: 0.8680835\ttest: 1.2402932\tbest: 1.2157343 (48)\ttotal: 7.67s\tremaining: 1m 37s\n",
      "146:\tlearn: 0.8673070\ttest: 1.2405156\tbest: 1.2157343 (48)\ttotal: 7.73s\tremaining: 1m 37s\n",
      "147:\tlearn: 0.8665007\ttest: 1.2407457\tbest: 1.2157343 (48)\ttotal: 7.78s\tremaining: 1m 37s\n",
      "148:\tlearn: 0.8655727\ttest: 1.2408228\tbest: 1.2157343 (48)\ttotal: 7.83s\tremaining: 1m 37s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.21573433\n",
      "bestIteration = 48\n",
      "\n",
      "Shrink model to first 49 iterations.\n",
      "0:\tlearn: 1.3207973\ttest: 1.3467931\tbest: 1.3467931 (0)\ttotal: 40.8ms\tremaining: 1m 21s\n",
      "1:\tlearn: 1.3119500\ttest: 1.3408264\tbest: 1.3408264 (1)\ttotal: 90.9ms\tremaining: 1m 30s\n",
      "2:\tlearn: 1.3033433\ttest: 1.3347315\tbest: 1.3347315 (2)\ttotal: 137ms\tremaining: 1m 30s\n",
      "3:\tlearn: 1.2951592\ttest: 1.3290190\tbest: 1.3290190 (3)\ttotal: 180ms\tremaining: 1m 29s\n",
      "4:\tlearn: 1.2871970\ttest: 1.3238397\tbest: 1.3238397 (4)\ttotal: 229ms\tremaining: 1m 31s\n",
      "5:\tlearn: 1.2793465\ttest: 1.3188744\tbest: 1.3188744 (5)\ttotal: 274ms\tremaining: 1m 31s\n",
      "6:\tlearn: 1.2716976\ttest: 1.3140403\tbest: 1.3140403 (6)\ttotal: 320ms\tremaining: 1m 31s\n",
      "7:\tlearn: 1.2643694\ttest: 1.3095583\tbest: 1.3095583 (7)\ttotal: 369ms\tremaining: 1m 31s\n",
      "8:\tlearn: 1.2572946\ttest: 1.3054951\tbest: 1.3054951 (8)\ttotal: 424ms\tremaining: 1m 33s\n",
      "9:\tlearn: 1.2504665\ttest: 1.3017364\tbest: 1.3017364 (9)\ttotal: 473ms\tremaining: 1m 34s\n",
      "10:\tlearn: 1.2437903\ttest: 1.2977595\tbest: 1.2977595 (10)\ttotal: 521ms\tremaining: 1m 34s\n",
      "11:\tlearn: 1.2371713\ttest: 1.2941078\tbest: 1.2941078 (11)\ttotal: 571ms\tremaining: 1m 34s\n",
      "12:\tlearn: 1.2309070\ttest: 1.2908759\tbest: 1.2908759 (12)\ttotal: 625ms\tremaining: 1m 35s\n",
      "13:\tlearn: 1.2247538\ttest: 1.2872848\tbest: 1.2872848 (13)\ttotal: 676ms\tremaining: 1m 35s\n",
      "14:\tlearn: 1.2186809\ttest: 1.2840652\tbest: 1.2840652 (14)\ttotal: 729ms\tremaining: 1m 36s\n",
      "15:\tlearn: 1.2126409\ttest: 1.2810754\tbest: 1.2810754 (15)\ttotal: 793ms\tremaining: 1m 38s\n",
      "16:\tlearn: 1.2069678\ttest: 1.2781059\tbest: 1.2781059 (16)\ttotal: 840ms\tremaining: 1m 38s\n",
      "17:\tlearn: 1.2015387\ttest: 1.2753742\tbest: 1.2753742 (17)\ttotal: 888ms\tremaining: 1m 37s\n",
      "18:\tlearn: 1.1963221\ttest: 1.2725893\tbest: 1.2725893 (18)\ttotal: 935ms\tremaining: 1m 37s\n",
      "19:\tlearn: 1.1912210\ttest: 1.2701359\tbest: 1.2701359 (19)\ttotal: 983ms\tremaining: 1m 37s\n",
      "20:\tlearn: 1.1861274\ttest: 1.2678484\tbest: 1.2678484 (20)\ttotal: 1.04s\tremaining: 1m 37s\n",
      "21:\tlearn: 1.1812712\ttest: 1.2656384\tbest: 1.2656384 (21)\ttotal: 1.09s\tremaining: 1m 38s\n",
      "22:\tlearn: 1.1763835\ttest: 1.2636326\tbest: 1.2636326 (22)\ttotal: 1.14s\tremaining: 1m 38s\n",
      "23:\tlearn: 1.1716902\ttest: 1.2617761\tbest: 1.2617761 (23)\ttotal: 1.19s\tremaining: 1m 38s\n",
      "24:\tlearn: 1.1672945\ttest: 1.2599400\tbest: 1.2599400 (24)\ttotal: 1.24s\tremaining: 1m 37s\n",
      "25:\tlearn: 1.1629542\ttest: 1.2581292\tbest: 1.2581292 (25)\ttotal: 1.28s\tremaining: 1m 37s\n",
      "26:\tlearn: 1.1587105\ttest: 1.2564694\tbest: 1.2564694 (26)\ttotal: 1.33s\tremaining: 1m 37s\n",
      "27:\tlearn: 1.1544229\ttest: 1.2550731\tbest: 1.2550731 (27)\ttotal: 1.39s\tremaining: 1m 37s\n",
      "28:\tlearn: 1.1503412\ttest: 1.2537447\tbest: 1.2537447 (28)\ttotal: 1.44s\tremaining: 1m 37s\n",
      "29:\tlearn: 1.1464585\ttest: 1.2526623\tbest: 1.2526623 (29)\ttotal: 1.49s\tremaining: 1m 37s\n",
      "30:\tlearn: 1.1426594\ttest: 1.2515259\tbest: 1.2515259 (30)\ttotal: 1.53s\tremaining: 1m 37s\n",
      "31:\tlearn: 1.1389692\ttest: 1.2506102\tbest: 1.2506102 (31)\ttotal: 1.59s\tremaining: 1m 37s\n",
      "32:\tlearn: 1.1353147\ttest: 1.2495279\tbest: 1.2495279 (32)\ttotal: 1.64s\tremaining: 1m 37s\n",
      "33:\tlearn: 1.1319167\ttest: 1.2483924\tbest: 1.2483924 (33)\ttotal: 1.68s\tremaining: 1m 37s\n",
      "34:\tlearn: 1.1285750\ttest: 1.2474832\tbest: 1.2474832 (34)\ttotal: 1.73s\tremaining: 1m 37s\n",
      "35:\tlearn: 1.1252845\ttest: 1.2467984\tbest: 1.2467984 (35)\ttotal: 1.78s\tremaining: 1m 37s\n",
      "36:\tlearn: 1.1221383\ttest: 1.2460561\tbest: 1.2460561 (36)\ttotal: 1.83s\tremaining: 1m 37s\n",
      "37:\tlearn: 1.1190233\ttest: 1.2453041\tbest: 1.2453041 (37)\ttotal: 1.88s\tremaining: 1m 37s\n",
      "38:\tlearn: 1.1159624\ttest: 1.2447346\tbest: 1.2447346 (38)\ttotal: 1.93s\tremaining: 1m 36s\n",
      "39:\tlearn: 1.1130160\ttest: 1.2443497\tbest: 1.2443497 (39)\ttotal: 1.98s\tremaining: 1m 36s\n",
      "40:\tlearn: 1.1102125\ttest: 1.2441544\tbest: 1.2441544 (40)\ttotal: 2.03s\tremaining: 1m 36s\n",
      "41:\tlearn: 1.1074643\ttest: 1.2437518\tbest: 1.2437518 (41)\ttotal: 2.09s\tremaining: 1m 37s\n",
      "42:\tlearn: 1.1048022\ttest: 1.2432881\tbest: 1.2432881 (42)\ttotal: 2.14s\tremaining: 1m 37s\n",
      "43:\tlearn: 1.1021106\ttest: 1.2429078\tbest: 1.2429078 (43)\ttotal: 2.19s\tremaining: 1m 37s\n",
      "44:\tlearn: 1.0996216\ttest: 1.2424737\tbest: 1.2424737 (44)\ttotal: 2.23s\tremaining: 1m 37s\n",
      "45:\tlearn: 1.0971221\ttest: 1.2423040\tbest: 1.2423040 (45)\ttotal: 2.28s\tremaining: 1m 36s\n",
      "46:\tlearn: 1.0948003\ttest: 1.2420456\tbest: 1.2420456 (46)\ttotal: 2.33s\tremaining: 1m 36s\n",
      "47:\tlearn: 1.0925108\ttest: 1.2419474\tbest: 1.2419474 (47)\ttotal: 2.38s\tremaining: 1m 36s\n",
      "48:\tlearn: 1.0902540\ttest: 1.2418266\tbest: 1.2418266 (48)\ttotal: 2.43s\tremaining: 1m 36s\n",
      "49:\tlearn: 1.0879877\ttest: 1.2417752\tbest: 1.2417752 (49)\ttotal: 2.48s\tremaining: 1m 36s\n",
      "50:\tlearn: 1.0858338\ttest: 1.2418387\tbest: 1.2417752 (49)\ttotal: 2.54s\tremaining: 1m 37s\n",
      "51:\tlearn: 1.0837864\ttest: 1.2419235\tbest: 1.2417752 (49)\ttotal: 2.59s\tremaining: 1m 37s\n",
      "52:\tlearn: 1.0817956\ttest: 1.2419297\tbest: 1.2417752 (49)\ttotal: 2.64s\tremaining: 1m 36s\n",
      "53:\tlearn: 1.0798056\ttest: 1.2420494\tbest: 1.2417752 (49)\ttotal: 2.69s\tremaining: 1m 36s\n",
      "54:\tlearn: 1.0778268\ttest: 1.2421047\tbest: 1.2417752 (49)\ttotal: 2.74s\tremaining: 1m 36s\n",
      "55:\tlearn: 1.0760532\ttest: 1.2419939\tbest: 1.2417752 (49)\ttotal: 2.79s\tremaining: 1m 36s\n",
      "56:\tlearn: 1.0742600\ttest: 1.2422744\tbest: 1.2417752 (49)\ttotal: 2.85s\tremaining: 1m 36s\n",
      "57:\tlearn: 1.0724190\ttest: 1.2424700\tbest: 1.2417752 (49)\ttotal: 2.9s\tremaining: 1m 37s\n",
      "58:\tlearn: 1.0706815\ttest: 1.2427024\tbest: 1.2417752 (49)\ttotal: 2.96s\tremaining: 1m 37s\n",
      "59:\tlearn: 1.0690553\ttest: 1.2427819\tbest: 1.2417752 (49)\ttotal: 3s\tremaining: 1m 37s\n",
      "60:\tlearn: 1.0673491\ttest: 1.2429928\tbest: 1.2417752 (49)\ttotal: 3.06s\tremaining: 1m 37s\n",
      "61:\tlearn: 1.0657650\ttest: 1.2431599\tbest: 1.2417752 (49)\ttotal: 3.11s\tremaining: 1m 37s\n",
      "62:\tlearn: 1.0641548\ttest: 1.2434746\tbest: 1.2417752 (49)\ttotal: 3.16s\tremaining: 1m 37s\n",
      "63:\tlearn: 1.0626249\ttest: 1.2438333\tbest: 1.2417752 (49)\ttotal: 3.21s\tremaining: 1m 37s\n",
      "64:\tlearn: 1.0611116\ttest: 1.2442493\tbest: 1.2417752 (49)\ttotal: 3.26s\tremaining: 1m 37s\n",
      "65:\tlearn: 1.0596730\ttest: 1.2445156\tbest: 1.2417752 (49)\ttotal: 3.3s\tremaining: 1m 36s\n",
      "66:\tlearn: 1.0581971\ttest: 1.2449553\tbest: 1.2417752 (49)\ttotal: 3.37s\tremaining: 1m 37s\n",
      "67:\tlearn: 1.0567845\ttest: 1.2454213\tbest: 1.2417752 (49)\ttotal: 3.42s\tremaining: 1m 37s\n",
      "68:\tlearn: 1.0553817\ttest: 1.2455611\tbest: 1.2417752 (49)\ttotal: 3.47s\tremaining: 1m 37s\n",
      "69:\tlearn: 1.0541108\ttest: 1.2458729\tbest: 1.2417752 (49)\ttotal: 3.52s\tremaining: 1m 37s\n",
      "70:\tlearn: 1.0527281\ttest: 1.2463382\tbest: 1.2417752 (49)\ttotal: 3.58s\tremaining: 1m 37s\n",
      "71:\tlearn: 1.0515587\ttest: 1.2466310\tbest: 1.2417752 (49)\ttotal: 3.63s\tremaining: 1m 37s\n",
      "72:\tlearn: 1.0503303\ttest: 1.2470099\tbest: 1.2417752 (49)\ttotal: 3.69s\tremaining: 1m 37s\n",
      "73:\tlearn: 1.0491079\ttest: 1.2472054\tbest: 1.2417752 (49)\ttotal: 3.73s\tremaining: 1m 37s\n",
      "74:\tlearn: 1.0478669\ttest: 1.2475732\tbest: 1.2417752 (49)\ttotal: 3.79s\tremaining: 1m 37s\n",
      "75:\tlearn: 1.0466715\ttest: 1.2481005\tbest: 1.2417752 (49)\ttotal: 3.85s\tremaining: 1m 37s\n",
      "76:\tlearn: 1.0455319\ttest: 1.2483893\tbest: 1.2417752 (49)\ttotal: 3.9s\tremaining: 1m 37s\n",
      "77:\tlearn: 1.0444742\ttest: 1.2486647\tbest: 1.2417752 (49)\ttotal: 3.95s\tremaining: 1m 37s\n",
      "78:\tlearn: 1.0432702\ttest: 1.2491565\tbest: 1.2417752 (49)\ttotal: 4.01s\tremaining: 1m 37s\n",
      "79:\tlearn: 1.0422284\ttest: 1.2494955\tbest: 1.2417752 (49)\ttotal: 4.07s\tremaining: 1m 37s\n",
      "80:\tlearn: 1.0411881\ttest: 1.2499257\tbest: 1.2417752 (49)\ttotal: 4.12s\tremaining: 1m 37s\n",
      "81:\tlearn: 1.0401679\ttest: 1.2503646\tbest: 1.2417752 (49)\ttotal: 4.17s\tremaining: 1m 37s\n",
      "82:\tlearn: 1.0391884\ttest: 1.2508042\tbest: 1.2417752 (49)\ttotal: 4.22s\tremaining: 1m 37s\n",
      "83:\tlearn: 1.0382981\ttest: 1.2509646\tbest: 1.2417752 (49)\ttotal: 4.27s\tremaining: 1m 37s\n",
      "84:\tlearn: 1.0372397\ttest: 1.2514161\tbest: 1.2417752 (49)\ttotal: 4.33s\tremaining: 1m 37s\n",
      "85:\tlearn: 1.0362787\ttest: 1.2518655\tbest: 1.2417752 (49)\ttotal: 4.38s\tremaining: 1m 37s\n",
      "86:\tlearn: 1.0354092\ttest: 1.2520949\tbest: 1.2417752 (49)\ttotal: 4.44s\tremaining: 1m 37s\n",
      "87:\tlearn: 1.0344904\ttest: 1.2525195\tbest: 1.2417752 (49)\ttotal: 4.49s\tremaining: 1m 37s\n",
      "88:\tlearn: 1.0336022\ttest: 1.2528203\tbest: 1.2417752 (49)\ttotal: 4.54s\tremaining: 1m 37s\n",
      "89:\tlearn: 1.0326447\ttest: 1.2533545\tbest: 1.2417752 (49)\ttotal: 4.6s\tremaining: 1m 37s\n",
      "90:\tlearn: 1.0317613\ttest: 1.2539476\tbest: 1.2417752 (49)\ttotal: 4.65s\tremaining: 1m 37s\n",
      "91:\tlearn: 1.0308375\ttest: 1.2542362\tbest: 1.2417752 (49)\ttotal: 4.71s\tremaining: 1m 37s\n",
      "92:\tlearn: 1.0300207\ttest: 1.2544810\tbest: 1.2417752 (49)\ttotal: 4.76s\tremaining: 1m 37s\n",
      "93:\tlearn: 1.0291898\ttest: 1.2549812\tbest: 1.2417752 (49)\ttotal: 4.81s\tremaining: 1m 37s\n",
      "94:\tlearn: 1.0283598\ttest: 1.2553098\tbest: 1.2417752 (49)\ttotal: 4.86s\tremaining: 1m 37s\n",
      "95:\tlearn: 1.0275804\ttest: 1.2557419\tbest: 1.2417752 (49)\ttotal: 4.91s\tremaining: 1m 37s\n",
      "96:\tlearn: 1.0267572\ttest: 1.2560955\tbest: 1.2417752 (49)\ttotal: 4.97s\tremaining: 1m 37s\n",
      "97:\tlearn: 1.0259372\ttest: 1.2564758\tbest: 1.2417752 (49)\ttotal: 5.02s\tremaining: 1m 37s\n",
      "98:\tlearn: 1.0251333\ttest: 1.2567996\tbest: 1.2417752 (49)\ttotal: 5.08s\tremaining: 1m 37s\n",
      "99:\tlearn: 1.0245096\ttest: 1.2569588\tbest: 1.2417752 (49)\ttotal: 5.12s\tremaining: 1m 37s\n",
      "100:\tlearn: 1.0237597\ttest: 1.2572686\tbest: 1.2417752 (49)\ttotal: 5.17s\tremaining: 1m 37s\n",
      "101:\tlearn: 1.0230381\ttest: 1.2576282\tbest: 1.2417752 (49)\ttotal: 5.21s\tremaining: 1m 37s\n",
      "102:\tlearn: 1.0222293\ttest: 1.2579769\tbest: 1.2417752 (49)\ttotal: 5.28s\tremaining: 1m 37s\n",
      "103:\tlearn: 1.0216037\ttest: 1.2582023\tbest: 1.2417752 (49)\ttotal: 5.32s\tremaining: 1m 36s\n",
      "104:\tlearn: 1.0208801\ttest: 1.2584688\tbest: 1.2417752 (49)\ttotal: 5.37s\tremaining: 1m 36s\n",
      "105:\tlearn: 1.0201905\ttest: 1.2587381\tbest: 1.2417752 (49)\ttotal: 5.43s\tremaining: 1m 37s\n",
      "106:\tlearn: 1.0194457\ttest: 1.2590260\tbest: 1.2417752 (49)\ttotal: 5.48s\tremaining: 1m 37s\n",
      "107:\tlearn: 1.0187628\ttest: 1.2594800\tbest: 1.2417752 (49)\ttotal: 5.54s\tremaining: 1m 36s\n",
      "108:\tlearn: 1.0180221\ttest: 1.2599905\tbest: 1.2417752 (49)\ttotal: 5.59s\tremaining: 1m 36s\n",
      "109:\tlearn: 1.0173607\ttest: 1.2602277\tbest: 1.2417752 (49)\ttotal: 5.64s\tremaining: 1m 36s\n",
      "110:\tlearn: 1.0167363\ttest: 1.2604878\tbest: 1.2417752 (49)\ttotal: 5.69s\tremaining: 1m 36s\n",
      "111:\tlearn: 1.0160811\ttest: 1.2607856\tbest: 1.2417752 (49)\ttotal: 5.75s\tremaining: 1m 36s\n",
      "112:\tlearn: 1.0153773\ttest: 1.2613034\tbest: 1.2417752 (49)\ttotal: 5.8s\tremaining: 1m 36s\n",
      "113:\tlearn: 1.0147517\ttest: 1.2616530\tbest: 1.2417752 (49)\ttotal: 5.85s\tremaining: 1m 36s\n",
      "114:\tlearn: 1.0140829\ttest: 1.2619434\tbest: 1.2417752 (49)\ttotal: 5.9s\tremaining: 1m 36s\n",
      "115:\tlearn: 1.0134405\ttest: 1.2621823\tbest: 1.2417752 (49)\ttotal: 5.96s\tremaining: 1m 36s\n",
      "116:\tlearn: 1.0128330\ttest: 1.2623734\tbest: 1.2417752 (49)\ttotal: 6s\tremaining: 1m 36s\n",
      "117:\tlearn: 1.0121493\ttest: 1.2629214\tbest: 1.2417752 (49)\ttotal: 6.06s\tremaining: 1m 36s\n",
      "118:\tlearn: 1.0115016\ttest: 1.2632417\tbest: 1.2417752 (49)\ttotal: 6.12s\tremaining: 1m 36s\n",
      "119:\tlearn: 1.0109212\ttest: 1.2635452\tbest: 1.2417752 (49)\ttotal: 6.17s\tremaining: 1m 36s\n",
      "120:\tlearn: 1.0103818\ttest: 1.2636955\tbest: 1.2417752 (49)\ttotal: 6.22s\tremaining: 1m 36s\n",
      "121:\tlearn: 1.0097766\ttest: 1.2639691\tbest: 1.2417752 (49)\ttotal: 6.28s\tremaining: 1m 36s\n",
      "122:\tlearn: 1.0091569\ttest: 1.2640808\tbest: 1.2417752 (49)\ttotal: 6.33s\tremaining: 1m 36s\n",
      "123:\tlearn: 1.0086643\ttest: 1.2643312\tbest: 1.2417752 (49)\ttotal: 6.38s\tremaining: 1m 36s\n",
      "124:\tlearn: 1.0080172\ttest: 1.2646892\tbest: 1.2417752 (49)\ttotal: 6.43s\tremaining: 1m 36s\n",
      "125:\tlearn: 1.0074385\ttest: 1.2651112\tbest: 1.2417752 (49)\ttotal: 6.49s\tremaining: 1m 36s\n",
      "126:\tlearn: 1.0069414\ttest: 1.2653545\tbest: 1.2417752 (49)\ttotal: 6.53s\tremaining: 1m 36s\n",
      "127:\tlearn: 1.0064186\ttest: 1.2656282\tbest: 1.2417752 (49)\ttotal: 6.57s\tremaining: 1m 36s\n",
      "128:\tlearn: 1.0059189\ttest: 1.2657233\tbest: 1.2417752 (49)\ttotal: 6.62s\tremaining: 1m 35s\n",
      "129:\tlearn: 1.0054052\ttest: 1.2659358\tbest: 1.2417752 (49)\ttotal: 6.67s\tremaining: 1m 35s\n",
      "130:\tlearn: 1.0048417\ttest: 1.2659458\tbest: 1.2417752 (49)\ttotal: 6.72s\tremaining: 1m 35s\n",
      "131:\tlearn: 1.0042292\ttest: 1.2662930\tbest: 1.2417752 (49)\ttotal: 6.78s\tremaining: 1m 35s\n",
      "132:\tlearn: 1.0037005\ttest: 1.2664456\tbest: 1.2417752 (49)\ttotal: 6.83s\tremaining: 1m 35s\n",
      "133:\tlearn: 1.0030443\ttest: 1.2666130\tbest: 1.2417752 (49)\ttotal: 6.88s\tremaining: 1m 35s\n",
      "134:\tlearn: 1.0024697\ttest: 1.2667718\tbest: 1.2417752 (49)\ttotal: 6.94s\tremaining: 1m 35s\n",
      "135:\tlearn: 1.0019687\ttest: 1.2671736\tbest: 1.2417752 (49)\ttotal: 6.99s\tremaining: 1m 35s\n",
      "136:\tlearn: 1.0014286\ttest: 1.2674174\tbest: 1.2417752 (49)\ttotal: 7.03s\tremaining: 1m 35s\n",
      "137:\tlearn: 1.0009177\ttest: 1.2674863\tbest: 1.2417752 (49)\ttotal: 7.08s\tremaining: 1m 35s\n",
      "138:\tlearn: 1.0004469\ttest: 1.2677911\tbest: 1.2417752 (49)\ttotal: 7.12s\tremaining: 1m 35s\n",
      "139:\tlearn: 0.9998944\ttest: 1.2680181\tbest: 1.2417752 (49)\ttotal: 7.18s\tremaining: 1m 35s\n",
      "140:\tlearn: 0.9993275\ttest: 1.2682112\tbest: 1.2417752 (49)\ttotal: 7.23s\tremaining: 1m 35s\n",
      "141:\tlearn: 0.9987259\ttest: 1.2685062\tbest: 1.2417752 (49)\ttotal: 7.29s\tremaining: 1m 35s\n",
      "142:\tlearn: 0.9981802\ttest: 1.2687003\tbest: 1.2417752 (49)\ttotal: 7.35s\tremaining: 1m 35s\n",
      "143:\tlearn: 0.9976693\ttest: 1.2688627\tbest: 1.2417752 (49)\ttotal: 7.4s\tremaining: 1m 35s\n",
      "144:\tlearn: 0.9970851\ttest: 1.2689799\tbest: 1.2417752 (49)\ttotal: 7.46s\tremaining: 1m 35s\n",
      "145:\tlearn: 0.9965097\ttest: 1.2690896\tbest: 1.2417752 (49)\ttotal: 7.51s\tremaining: 1m 35s\n",
      "146:\tlearn: 0.9960072\ttest: 1.2691669\tbest: 1.2417752 (49)\ttotal: 7.56s\tremaining: 1m 35s\n",
      "147:\tlearn: 0.9955302\ttest: 1.2693710\tbest: 1.2417752 (49)\ttotal: 7.61s\tremaining: 1m 35s\n",
      "148:\tlearn: 0.9950350\ttest: 1.2695310\tbest: 1.2417752 (49)\ttotal: 7.66s\tremaining: 1m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  83%|████████▎ | 5/6 [00:43<00:08,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149:\tlearn: 0.9945255\ttest: 1.2697612\tbest: 1.2417752 (49)\ttotal: 7.71s\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.241775198\n",
      "bestIteration = 49\n",
      "\n",
      "Shrink model to first 50 iterations.\n",
      "0:\tlearn: 1.3097167\ttest: 1.2352324\tbest: 1.2352324 (0)\ttotal: 47.3ms\tremaining: 1m 34s\n",
      "1:\tlearn: 1.2985935\ttest: 1.2303971\tbest: 1.2303971 (1)\ttotal: 93ms\tremaining: 1m 32s\n",
      "2:\tlearn: 1.2875891\ttest: 1.2260627\tbest: 1.2260627 (2)\ttotal: 143ms\tremaining: 1m 35s\n",
      "3:\tlearn: 1.2768624\ttest: 1.2219416\tbest: 1.2219416 (3)\ttotal: 192ms\tremaining: 1m 35s\n",
      "4:\tlearn: 1.2664420\ttest: 1.2180376\tbest: 1.2180376 (4)\ttotal: 246ms\tremaining: 1m 38s\n",
      "5:\tlearn: 1.2563530\ttest: 1.2144878\tbest: 1.2144878 (5)\ttotal: 294ms\tremaining: 1m 37s\n",
      "6:\tlearn: 1.2466225\ttest: 1.2109892\tbest: 1.2109892 (6)\ttotal: 345ms\tremaining: 1m 38s\n",
      "7:\tlearn: 1.2371016\ttest: 1.2076690\tbest: 1.2076690 (7)\ttotal: 395ms\tremaining: 1m 38s\n",
      "8:\tlearn: 1.2280232\ttest: 1.2045563\tbest: 1.2045563 (8)\ttotal: 445ms\tremaining: 1m 38s\n",
      "9:\tlearn: 1.2191066\ttest: 1.2015321\tbest: 1.2015321 (9)\ttotal: 497ms\tremaining: 1m 38s\n",
      "10:\tlearn: 1.2105050\ttest: 1.1987440\tbest: 1.1987440 (10)\ttotal: 539ms\tremaining: 1m 37s\n",
      "11:\tlearn: 1.2021620\ttest: 1.1960586\tbest: 1.1960586 (11)\ttotal: 607ms\tremaining: 1m 40s\n",
      "12:\tlearn: 1.1938922\ttest: 1.1937773\tbest: 1.1937773 (12)\ttotal: 656ms\tremaining: 1m 40s\n",
      "13:\tlearn: 1.1860504\ttest: 1.1916532\tbest: 1.1916532 (13)\ttotal: 712ms\tremaining: 1m 40s\n",
      "14:\tlearn: 1.1781305\ttest: 1.1895122\tbest: 1.1895122 (14)\ttotal: 758ms\tremaining: 1m 40s\n",
      "15:\tlearn: 1.1705988\ttest: 1.1871830\tbest: 1.1871830 (15)\ttotal: 805ms\tremaining: 1m 39s\n",
      "16:\tlearn: 1.1632060\ttest: 1.1852215\tbest: 1.1852215 (16)\ttotal: 852ms\tremaining: 1m 39s\n",
      "17:\tlearn: 1.1559507\ttest: 1.1836079\tbest: 1.1836079 (17)\ttotal: 904ms\tremaining: 1m 39s\n",
      "18:\tlearn: 1.1490654\ttest: 1.1819825\tbest: 1.1819825 (18)\ttotal: 953ms\tremaining: 1m 39s\n",
      "19:\tlearn: 1.1420389\ttest: 1.1805549\tbest: 1.1805549 (19)\ttotal: 1s\tremaining: 1m 39s\n",
      "20:\tlearn: 1.1354191\ttest: 1.1790662\tbest: 1.1790662 (20)\ttotal: 1.05s\tremaining: 1m 38s\n",
      "21:\tlearn: 1.1291005\ttest: 1.1777285\tbest: 1.1777285 (21)\ttotal: 1.1s\tremaining: 1m 38s\n",
      "22:\tlearn: 1.1226889\ttest: 1.1766085\tbest: 1.1766085 (22)\ttotal: 1.15s\tremaining: 1m 38s\n",
      "23:\tlearn: 1.1164446\ttest: 1.1753301\tbest: 1.1753301 (23)\ttotal: 1.2s\tremaining: 1m 38s\n",
      "24:\tlearn: 1.1104597\ttest: 1.1743612\tbest: 1.1743612 (24)\ttotal: 1.25s\tremaining: 1m 38s\n",
      "25:\tlearn: 1.1043947\ttest: 1.1735793\tbest: 1.1735793 (25)\ttotal: 1.3s\tremaining: 1m 38s\n",
      "26:\tlearn: 1.0985055\ttest: 1.1728344\tbest: 1.1728344 (26)\ttotal: 1.35s\tremaining: 1m 38s\n",
      "27:\tlearn: 1.0929954\ttest: 1.1720772\tbest: 1.1720772 (27)\ttotal: 1.39s\tremaining: 1m 38s\n",
      "28:\tlearn: 1.0875516\ttest: 1.1714059\tbest: 1.1714059 (28)\ttotal: 1.44s\tremaining: 1m 37s\n",
      "29:\tlearn: 1.0821662\ttest: 1.1709620\tbest: 1.1709620 (29)\ttotal: 1.49s\tremaining: 1m 37s\n",
      "30:\tlearn: 1.0771845\ttest: 1.1704018\tbest: 1.1704018 (30)\ttotal: 1.55s\tremaining: 1m 38s\n",
      "31:\tlearn: 1.0720953\ttest: 1.1700579\tbest: 1.1700579 (31)\ttotal: 1.6s\tremaining: 1m 38s\n",
      "32:\tlearn: 1.0672684\ttest: 1.1695970\tbest: 1.1695970 (32)\ttotal: 1.65s\tremaining: 1m 38s\n",
      "33:\tlearn: 1.0625049\ttest: 1.1692775\tbest: 1.1692775 (33)\ttotal: 1.7s\tremaining: 1m 38s\n",
      "34:\tlearn: 1.0578087\ttest: 1.1690012\tbest: 1.1690012 (34)\ttotal: 1.75s\tremaining: 1m 38s\n",
      "35:\tlearn: 1.0534671\ttest: 1.1687029\tbest: 1.1687029 (35)\ttotal: 1.79s\tremaining: 1m 37s\n",
      "36:\tlearn: 1.0489892\ttest: 1.1686109\tbest: 1.1686109 (36)\ttotal: 1.84s\tremaining: 1m 37s\n",
      "37:\tlearn: 1.0447183\ttest: 1.1684348\tbest: 1.1684348 (37)\ttotal: 1.89s\tremaining: 1m 37s\n",
      "38:\tlearn: 1.0405481\ttest: 1.1684588\tbest: 1.1684348 (37)\ttotal: 1.94s\tremaining: 1m 37s\n",
      "39:\tlearn: 1.0363552\ttest: 1.1685437\tbest: 1.1684348 (37)\ttotal: 1.99s\tremaining: 1m 37s\n",
      "40:\tlearn: 1.0324448\ttest: 1.1685852\tbest: 1.1684348 (37)\ttotal: 2.03s\tremaining: 1m 37s\n",
      "41:\tlearn: 1.0285781\ttest: 1.1687007\tbest: 1.1684348 (37)\ttotal: 2.08s\tremaining: 1m 37s\n",
      "42:\tlearn: 1.0247798\ttest: 1.1689117\tbest: 1.1684348 (37)\ttotal: 2.13s\tremaining: 1m 36s\n",
      "43:\tlearn: 1.0211830\ttest: 1.1690502\tbest: 1.1684348 (37)\ttotal: 2.18s\tremaining: 1m 36s\n",
      "44:\tlearn: 1.0176695\ttest: 1.1694460\tbest: 1.1684348 (37)\ttotal: 2.23s\tremaining: 1m 36s\n",
      "45:\tlearn: 1.0142623\ttest: 1.1697329\tbest: 1.1684348 (37)\ttotal: 2.28s\tremaining: 1m 36s\n",
      "46:\tlearn: 1.0108934\ttest: 1.1698236\tbest: 1.1684348 (37)\ttotal: 2.32s\tremaining: 1m 36s\n",
      "47:\tlearn: 1.0075834\ttest: 1.1700943\tbest: 1.1684348 (37)\ttotal: 2.36s\tremaining: 1m 36s\n",
      "48:\tlearn: 1.0043186\ttest: 1.1703344\tbest: 1.1684348 (37)\ttotal: 2.41s\tremaining: 1m 36s\n",
      "49:\tlearn: 1.0011959\ttest: 1.1707596\tbest: 1.1684348 (37)\ttotal: 2.46s\tremaining: 1m 35s\n",
      "50:\tlearn: 0.9981718\ttest: 1.1712761\tbest: 1.1684348 (37)\ttotal: 2.52s\tremaining: 1m 36s\n",
      "51:\tlearn: 0.9951908\ttest: 1.1714970\tbest: 1.1684348 (37)\ttotal: 2.57s\tremaining: 1m 36s\n",
      "52:\tlearn: 0.9923324\ttest: 1.1718956\tbest: 1.1684348 (37)\ttotal: 2.61s\tremaining: 1m 35s\n",
      "53:\tlearn: 0.9894263\ttest: 1.1722862\tbest: 1.1684348 (37)\ttotal: 2.66s\tremaining: 1m 35s\n",
      "54:\tlearn: 0.9866626\ttest: 1.1728219\tbest: 1.1684348 (37)\ttotal: 2.72s\tremaining: 1m 36s\n",
      "55:\tlearn: 0.9839859\ttest: 1.1729998\tbest: 1.1684348 (37)\ttotal: 2.77s\tremaining: 1m 35s\n",
      "56:\tlearn: 0.9814079\ttest: 1.1735545\tbest: 1.1684348 (37)\ttotal: 2.81s\tremaining: 1m 35s\n",
      "57:\tlearn: 0.9788806\ttest: 1.1740165\tbest: 1.1684348 (37)\ttotal: 2.86s\tremaining: 1m 35s\n",
      "58:\tlearn: 0.9764717\ttest: 1.1745034\tbest: 1.1684348 (37)\ttotal: 2.92s\tremaining: 1m 36s\n",
      "59:\tlearn: 0.9740358\ttest: 1.1749181\tbest: 1.1684348 (37)\ttotal: 2.96s\tremaining: 1m 35s\n",
      "60:\tlearn: 0.9716010\ttest: 1.1754257\tbest: 1.1684348 (37)\ttotal: 3.02s\tremaining: 1m 35s\n",
      "61:\tlearn: 0.9692567\ttest: 1.1759629\tbest: 1.1684348 (37)\ttotal: 3.07s\tremaining: 1m 36s\n",
      "62:\tlearn: 0.9669937\ttest: 1.1763848\tbest: 1.1684348 (37)\ttotal: 3.12s\tremaining: 1m 36s\n",
      "63:\tlearn: 0.9648116\ttest: 1.1771377\tbest: 1.1684348 (37)\ttotal: 3.18s\tremaining: 1m 36s\n",
      "64:\tlearn: 0.9626598\ttest: 1.1776675\tbest: 1.1684348 (37)\ttotal: 3.22s\tremaining: 1m 35s\n",
      "65:\tlearn: 0.9605603\ttest: 1.1781591\tbest: 1.1684348 (37)\ttotal: 3.27s\tremaining: 1m 35s\n",
      "66:\tlearn: 0.9585150\ttest: 1.1786766\tbest: 1.1684348 (37)\ttotal: 3.33s\tremaining: 1m 36s\n",
      "67:\tlearn: 0.9565005\ttest: 1.1790300\tbest: 1.1684348 (37)\ttotal: 3.38s\tremaining: 1m 35s\n",
      "68:\tlearn: 0.9545175\ttest: 1.1797113\tbest: 1.1684348 (37)\ttotal: 3.44s\tremaining: 1m 36s\n",
      "69:\tlearn: 0.9526044\ttest: 1.1801048\tbest: 1.1684348 (37)\ttotal: 3.49s\tremaining: 1m 36s\n",
      "70:\tlearn: 0.9506839\ttest: 1.1807128\tbest: 1.1684348 (37)\ttotal: 3.54s\tremaining: 1m 36s\n",
      "71:\tlearn: 0.9488497\ttest: 1.1813213\tbest: 1.1684348 (37)\ttotal: 3.59s\tremaining: 1m 36s\n",
      "72:\tlearn: 0.9471000\ttest: 1.1820687\tbest: 1.1684348 (37)\ttotal: 3.64s\tremaining: 1m 36s\n",
      "73:\tlearn: 0.9453239\ttest: 1.1826625\tbest: 1.1684348 (37)\ttotal: 3.69s\tremaining: 1m 36s\n",
      "74:\tlearn: 0.9436685\ttest: 1.1832919\tbest: 1.1684348 (37)\ttotal: 3.74s\tremaining: 1m 36s\n",
      "75:\tlearn: 0.9420079\ttest: 1.1839897\tbest: 1.1684348 (37)\ttotal: 3.79s\tremaining: 1m 36s\n",
      "76:\tlearn: 0.9404432\ttest: 1.1845669\tbest: 1.1684348 (37)\ttotal: 3.85s\tremaining: 1m 36s\n",
      "77:\tlearn: 0.9387653\ttest: 1.1850762\tbest: 1.1684348 (37)\ttotal: 3.9s\tremaining: 1m 36s\n",
      "78:\tlearn: 0.9372399\ttest: 1.1854445\tbest: 1.1684348 (37)\ttotal: 3.94s\tremaining: 1m 35s\n",
      "79:\tlearn: 0.9356812\ttest: 1.1860349\tbest: 1.1684348 (37)\ttotal: 3.99s\tremaining: 1m 35s\n",
      "80:\tlearn: 0.9342178\ttest: 1.1865186\tbest: 1.1684348 (37)\ttotal: 4.03s\tremaining: 1m 35s\n",
      "81:\tlearn: 0.9326589\ttest: 1.1869795\tbest: 1.1684348 (37)\ttotal: 4.09s\tremaining: 1m 35s\n",
      "82:\tlearn: 0.9313251\ttest: 1.1873716\tbest: 1.1684348 (37)\ttotal: 4.14s\tremaining: 1m 35s\n",
      "83:\tlearn: 0.9298423\ttest: 1.1879107\tbest: 1.1684348 (37)\ttotal: 4.19s\tremaining: 1m 35s\n",
      "84:\tlearn: 0.9283819\ttest: 1.1882593\tbest: 1.1684348 (37)\ttotal: 4.24s\tremaining: 1m 35s\n",
      "85:\tlearn: 0.9269836\ttest: 1.1887844\tbest: 1.1684348 (37)\ttotal: 4.29s\tremaining: 1m 35s\n",
      "86:\tlearn: 0.9256308\ttest: 1.1892474\tbest: 1.1684348 (37)\ttotal: 4.33s\tremaining: 1m 35s\n",
      "87:\tlearn: 0.9243138\ttest: 1.1897791\tbest: 1.1684348 (37)\ttotal: 4.39s\tremaining: 1m 35s\n",
      "88:\tlearn: 0.9230666\ttest: 1.1904412\tbest: 1.1684348 (37)\ttotal: 4.43s\tremaining: 1m 35s\n",
      "89:\tlearn: 0.9218670\ttest: 1.1911205\tbest: 1.1684348 (37)\ttotal: 4.49s\tremaining: 1m 35s\n",
      "90:\tlearn: 0.9206085\ttest: 1.1916200\tbest: 1.1684348 (37)\ttotal: 4.54s\tremaining: 1m 35s\n",
      "91:\tlearn: 0.9193475\ttest: 1.1919545\tbest: 1.1684348 (37)\ttotal: 4.59s\tremaining: 1m 35s\n",
      "92:\tlearn: 0.9181676\ttest: 1.1925520\tbest: 1.1684348 (37)\ttotal: 4.64s\tremaining: 1m 35s\n",
      "93:\tlearn: 0.9168573\ttest: 1.1929811\tbest: 1.1684348 (37)\ttotal: 4.69s\tremaining: 1m 35s\n",
      "94:\tlearn: 0.9156593\ttest: 1.1934054\tbest: 1.1684348 (37)\ttotal: 4.75s\tremaining: 1m 35s\n",
      "95:\tlearn: 0.9145260\ttest: 1.1936359\tbest: 1.1684348 (37)\ttotal: 4.79s\tremaining: 1m 35s\n",
      "96:\tlearn: 0.9133454\ttest: 1.1942042\tbest: 1.1684348 (37)\ttotal: 4.85s\tremaining: 1m 35s\n",
      "97:\tlearn: 0.9122075\ttest: 1.1945748\tbest: 1.1684348 (37)\ttotal: 4.9s\tremaining: 1m 35s\n",
      "98:\tlearn: 0.9110328\ttest: 1.1951095\tbest: 1.1684348 (37)\ttotal: 4.96s\tremaining: 1m 35s\n",
      "99:\tlearn: 0.9099471\ttest: 1.1955671\tbest: 1.1684348 (37)\ttotal: 5.01s\tremaining: 1m 35s\n",
      "100:\tlearn: 0.9088312\ttest: 1.1960662\tbest: 1.1684348 (37)\ttotal: 5.07s\tremaining: 1m 35s\n",
      "101:\tlearn: 0.9077294\ttest: 1.1964523\tbest: 1.1684348 (37)\ttotal: 5.13s\tremaining: 1m 35s\n",
      "102:\tlearn: 0.9065766\ttest: 1.1969382\tbest: 1.1684348 (37)\ttotal: 5.17s\tremaining: 1m 35s\n",
      "103:\tlearn: 0.9056039\ttest: 1.1971903\tbest: 1.1684348 (37)\ttotal: 5.22s\tremaining: 1m 35s\n",
      "104:\tlearn: 0.9046063\ttest: 1.1974647\tbest: 1.1684348 (37)\ttotal: 5.26s\tremaining: 1m 34s\n",
      "105:\tlearn: 0.9035266\ttest: 1.1979997\tbest: 1.1684348 (37)\ttotal: 5.32s\tremaining: 1m 35s\n",
      "106:\tlearn: 0.9025988\ttest: 1.1983598\tbest: 1.1684348 (37)\ttotal: 5.36s\tremaining: 1m 34s\n",
      "107:\tlearn: 0.9016810\ttest: 1.1988023\tbest: 1.1684348 (37)\ttotal: 5.41s\tremaining: 1m 34s\n",
      "108:\tlearn: 0.9006895\ttest: 1.1992361\tbest: 1.1684348 (37)\ttotal: 5.47s\tremaining: 1m 34s\n",
      "109:\tlearn: 0.8997346\ttest: 1.1995450\tbest: 1.1684348 (37)\ttotal: 5.52s\tremaining: 1m 34s\n",
      "110:\tlearn: 0.8987873\ttest: 1.1998880\tbest: 1.1684348 (37)\ttotal: 5.57s\tremaining: 1m 34s\n",
      "111:\tlearn: 0.8978370\ttest: 1.2003428\tbest: 1.1684348 (37)\ttotal: 5.63s\tremaining: 1m 34s\n",
      "112:\tlearn: 0.8968816\ttest: 1.2008957\tbest: 1.1684348 (37)\ttotal: 5.68s\tremaining: 1m 34s\n",
      "113:\tlearn: 0.8960255\ttest: 1.2011581\tbest: 1.1684348 (37)\ttotal: 5.73s\tremaining: 1m 34s\n",
      "114:\tlearn: 0.8952063\ttest: 1.2016284\tbest: 1.1684348 (37)\ttotal: 5.78s\tremaining: 1m 34s\n",
      "115:\tlearn: 0.8942676\ttest: 1.2018073\tbest: 1.1684348 (37)\ttotal: 5.83s\tremaining: 1m 34s\n",
      "116:\tlearn: 0.8933059\ttest: 1.2021510\tbest: 1.1684348 (37)\ttotal: 5.88s\tremaining: 1m 34s\n",
      "117:\tlearn: 0.8923506\ttest: 1.2025452\tbest: 1.1684348 (37)\ttotal: 5.93s\tremaining: 1m 34s\n",
      "118:\tlearn: 0.8913872\ttest: 1.2029529\tbest: 1.1684348 (37)\ttotal: 5.99s\tremaining: 1m 34s\n",
      "119:\tlearn: 0.8904792\ttest: 1.2033227\tbest: 1.1684348 (37)\ttotal: 6.05s\tremaining: 1m 34s\n",
      "120:\tlearn: 0.8896961\ttest: 1.2037618\tbest: 1.1684348 (37)\ttotal: 6.1s\tremaining: 1m 34s\n",
      "121:\tlearn: 0.8888251\ttest: 1.2042798\tbest: 1.1684348 (37)\ttotal: 6.15s\tremaining: 1m 34s\n",
      "122:\tlearn: 0.8880145\ttest: 1.2044051\tbest: 1.1684348 (37)\ttotal: 6.19s\tremaining: 1m 34s\n",
      "123:\tlearn: 0.8872440\ttest: 1.2046517\tbest: 1.1684348 (37)\ttotal: 6.24s\tremaining: 1m 34s\n",
      "124:\tlearn: 0.8863134\ttest: 1.2048820\tbest: 1.1684348 (37)\ttotal: 6.29s\tremaining: 1m 34s\n",
      "125:\tlearn: 0.8854988\ttest: 1.2053736\tbest: 1.1684348 (37)\ttotal: 6.35s\tremaining: 1m 34s\n",
      "126:\tlearn: 0.8845458\ttest: 1.2056793\tbest: 1.1684348 (37)\ttotal: 6.42s\tremaining: 1m 34s\n",
      "127:\tlearn: 0.8837854\ttest: 1.2058759\tbest: 1.1684348 (37)\ttotal: 6.46s\tremaining: 1m 34s\n",
      "128:\tlearn: 0.8828903\ttest: 1.2062044\tbest: 1.1684348 (37)\ttotal: 6.52s\tremaining: 1m 34s\n",
      "129:\tlearn: 0.8821578\ttest: 1.2064398\tbest: 1.1684348 (37)\ttotal: 6.56s\tremaining: 1m 34s\n",
      "130:\tlearn: 0.8814541\ttest: 1.2066498\tbest: 1.1684348 (37)\ttotal: 6.6s\tremaining: 1m 34s\n",
      "131:\tlearn: 0.8806432\ttest: 1.2070084\tbest: 1.1684348 (37)\ttotal: 6.66s\tremaining: 1m 34s\n",
      "132:\tlearn: 0.8798898\ttest: 1.2070653\tbest: 1.1684348 (37)\ttotal: 6.71s\tremaining: 1m 34s\n",
      "133:\tlearn: 0.8791278\ttest: 1.2072995\tbest: 1.1684348 (37)\ttotal: 6.75s\tremaining: 1m 34s\n",
      "134:\tlearn: 0.8784032\ttest: 1.2076761\tbest: 1.1684348 (37)\ttotal: 6.81s\tremaining: 1m 34s\n",
      "135:\tlearn: 0.8775708\ttest: 1.2078497\tbest: 1.1684348 (37)\ttotal: 6.87s\tremaining: 1m 34s\n",
      "136:\tlearn: 0.8768034\ttest: 1.2079005\tbest: 1.1684348 (37)\ttotal: 6.91s\tremaining: 1m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 6/6 [00:51<00:00,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137:\tlearn: 0.8760958\ttest: 1.2080322\tbest: 1.1684348 (37)\ttotal: 6.96s\tremaining: 1m 33s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 1.168434787\n",
      "bestIteration = 37\n",
      "\n",
      "Shrink model to first 38 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stacking_model.fit(minor_predictions_train, y_train_1, minor_predictions_val, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37243/1539598227.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(catboost_pred_3, device=device),\n"
     ]
    }
   ],
   "source": [
    "minor_predictions_test = torch.cat([\n",
    "    X_train_3,\n",
    "    linreg_pred,\n",
    "    torch.tensor(catboost_pred_3, device=device),\n",
    "], dim=1).float().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor_predictions_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_pred = stacking_model.predict(minor_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between prediction 0 and true value: 0.3387\n",
      "Correlation between prediction 1 and true value: 0.3936\n",
      "Correlation between prediction 2 and true value: 0.4071\n",
      "Correlation between prediction 3 and true value: 0.3738\n",
      "Correlation between prediction 4 and true value: 0.3775\n",
      "Correlation between prediction 5 and true value: 0.3882\n"
     ]
    }
   ],
   "source": [
    "print_corr(stacking_pred, y_train_3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14247963658495932\n",
      "0.1447045795553376\n"
     ]
    }
   ],
   "source": [
    "print(r2(stacking_pred, y_train_3.cpu()))\n",
    "print(r2_from_list(r_list(stacking_pred, y_train_3.cpu())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalkForwardTest:\n",
    "    def __init__(self, model, X, Y, train_num_steps: int, val_num_steps: int, test_num_steps: int):\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.train_num_steps = train_num_steps\n",
    "        self.val_num_steps = val_num_steps\n",
    "        self.test_num_steps = test_num_steps\n",
    "\n",
    "        self._slices = None # shape: (num_sets, train_slice, val_slice, test_slice)\n",
    "\n",
    "    def _split_data(self):\n",
    "        num_wf_iterations = (len(self.Y) - self.train_num_steps - self.val_num_steps - self.test_num_steps) // self.train_num_steps\n",
    "        self._slices = np.zeros((num_wf_iterations, 3), dtype=object)\n",
    "        self._num_wf_iterations = num_wf_iterations\n",
    "        for i in range(num_wf_iterations):\n",
    "            train_slice = slice(i * self.train_num_steps, (i + 1) * self.train_num_steps)\n",
    "            val_slice = slice(train_slice.stop, train_slice.stop + self.val_num_steps)\n",
    "            test_slice = slice(val_slice.stop, val_slice.stop + self.test_num_steps)\n",
    "            self._slices[i] = (train_slice, val_slice, test_slice)\n",
    "    \n",
    "    def fit(self):\n",
    "        self._split_data()\n",
    "        self._predictions = None # shape: (num_sets, test_num_steps, Y.shape[1])\n",
    "        for i in range(self._num_wf_iterations):\n",
    "            train_slice, val_slice, test_slice = self._slices[i]\n",
    "            self.model.fit(self.X[train_slice], self.Y[train_slice], self.X[val_slice], self.Y[val_slice])\n",
    "            pred = self.model.predict(self.X[test_slice])\n",
    "            self._predictions[i] = pred\n",
    "        return self._predictions\n",
    "    \n",
    "    @property\n",
    "    def correct_predictions(self):\n",
    "        # only test sets\n",
    "        return [slice_ for slice_ in self._slices[2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
